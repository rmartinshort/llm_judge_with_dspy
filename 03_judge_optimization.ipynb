{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9559ccd0-996b-491f-96a6-569e3e6005cd",
   "metadata": {},
   "source": [
    "## Optimization of judge using gold standard labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ada2a8d4-7501-42ec-91aa-79a7258016dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d85d9ce5-2fc0-4491-9f68-1df83ff7d1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rmartinshort/Documents/DS_projects/dspy_judge/judgemodel/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dspy_judge.llm_caller.utils import load_secrets\n",
    "from dspy_judge.data_loader.dataset_loader import CustomerSupportDatasetLoader\n",
    "from dspy_judge.processor.parallel_processor import ParallelProcessor\n",
    "from dspy_judge.prompts.dspy_signatures import SupportTranscriptJudge\n",
    "from dspy_judge.processor.utils import convert_dataset_to_dspy_examples, extract_llm_response_fields_dspy\n",
    "from dspy_judge.processor.parallel_processor import ParallelProcessor\n",
    "from dspy_judge.metrics import match_judge_metric\n",
    "from dspy_judge.plotting import plot_judge_results\n",
    "import numpy as np\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71ea396b-0268-49a8-8241-06636e3ea490",
   "metadata": {},
   "outputs": [],
   "source": [
    "secrets = load_secrets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0274486f-ebc5-4e1a-9051-20e370de4d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = CustomerSupportDatasetLoader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2577fc-8e6a-4599-a044-7ccb346c339a",
   "metadata": {},
   "source": [
    "## Set up judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9526922-17e4-45a9-a506-bef536f98693",
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_model = dspy.LM(\n",
    "    \"gemini/gemini-1.5-flash\",\n",
    "    api_key=secrets[\"GEMINI_API_KEY\"],\n",
    "    cache=False,\n",
    "    temperature=0\n",
    ")\n",
    "dspy.configure(lm=judge_model,track_usage=True,adapter=dspy.JSONAdapter())\n",
    "generate_judge_reasoning = dspy.ChainOfThought(SupportTranscriptJudge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b532f042-07ec-45cb-8b62-80119ad624e2",
   "metadata": {},
   "source": [
    "## Load the gold standard judge dataset (AKA SME labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "416d2082-8b0b-4129-a494-487a9e9c1be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:24 - dspy_judge.data_loader.dataset_loader - INFO - Local dataset loaded from datasets/gold_standard_judge_result. Size: 160\n"
     ]
    }
   ],
   "source": [
    "dspy_gold_standard_judge_results = data_loader.load_local_dataset(\"datasets/gold_standard_judge_result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4d4095b-4718-4a93-b58d-552f381450d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:25 - dspy_judge.processor.utils - INFO - Processed 160 training examples\n"
     ]
    }
   ],
   "source": [
    "judge_dataset_examples = convert_dataset_to_dspy_examples(\n",
    "    dspy_gold_standard_judge_results,\n",
    "    field_mapping = {\"transcript\":\"output_transcript\",\"satisfied\":\"satisfied\"},\n",
    "    input_field=\"transcript\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee52c402-3ef7-41af-a20f-5f76daa84d31",
   "metadata": {},
   "source": [
    "## Check that the metric works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24668fac-9eb2-47d9-8bb4-aa7d85a41bf2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:26:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:26:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "  0%|                                                                                                                      | 0/160 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 1 (0.0%):   1%|▍                                                                            | 1/160 [00:00<01:30,  1.76it/s]2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 2 (50.0%):   1%|▍                                                                           | 1/160 [00:00<01:30,  1.76it/s]2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 3 (33.3%):   1%|▉                                                                           | 2/160 [00:00<01:29,  1.76it/s]2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 2.00 / 4 (50.0%):   2%|█▍                                                                          | 3/160 [00:00<01:29,  1.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 2.00 / 5 (40.0%):   2%|█▉                                                                          | 4/160 [00:00<01:28,  1.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 3.00 / 6 (50.0%):   3%|██▍                                                                         | 5/160 [00:00<01:27,  1.76it/s]2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 7 (57.1%):   4%|██▊                                                                         | 6/160 [00:00<01:27,  1.76it/s]2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 5.00 / 8 (62.5%):   4%|███▎                                                                        | 7/160 [00:00<01:26,  1.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 5.00 / 9 (55.6%):   5%|███▊                                                                        | 8/160 [00:00<01:26,  1.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 6.00 / 10 (60.0%):   6%|████▏                                                                      | 9/160 [00:00<01:25,  1.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 7.00 / 11 (63.6%):   6%|████▋                                                                     | 10/160 [00:00<01:25,  1.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 7.00 / 12 (58.3%):   7%|█████                                                                     | 11/160 [00:00<01:24,  1.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 13 (53.8%):   8%|█████▌                                                                    | 12/160 [00:00<01:23,  1.76it/s]2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 14 (57.1%):   8%|██████                                                                    | 13/160 [00:00<01:23,  1.76it/s]2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 8.00 / 15 (53.3%):   9%|██████▍                                                                   | 14/160 [00:00<01:22,  1.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 16 (56.2%):   9%|██████▉                                                                   | 15/160 [00:00<01:22,  1.76it/s]2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 17 (58.8%):  10%|███████▎                                                                 | 16/160 [00:00<01:21,  1.76it/s]2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 18 (61.1%):  11%|███████▊                                                                 | 17/160 [00:00<01:21,  1.76it/s]2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 19 (57.9%):  11%|████████▏                                                                | 18/160 [00:00<01:20,  1.76it/s]2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 20 (60.0%):  12%|████████▋                                                                | 19/160 [00:00<01:20,  1.76it/s]2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 21 (61.9%):  12%|█████████▏                                                               | 20/160 [00:00<01:19,  1.76it/s]2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 22 (63.6%):  13%|█████████▌                                                               | 21/160 [00:00<01:18,  1.76it/s]2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 23 (65.2%):  14%|██████████                                                               | 22/160 [00:00<01:18,  1.76it/s]2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 24 (66.7%):  14%|██████████▍                                                              | 23/160 [00:00<01:17,  1.76it/s]2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 25 (68.0%):  16%|███████████▍                                                             | 25/160 [00:01<00:04, 29.04it/s]2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 26 (69.2%):  16%|███████████▍                                                             | 25/160 [00:01<00:04, 29.04it/s]2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 19.00 / 27 (70.4%):  16%|███████████▊                                                             | 26/160 [00:01<00:04, 29.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 19.00 / 28 (67.9%):  17%|████████████▎                                                            | 27/160 [00:01<00:04, 29.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 20.00 / 29 (69.0%):  18%|████████████▊                                                            | 28/160 [00:01<00:04, 29.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 30 (66.7%):  18%|█████████████▏                                                           | 29/160 [00:01<00:04, 29.04it/s]2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 21.00 / 31 (67.7%):  19%|█████████████▋                                                           | 30/160 [00:01<00:04, 29.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 22.00 / 32 (68.8%):  19%|██████████████▏                                                          | 31/160 [00:01<00:04, 29.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 33 (66.7%):  20%|██████████████▌                                                          | 32/160 [00:01<00:04, 29.04it/s]2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 34 (67.6%):  21%|███████████████                                                          | 33/160 [00:01<00:04, 29.04it/s]2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 35 (68.6%):  21%|███████████████▌                                                         | 34/160 [00:01<00:04, 29.04it/s]2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 24.00 / 35 (68.6%):  22%|███████████████▉                                                         | 35/160 [00:01<00:03, 39.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.00 / 36 (69.4%):  22%|███████████████▉                                                         | 35/160 [00:01<00:03, 39.08it/s]2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 26.00 / 37 (70.3%):  22%|████████████████▍                                                        | 36/160 [00:01<00:03, 39.08it/s]2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27.00 / 38 (71.1%):  23%|████████████████▉                                                        | 37/160 [00:01<00:03, 39.08it/s]2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 28.00 / 39 (71.8%):  24%|█████████████████▎                                                       | 38/160 [00:01<00:03, 39.08it/s]2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 29.00 / 40 (72.5%):  24%|█████████████████▊                                                       | 39/160 [00:01<00:03, 39.08it/s]2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 29.00 / 41 (70.7%):  25%|██████████████████▎                                                      | 40/160 [00:01<00:03, 39.08it/s]2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 30.00 / 42 (71.4%):  26%|██████████████████▋                                                      | 41/160 [00:01<00:03, 39.08it/s]2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 30.00 / 43 (69.8%):  26%|███████████████████▏                                                     | 42/160 [00:01<00:03, 39.08it/s]2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 31.00 / 44 (70.5%):  27%|███████████████████▌                                                     | 43/160 [00:01<00:02, 39.08it/s]2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 31.00 / 45 (68.9%):  28%|████████████████████                                                     | 44/160 [00:01<00:02, 39.08it/s]2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 32.00 / 46 (69.6%):  28%|████████████████████▌                                                    | 45/160 [00:01<00:02, 39.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 32.00 / 46 (69.6%):  29%|████████████████████▉                                                    | 46/160 [00:01<00:02, 47.51it/s]2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 32.00 / 47 (68.1%):  29%|████████████████████▉                                                    | 46/160 [00:01<00:02, 47.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 32.00 / 48 (66.7%):  29%|█████████████████████▍                                                   | 47/160 [00:01<00:02, 47.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:26:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 33.00 / 49 (67.3%):  30%|█████████████████████▉                                                   | 48/160 [00:01<00:02, 47.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 33.00 / 50 (66.0%):  31%|██████████████████████▎                                                  | 49/160 [00:01<00:02, 47.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 34.00 / 51 (66.7%):  31%|██████████████████████▊                                                  | 50/160 [00:01<00:02, 47.51it/s]2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 35.00 / 52 (67.3%):  32%|███████████████████████▎                                                 | 51/160 [00:01<00:02, 47.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 35.00 / 53 (66.0%):  32%|███████████████████████▋                                                 | 52/160 [00:01<00:02, 47.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 35.00 / 53 (66.0%):  33%|████████████████████████▏                                                | 53/160 [00:01<00:02, 40.84it/s]2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 36.00 / 54 (66.7%):  33%|████████████████████████▏                                                | 53/160 [00:01<00:02, 40.84it/s]2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 37.00 / 55 (67.3%):  34%|████████████████████████▋                                                | 54/160 [00:01<00:02, 40.84it/s]2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 37.00 / 56 (66.1%):  34%|█████████████████████████                                                | 55/160 [00:01<00:02, 40.84it/s]2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 37.00 / 57 (64.9%):  35%|█████████████████████████▌                                               | 56/160 [00:01<00:02, 40.84it/s]2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 37.00 / 58 (63.8%):  36%|██████████████████████████                                               | 57/160 [00:01<00:02, 40.84it/s]2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 37.00 / 59 (62.7%):  36%|██████████████████████████▍                                              | 58/160 [00:01<00:02, 40.84it/s]2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 38.00 / 60 (63.3%):  37%|██████████████████████████▉                                              | 59/160 [00:01<00:02, 40.84it/s]2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 38.00 / 61 (62.3%):  38%|███████████████████████████▍                                             | 60/160 [00:01<00:02, 40.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 39.00 / 62 (62.9%):  38%|███████████████████████████▊                                             | 61/160 [00:01<00:02, 40.84it/s]2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 40.00 / 63 (63.5%):  39%|████████████████████████████▎                                            | 62/160 [00:01<00:02, 40.84it/s]2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 41.00 / 64 (64.1%):  39%|████████████████████████████▋                                            | 63/160 [00:01<00:02, 40.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 41.00 / 65 (63.1%):  40%|█████████████████████████████▏                                           | 64/160 [00:01<00:02, 40.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 42.00 / 66 (63.6%):  41%|█████████████████████████████▋                                           | 65/160 [00:01<00:02, 40.84it/s]2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 42.00 / 67 (62.7%):  41%|██████████████████████████████                                           | 66/160 [00:01<00:02, 40.84it/s]2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 42.00 / 68 (61.8%):  42%|██████████████████████████████▌                                          | 67/160 [00:01<00:02, 40.84it/s]2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 42.00 / 68 (61.8%):  42%|███████████████████████████████                                          | 68/160 [00:01<00:01, 54.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 42.00 / 69 (60.9%):  42%|███████████████████████████████                                          | 68/160 [00:01<00:01, 54.47it/s]2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 43.00 / 70 (61.4%):  43%|███████████████████████████████▍                                         | 69/160 [00:01<00:01, 54.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 43.00 / 71 (60.6%):  44%|███████████████████████████████▉                                         | 70/160 [00:01<00:01, 54.47it/s]2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 43.00 / 72 (59.7%):  44%|████████████████████████████████▍                                        | 71/160 [00:01<00:01, 54.47it/s]2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 44.00 / 73 (60.3%):  45%|████████████████████████████████▊                                        | 72/160 [00:01<00:01, 54.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 45.00 / 74 (60.8%):  46%|█████████████████████████████████▎                                       | 73/160 [00:01<00:01, 54.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 45.00 / 75 (60.0%):  46%|█████████████████████████████████▊                                       | 74/160 [00:01<00:01, 54.47it/s]2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 45.00 / 75 (60.0%):  47%|██████████████████████████████████▏                                      | 75/160 [00:01<00:01, 44.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 45.00 / 76 (59.2%):  47%|██████████████████████████████████▏                                      | 75/160 [00:01<00:01, 44.96it/s]2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 46.00 / 77 (59.7%):  48%|██████████████████████████████████▋                                      | 76/160 [00:01<00:01, 44.96it/s]2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 47.00 / 78 (60.3%):  48%|███████████████████████████████████▏                                     | 77/160 [00:01<00:01, 44.96it/s]2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 47.00 / 79 (59.5%):  49%|███████████████████████████████████▌                                     | 78/160 [00:01<00:01, 44.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 47.00 / 80 (58.8%):  49%|████████████████████████████████████                                     | 79/160 [00:01<00:01, 44.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 48.00 / 81 (59.3%):  50%|████████████████████████████████████▌                                    | 80/160 [00:01<00:01, 44.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 49.00 / 82 (59.8%):  51%|████████████████████████████████████▉                                    | 81/160 [00:01<00:01, 44.96it/s]2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 49.00 / 83 (59.0%):  51%|█████████████████████████████████████▍                                   | 82/160 [00:01<00:01, 44.96it/s]2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 49.00 / 84 (58.3%):  52%|█████████████████████████████████████▊                                   | 83/160 [00:02<00:01, 44.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 49.00 / 84 (58.3%):  52%|██████████████████████████████████████▎                                  | 84/160 [00:02<00:01, 51.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 50.00 / 85 (58.8%):  52%|██████████████████████████████████████▎                                  | 84/160 [00:02<00:01, 51.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 51.00 / 86 (59.3%):  53%|██████████████████████████████████████▊                                  | 85/160 [00:02<00:01, 51.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 52.00 / 87 (59.8%):  54%|███████████████████████████████████████▏                                 | 86/160 [00:02<00:01, 51.84it/s]2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 53.00 / 88 (60.2%):  54%|███████████████████████████████████████▋                                 | 87/160 [00:02<00:01, 51.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 54.00 / 89 (60.7%):  55%|████████████████████████████████████████▏                                | 88/160 [00:02<00:01, 51.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 54.00 / 90 (60.0%):  56%|████████████████████████████████████████▌                                | 89/160 [00:02<00:01, 51.84it/s]2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 55.00 / 91 (60.4%):  56%|█████████████████████████████████████████                                | 90/160 [00:02<00:01, 51.84it/s]2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 56.00 / 92 (60.9%):  57%|█████████████████████████████████████████▌                               | 91/160 [00:02<00:01, 51.84it/s]2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 56.00 / 92 (60.9%):  57%|█████████████████████████████████████████▉                               | 92/160 [00:02<00:01, 55.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 56.00 / 93 (60.2%):  57%|█████████████████████████████████████████▉                               | 92/160 [00:02<00:01, 55.72it/s]2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 57.00 / 94 (60.6%):  58%|██████████████████████████████████████████▍                              | 93/160 [00:02<00:01, 55.72it/s]2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 57.00 / 95 (60.0%):  59%|██████████████████████████████████████████▉                              | 94/160 [00:02<00:01, 55.72it/s]2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 58.00 / 96 (60.4%):  59%|███████████████████████████████████████████▎                             | 95/160 [00:02<00:01, 55.72it/s]2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 59.00 / 97 (60.8%):  60%|███████████████████████████████████████████▊                             | 96/160 [00:02<00:01, 55.72it/s]2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 59.00 / 98 (60.2%):  61%|████████████████████████████████████████████▎                            | 97/160 [00:02<00:01, 55.72it/s]2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 59.00 / 99 (59.6%):  61%|████████████████████████████████████████████▋                            | 98/160 [00:02<00:01, 55.72it/s]2025-08-18 21:26:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 59.00 / 99 (59.6%):  62%|█████████████████████████████████████████████▏                           | 99/160 [00:02<00:01, 48.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 60.00 / 100 (60.0%):  62%|████████████████████████████████████████████▌                           | 99/160 [00:02<00:01, 48.20it/s]2025-08-18 21:26:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 60.00 / 101 (59.4%):  62%|████████████████████████████████████████████▍                          | 100/160 [00:02<00:01, 48.20it/s]2025-08-18 21:26:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 61.00 / 102 (59.8%):  63%|████████████████████████████████████████████▊                          | 101/160 [00:02<00:01, 48.20it/s]2025-08-18 21:26:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 62.00 / 103 (60.2%):  64%|█████████████████████████████████████████████▎                         | 102/160 [00:02<00:01, 48.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 62.00 / 104 (59.6%):  64%|█████████████████████████████████████████████▋                         | 103/160 [00:02<00:01, 48.20it/s]2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 63.00 / 105 (60.0%):  65%|██████████████████████████████████████████████▏                        | 104/160 [00:02<00:01, 48.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 64.00 / 106 (60.4%):  66%|██████████████████████████████████████████████▌                        | 105/160 [00:02<00:01, 48.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 65.00 / 107 (60.7%):  66%|███████████████████████████████████████████████                        | 106/160 [00:02<00:01, 48.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 66.00 / 108 (61.1%):  67%|███████████████████████████████████████████████▍                       | 107/160 [00:02<00:01, 48.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 67.00 / 109 (61.5%):  68%|███████████████████████████████████████████████▉                       | 108/160 [00:02<00:01, 48.20it/s]2025-08-18 21:26:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 67.00 / 109 (61.5%):  68%|████████████████████████████████████████████████▎                      | 109/160 [00:02<00:00, 58.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 67.00 / 110 (60.9%):  68%|████████████████████████████████████████████████▎                      | 109/160 [00:02<00:00, 58.20it/s]2025-08-18 21:26:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 68.00 / 111 (61.3%):  69%|████████████████████████████████████████████████▊                      | 110/160 [00:02<00:00, 58.20it/s]2025-08-18 21:26:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 68.00 / 112 (60.7%):  69%|█████████████████████████████████████████████████▎                     | 111/160 [00:02<00:00, 58.20it/s]2025-08-18 21:26:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 69.00 / 113 (61.1%):  70%|█████████████████████████████████████████████████▋                     | 112/160 [00:02<00:00, 58.20it/s]2025-08-18 21:26:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 70.00 / 114 (61.4%):  71%|██████████████████████████████████████████████████▏                    | 113/160 [00:02<00:00, 58.20it/s]2025-08-18 21:26:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 71.00 / 115 (61.7%):  71%|██████████████████████████████████████████████████▌                    | 114/160 [00:02<00:00, 58.20it/s]2025-08-18 21:26:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 72.00 / 116 (62.1%):  72%|███████████████████████████████████████████████████                    | 115/160 [00:02<00:00, 58.20it/s]2025-08-18 21:26:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 72.00 / 116 (62.1%):  72%|███████████████████████████████████████████████████▍                   | 116/160 [00:02<00:00, 56.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 72.00 / 117 (61.5%):  72%|███████████████████████████████████████████████████▍                   | 116/160 [00:02<00:00, 56.75it/s]2025-08-18 21:26:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 73.00 / 118 (61.9%):  73%|███████████████████████████████████████████████████▉                   | 117/160 [00:02<00:00, 56.75it/s]2025-08-18 21:26:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 74.00 / 119 (62.2%):  74%|████████████████████████████████████████████████████▎                  | 118/160 [00:02<00:00, 56.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 75.00 / 120 (62.5%):  74%|████████████████████████████████████████████████████▊                  | 119/160 [00:02<00:00, 56.75it/s]2025-08-18 21:26:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 75.00 / 121 (62.0%):  75%|█████████████████████████████████████████████████████▎                 | 120/160 [00:02<00:00, 56.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 76.00 / 122 (62.3%):  76%|█████████████████████████████████████████████████████▋                 | 121/160 [00:02<00:00, 56.75it/s]2025-08-18 21:26:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 77.00 / 123 (62.6%):  76%|██████████████████████████████████████████████████████▏                | 122/160 [00:02<00:00, 56.75it/s]2025-08-18 21:26:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 77.00 / 123 (62.6%):  77%|██████████████████████████████████████████████████████▌                | 123/160 [00:02<00:00, 49.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 78.00 / 124 (62.9%):  77%|██████████████████████████████████████████████████████▌                | 123/160 [00:02<00:00, 49.94it/s]2025-08-18 21:26:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 79.00 / 125 (63.2%):  78%|███████████████████████████████████████████████████████                | 124/160 [00:02<00:00, 49.94it/s]2025-08-18 21:26:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 80.00 / 126 (63.5%):  78%|███████████████████████████████████████████████████████▍               | 125/160 [00:02<00:00, 49.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 81.00 / 127 (63.8%):  79%|███████████████████████████████████████████████████████▉               | 126/160 [00:02<00:00, 49.94it/s]2025-08-18 21:26:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 82.00 / 128 (64.1%):  79%|████████████████████████████████████████████████████████▎              | 127/160 [00:02<00:00, 49.94it/s]2025-08-18 21:26:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 83.00 / 129 (64.3%):  80%|████████████████████████████████████████████████████████▊              | 128/160 [00:02<00:00, 49.94it/s]2025-08-18 21:26:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 83.00 / 129 (64.3%):  81%|█████████████████████████████████████████████████████████▏             | 129/160 [00:02<00:00, 49.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 84.00 / 130 (64.6%):  81%|█████████████████████████████████████████████████████████▏             | 129/160 [00:02<00:00, 49.62it/s]2025-08-18 21:26:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 84.00 / 131 (64.1%):  81%|█████████████████████████████████████████████████████████▋             | 130/160 [00:02<00:00, 49.62it/s]2025-08-18 21:26:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 84.00 / 132 (63.6%):  82%|██████████████████████████████████████████████████████████▏            | 131/160 [00:02<00:00, 49.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 84.00 / 133 (63.2%):  82%|██████████████████████████████████████████████████████████▌            | 132/160 [00:02<00:00, 49.62it/s]2025-08-18 21:26:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 85.00 / 134 (63.4%):  83%|███████████████████████████████████████████████████████████            | 133/160 [00:02<00:00, 49.62it/s]2025-08-18 21:26:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 86.00 / 135 (63.7%):  84%|███████████████████████████████████████████████████████████▍           | 134/160 [00:02<00:00, 49.62it/s]2025-08-18 21:26:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 86.00 / 136 (63.2%):  84%|███████████████████████████████████████████████████████████▉           | 135/160 [00:02<00:00, 49.62it/s]2025-08-18 21:26:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 87.00 / 137 (63.5%):  85%|████████████████████████████████████████████████████████████▎          | 136/160 [00:02<00:00, 49.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 88.00 / 138 (63.8%):  86%|████████████████████████████████████████████████████████████▊          | 137/160 [00:02<00:00, 49.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 89.00 / 139 (64.0%):  87%|█████████████████████████████████████████████████████████████▋         | 139/160 [00:02<00:00, 60.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 89.00 / 140 (63.6%):  87%|█████████████████████████████████████████████████████████████▋         | 139/160 [00:02<00:00, 60.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 90.00 / 141 (63.8%):  88%|██████████████████████████████████████████████████████████████▏        | 140/160 [00:03<00:00, 60.85it/s]2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 91.00 / 142 (64.1%):  88%|██████████████████████████████████████████████████████████████▌        | 141/160 [00:03<00:00, 60.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 91.00 / 143 (63.6%):  89%|███████████████████████████████████████████████████████████████        | 142/160 [00:03<00:00, 60.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 91.00 / 144 (63.2%):  89%|███████████████████████████████████████████████████████████████▍       | 143/160 [00:03<00:00, 60.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 92.00 / 145 (63.4%):  90%|███████████████████████████████████████████████████████████████▉       | 144/160 [00:03<00:00, 60.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 92.00 / 146 (63.0%):  91%|████████████████████████████████████████████████████████████████▊      | 146/160 [00:03<00:00, 51.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 92.00 / 147 (62.6%):  91%|████████████████████████████████████████████████████████████████▊      | 146/160 [00:03<00:00, 51.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 93.00 / 148 (62.8%):  92%|█████████████████████████████████████████████████████████████████▏     | 147/160 [00:03<00:00, 51.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 94.00 / 149 (63.1%):  92%|█████████████████████████████████████████████████████████████████▋     | 148/160 [00:03<00:00, 51.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 95.00 / 150 (63.3%):  93%|██████████████████████████████████████████████████████████████████     | 149/160 [00:03<00:00, 51.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 96.00 / 151 (63.6%):  94%|██████████████████████████████████████████████████████████████████▌    | 150/160 [00:03<00:00, 51.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 97.00 / 152 (63.8%):  95%|███████████████████████████████████████████████████████████████████▍   | 152/160 [00:03<00:00, 48.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 98.00 / 153 (64.1%):  95%|███████████████████████████████████████████████████████████████████▍   | 152/160 [00:03<00:00, 48.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 98.00 / 154 (63.6%):  96%|███████████████████████████████████████████████████████████████████▉   | 153/160 [00:03<00:00, 48.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 98.00 / 155 (63.2%):  96%|████████████████████████████████████████████████████████████████████▎  | 154/160 [00:03<00:00, 48.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 99.00 / 156 (63.5%):  97%|████████████████████████████████████████████████████████████████████▊  | 155/160 [00:03<00:00, 48.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 100.00 / 157 (63.7%):  98%|████████████████████████████████████████████████████████████████████▎ | 156/160 [00:03<00:00, 48.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 101.00 / 158 (63.9%):  99%|█████████████████████████████████████████████████████████████████████▏| 158/160 [00:03<00:00, 50.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 102.00 / 159 (64.2%):  99%|█████████████████████████████████████████████████████████████████████▏| 158/160 [00:03<00:00, 50.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:26:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:26:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 102.00 / 160 (63.8%): 100%|██████████████████████████████████████████████████████████████████████| 160/160 [00:03<00:00, 46.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/18 21:26:34 INFO dspy.evaluate.evaluate: Average Metric: 102 / 160 (63.8%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>example_satisfied</th>\n",
       "      <th>_id</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>pred_satisfied</th>\n",
       "      <th>match_judge_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Company: comcastcares Transcript so far: Customer: why can’t I wat...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_0</td>\n",
       "      <td>Agent is polite and asks clarifying questions.</td>\n",
       "      <td>True</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Company: AppleSupport Transcript so far: Customer: my phone just s...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_1</td>\n",
       "      <td>Good first response, polite and helpful.</td>\n",
       "      <td>True</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Company: AskLyft Transcript so far: Customer: This guy hops into m...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_2</td>\n",
       "      <td>The agent is polite and offers to help.  Good start.</td>\n",
       "      <td>True</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Company: SpotifyCares Transcript so far: Customer: will spotify re...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_3</td>\n",
       "      <td>Good response, polite and helpful, but doesn't offer any alternati...</td>\n",
       "      <td>True</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Company: VirginTrains Transcript so far: Customer: ...would then @...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_4</td>\n",
       "      <td>Agent is polite and helpful, trying to gather information to assist.</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Company: comcastcares Transcript so far: Customer: Hey @comcastcar...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_155</td>\n",
       "      <td>The agent's response is unprofessional and unhelpful. The customer...</td>\n",
       "      <td>False</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Company: O2 Transcript so far: Customer: why you closing Tu Go? Wo...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_156</td>\n",
       "      <td>The agent is polite and acknowledges the customer's feedback. Howe...</td>\n",
       "      <td>False</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Company: AirAsiaSupport Transcript so far: Customer: Dear @AirAsia...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_157</td>\n",
       "      <td>The agent is polite and asks for necessary information to help.</td>\n",
       "      <td>True</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Company: TacoBellTeam Transcript so far: Customer: I just had a te...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_158</td>\n",
       "      <td>Good response, polite, and offers a solution. Seeks more informati...</td>\n",
       "      <td>True</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Company: comcastcares Transcript so far: Customer: Yo connection i...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_159</td>\n",
       "      <td>Good first step, but needs more troubleshooting steps if restartin...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                transcript  \\\n",
       "0    Company: comcastcares Transcript so far: Customer: why can’t I wat...   \n",
       "1    Company: AppleSupport Transcript so far: Customer: my phone just s...   \n",
       "2    Company: AskLyft Transcript so far: Customer: This guy hops into m...   \n",
       "3    Company: SpotifyCares Transcript so far: Customer: will spotify re...   \n",
       "4    Company: VirginTrains Transcript so far: Customer: ...would then @...   \n",
       "..                                                                     ...   \n",
       "155  Company: comcastcares Transcript so far: Customer: Hey @comcastcar...   \n",
       "156  Company: O2 Transcript so far: Customer: why you closing Tu Go? Wo...   \n",
       "157  Company: AirAsiaSupport Transcript so far: Customer: Dear @AirAsia...   \n",
       "158  Company: TacoBellTeam Transcript so far: Customer: I just had a te...   \n",
       "159  Company: comcastcares Transcript so far: Customer: Yo connection i...   \n",
       "\n",
       "     example_satisfied          _id  \\\n",
       "0                 True    example_0   \n",
       "1                 True    example_1   \n",
       "2                 True    example_2   \n",
       "3                 True    example_3   \n",
       "4                False    example_4   \n",
       "..                 ...          ...   \n",
       "155              False  example_155   \n",
       "156              False  example_156   \n",
       "157               True  example_157   \n",
       "158               True  example_158   \n",
       "159               True  example_159   \n",
       "\n",
       "                                                                 reasoning  \\\n",
       "0                           Agent is polite and asks clarifying questions.   \n",
       "1                                 Good first response, polite and helpful.   \n",
       "2                     The agent is polite and offers to help.  Good start.   \n",
       "3    Good response, polite and helpful, but doesn't offer any alternati...   \n",
       "4     Agent is polite and helpful, trying to gather information to assist.   \n",
       "..                                                                     ...   \n",
       "155  The agent's response is unprofessional and unhelpful. The customer...   \n",
       "156  The agent is polite and acknowledges the customer's feedback. Howe...   \n",
       "157        The agent is polite and asks for necessary information to help.   \n",
       "158  Good response, polite, and offers a solution. Seeks more informati...   \n",
       "159  Good first step, but needs more troubleshooting steps if restartin...   \n",
       "\n",
       "    pred_satisfied match_judge_metric  \n",
       "0             True             ✔️ [1]  \n",
       "1             True             ✔️ [1]  \n",
       "2             True             ✔️ [1]  \n",
       "3             True             ✔️ [1]  \n",
       "4             True                     \n",
       "..             ...                ...  \n",
       "155          False             ✔️ [1]  \n",
       "156          False             ✔️ [1]  \n",
       "157           True             ✔️ [1]  \n",
       "158           True             ✔️ [1]  \n",
       "159          False                     \n",
       "\n",
       "[160 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluator = dspy.Evaluate(\n",
    "    metric=match_judge_metric,\n",
    "    devset=judge_dataset_examples,\n",
    "    display_table=True,\n",
    "    display_progress=True,\n",
    "    num_threads=24,\n",
    ")\n",
    "original_score = evaluator(generate_judge_reasoning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee0f2cb9-d115-4c27-b989-69551057bc9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.75"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b9575c-d4f5-4521-8ec8-a9b3540cfe48",
   "metadata": {},
   "source": [
    "## Check that we can get the same result using the parallel processor\n",
    "\n",
    "Why do we do this? We need to confirm that when we run the judge on the generator development dataset, we can reproduce the same behavior that we saw in judge development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e7e5148-fa0a-4103-b98d-52b5595cd02d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:20 - dspy_judge.processor.parallel_processor - INFO - Initialized ParallelProcessor with max_workers=4\n",
      "2025-08-18 21:28:20 - dspy_judge.processor.parallel_processor - INFO - Processing 160 examples with 4 workers using DSPy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing with DSPy:   0%|                                                                                                | 0/160 [00:00<?, ?it/s]\u001b[92m21:28:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:   1%|▌                                                                                       | 1/160 [00:03<09:43,  3.67s/it]\u001b[92m21:28:24 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:24 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:24 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:24 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:24 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:24 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:24 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:24 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:25 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:25 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:25 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Processing with DSPy:   3%|██▊                                                                                     | 5/160 [00:04<01:45,  1.48it/s]\u001b[92m21:28:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:25 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:25 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:25 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:25 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:25 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:25 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:25 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:25 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:25 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:   6%|████▉                                                                                   | 9/160 [00:04<00:56,  2.68it/s]\u001b[92m21:28:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:25 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:25 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:25 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:25 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:25 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:25 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:25 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:   8%|███████                                                                                | 13/160 [00:05<00:37,  3.92it/s]\u001b[92m21:28:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:26 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:26 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:25 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:25 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:25 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:26 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:26 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:26 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:26 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:26 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:26 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  11%|█████████▏                                                                             | 17/160 [00:05<00:28,  5.04it/s]\u001b[92m21:28:26 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:26 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:26 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:26 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:26 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:26 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:26 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:26 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:26 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:26 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:26 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:26 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:26 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:26 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  13%|███████████▍                                                                           | 21/160 [00:06<00:23,  5.83it/s]\u001b[92m21:28:26 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:26 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:26 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:26 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:26 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:27 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:26 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:26 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:26 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:26 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:26 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:26 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:26 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:27 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:27 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:27 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:27 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  16%|█████████████▌                                                                         | 25/160 [00:06<00:21,  6.36it/s]\u001b[92m21:28:27 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:27 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:27 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:27 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  18%|███████████████▏                                                                       | 28/160 [00:06<00:16,  8.01it/s]\u001b[92m21:28:27 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:27 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:27 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:27 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:27 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:27 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:27 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:27 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:27 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:27 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:27 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:27 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:27 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Processing with DSPy:  19%|████████████████▎                                                                      | 30/160 [00:07<00:18,  7.13it/s]\u001b[92m21:28:27 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:27 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:27 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:27 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:27 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:27 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:27 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:27 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:28 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:28 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  20%|█████████████████▍                                                                     | 32/160 [00:07<00:19,  6.47it/s]\u001b[92m21:28:28 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:28 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:28 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:28 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:28 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:28 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:28 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:28 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:28 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:28 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:28 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:28 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:28 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:28 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:28 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:28 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:28 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  22%|███████████████████▌                                                                   | 36/160 [00:08<00:17,  7.06it/s]\u001b[92m21:28:28 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:28 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:28 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:28 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:28 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:28 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:28 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:28 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:28 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:28 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:28 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:28 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:28 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:29 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:29 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:29 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  25%|█████████████████████▊                                                                 | 40/160 [00:08<00:15,  7.63it/s]\u001b[92m21:28:29 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:29 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:29 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:29 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:29 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:29 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:29 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:29 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:29 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:29 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:29 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:29 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:29 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:29 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  28%|███████████████████████▉                                                               | 44/160 [00:08<00:13,  8.50it/s]\u001b[92m21:28:29 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:29 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:29 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:29 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  28%|████████████████████████▍                                                              | 45/160 [00:08<00:13,  8.48it/s]\u001b[92m21:28:29 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:29 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:29 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:29 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:29 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:29 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:29 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:29 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:29 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:29 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:29 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:30 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  30%|██████████████████████████                                                             | 48/160 [00:09<00:13,  8.58it/s]\u001b[92m21:28:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:30 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:30 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  31%|███████████████████████████▏                                                           | 50/160 [00:09<00:11,  9.52it/s]\u001b[92m21:28:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:30 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:30 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:30 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:30 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:30 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:30 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:30 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  32%|████████████████████████████▎                                                          | 52/160 [00:09<00:12,  8.43it/s]\u001b[92m21:28:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:30 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:30 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  34%|█████████████████████████████▉                                                         | 55/160 [00:09<00:09, 11.13it/s]\u001b[92m21:28:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:30 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:30 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:30 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:30 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:30 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  36%|██████████████████████████████▉                                                        | 57/160 [00:10<00:12,  8.24it/s]\u001b[92m21:28:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:30 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  38%|████████████████████████████████▋                                                      | 60/160 [00:10<00:12,  8.01it/s]\u001b[92m21:28:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  39%|██████████████████████████████████▎                                                    | 63/160 [00:10<00:09, 10.24it/s]\u001b[92m21:28:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  41%|███████████████████████████████████▎                                                   | 65/160 [00:11<00:11,  8.23it/s]\u001b[92m21:28:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  42%|████████████████████████████████████▉                                                  | 68/160 [00:11<00:11,  7.89it/s]\u001b[92m21:28:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  45%|███████████████████████████████████████▏                                               | 72/160 [00:12<00:10,  8.43it/s]\u001b[92m21:28:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  47%|████████████████████████████████████████▊                                              | 75/160 [00:12<00:08, 10.13it/s]\u001b[92m21:28:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  48%|█████████████████████████████████████████▊                                             | 77/160 [00:12<00:09,  9.10it/s]\u001b[92m21:28:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  49%|██████████████████████████████████████████▉                                            | 79/160 [00:12<00:08,  9.39it/s]\u001b[92m21:28:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  51%|████████████████████████████████████████████                                           | 81/160 [00:13<00:09,  7.98it/s]\u001b[92m21:28:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  52%|█████████████████████████████████████████████▏                                         | 83/160 [00:13<00:08,  9.20it/s]\u001b[92m21:28:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:34 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  53%|██████████████████████████████████████████████▏                                        | 85/160 [00:13<00:09,  7.88it/s]\u001b[92m21:28:34 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:34 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:34 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:34 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  54%|███████████████████████████████████████████████▎                                       | 87/160 [00:13<00:07,  9.20it/s]\u001b[92m21:28:34 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:34 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:34 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:34 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:34 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  56%|████████████████████████████████████████████████▍                                      | 89/160 [00:14<00:09,  7.75it/s]\u001b[92m21:28:34 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:34 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:34 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:34 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:34 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:34 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  57%|██████████████████████████████████████████████████                                     | 92/160 [00:14<00:07,  9.30it/s]\u001b[92m21:28:35 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:35 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:35 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:35 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Processing with DSPy:  59%|███████████████████████████████████████████████████                                    | 94/160 [00:14<00:07,  8.67it/s]\u001b[92m21:28:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:35 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:35 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:35 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:35 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  60%|████████████████████████████████████████████████████▏                                  | 96/160 [00:14<00:07,  8.92it/s]\u001b[92m21:28:35 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  61%|████████████████████████████████████████████████████▋                                  | 97/160 [00:14<00:07,  8.24it/s]\u001b[92m21:28:35 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:35 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:35 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:35 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:35 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:35 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:35 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  62%|█████████████████████████████████████████████████████▊                                | 100/160 [00:15<00:06,  9.10it/s]\u001b[92m21:28:35 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:35 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:36 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:36 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  63%|██████████████████████████████████████████████████████▎                               | 101/160 [00:15<00:07,  7.60it/s]\u001b[92m21:28:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:36 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:36 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:36 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:36 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:36 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  65%|███████████████████████████████████████████████████████▉                              | 104/160 [00:15<00:05,  9.44it/s]\u001b[92m21:28:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:36 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  66%|████████████████████████████████████████████████████████▍                             | 105/160 [00:15<00:06,  8.47it/s]\u001b[92m21:28:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:36 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:36 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:36 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:36 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:36 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:36 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:36 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  68%|██████████████████████████████████████████████████████████                            | 108/160 [00:16<00:05,  9.19it/s]\u001b[92m21:28:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  68%|██████████████████████████████████████████████████████████▌                           | 109/160 [00:16<00:05,  8.76it/s]\u001b[92m21:28:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:36 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  70%|████████████████████████████████████████████████████████████▏                         | 112/160 [00:16<00:05,  8.19it/s]\u001b[92m21:28:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  72%|█████████████████████████████████████████████████████████████▊                        | 115/160 [00:16<00:04, 10.09it/s]\u001b[92m21:28:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  73%|██████████████████████████████████████████████████████████████▉                       | 117/160 [00:17<00:05,  8.20it/s]\u001b[92m21:28:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  75%|████████████████████████████████████████████████████████████████▌                     | 120/160 [00:17<00:04,  9.02it/s]\u001b[92m21:28:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  76%|█████████████████████████████████████████████████████████████████                     | 121/160 [00:17<00:04,  8.12it/s]\u001b[92m21:28:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  78%|██████████████████████████████████████████████████████████████████▋                   | 124/160 [00:17<00:03,  9.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  79%|███████████████████████████████████████████████████████████████████▋                  | 126/160 [00:18<00:03,  9.14it/s]\u001b[92m21:28:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:39 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  80%|████████████████████████████████████████████████████████████████████▊                 | 128/160 [00:18<00:03,  9.34it/s]\u001b[92m21:28:39 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:39 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:39 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:39 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  81%|█████████████████████████████████████████████████████████████████████▎                | 129/160 [00:18<00:03,  8.09it/s]\u001b[92m21:28:39 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:39 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:39 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:39 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  82%|██████████████████████████████████████████████████████████████████████▍               | 131/160 [00:18<00:03,  9.19it/s]\u001b[92m21:28:39 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:39 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:39 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:39 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:39 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:39 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:39 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:39 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  82%|██████████████████████████████████████████████████████████████████████▉               | 132/160 [00:18<00:03,  8.12it/s]\u001b[92m21:28:39 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:39 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:39 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:39 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  84%|████████████████████████████████████████████████████████████████████████              | 134/160 [00:19<00:02,  8.90it/s]\u001b[92m21:28:39 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:39 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:39 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:39 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:39 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:39 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:39 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:39 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:39 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:39 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:39 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:40 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:40 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  85%|█████████████████████████████████████████████████████████████████████████             | 136/160 [00:19<00:03,  7.24it/s]\u001b[92m21:28:40 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:40 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:40 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:40 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:40 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:40 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:40 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:40 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:40 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:40 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:40 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:40 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:40 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:40 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:40 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:40 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:40 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  88%|███████████████████████████████████████████████████████████████████████████▎          | 140/160 [00:19<00:02,  8.12it/s]\u001b[92m21:28:40 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:40 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:40 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:40 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:40 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:40 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:40 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:40 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:40 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:40 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:40 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:40 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:40 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:41 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:41 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  90%|█████████████████████████████████████████████████████████████████████████████▍        | 144/160 [00:20<00:01,  8.21it/s]\u001b[92m21:28:41 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:41 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:41 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:41 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:41 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:41 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:41 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:41 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:41 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:41 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:41 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:41 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:41 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:41 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:41 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:41 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:41 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:41 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:41 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Processing with DSPy:  92%|███████████████████████████████████████████████████████████████████████████████▌      | 148/160 [00:20<00:01,  8.19it/s]\u001b[92m21:28:41 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:41 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:41 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:41 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:41 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:41 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:41 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:41 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:41 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:41 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:41 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:42 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:42 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:42 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  95%|█████████████████████████████████████████████████████████████████████████████████▋    | 152/160 [00:21<00:00,  8.27it/s]\u001b[92m21:28:42 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:42 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:42 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:42 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:42 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:42 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:42 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:42 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:42 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:42 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:42 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:42 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:42 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:42 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:42 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:28:42 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:28:42 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  98%|███████████████████████████████████████████████████████████████████████████████████▊  | 156/160 [00:21<00:00,  7.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:42 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:42 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:28:42 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:28:42 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:42 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  98%|████████████████████████████████████████████████████████████████████████████████████▍ | 157/160 [00:22<00:00,  7.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:42 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:28:43 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy: 100%|██████████████████████████████████████████████████████████████████████████████████████| 160/160 [00:22<00:00,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:28:43 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dspy_judge_config = {\n",
    "  \"model_name\":\"gemini/gemini-1.5-flash\",\n",
    "  \"api_key\":secrets[\"GEMINI_API_KEY\"],\n",
    "  \"temperature\": 0\n",
    "}\n",
    "\n",
    "dspy_judge_processor = ParallelProcessor()\n",
    "\n",
    "dspy_judge_results = dspy_judge_processor.process_dataset_with_dspy(\n",
    "  dspy_gold_standard_judge_results.select_columns(\n",
    "    [\"conversation_id\",\"output_transcript\"]\n",
    "  ),\n",
    "  input_field=\"output_transcript\",\n",
    "  dspy_module=generate_judge_reasoning,\n",
    "  dspy_config=dspy_judge_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58f666b2-733d-4c36-967a-1d5ac0035d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 160/160 [00:00<00:00, 12287.85 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dspy_judge_results = dspy_judge_results.map(\n",
    "    extract_llm_response_fields_dspy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18ab029b-7209-4f90-8517-2402fae62d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.625\n"
     ]
    }
   ],
   "source": [
    "# this results\n",
    "baseline_result = dspy_judge_results.to_pandas()[[\"conversation_id\",\"satisfied\"]].rename(\n",
    "    columns={\n",
    "        \"satisfied\":\"prediction\"\n",
    "    }\n",
    ")\n",
    "# gold standard result\n",
    "gold_standard_result = dspy_gold_standard_judge_results.to_pandas()[[\"conversation_id\",\"satisfied\"]].rename(\n",
    "    columns={\n",
    "        \"satisfied\":\"gold_standard\"\n",
    "    }\n",
    ")\n",
    "full_result = baseline_result.merge(\n",
    "    gold_standard_result,on=[\"conversation_id\"]\n",
    ")\n",
    "full_result[\"prediction\"] = full_result[\"prediction\"].astype(bool).astype(int)\n",
    "full_result[\"gold_standard\"] = full_result[\"gold_standard\"].astype(bool).astype(int)\n",
    "\n",
    "print(\n",
    "    np.mean(full_result[\"prediction\"] == full_result[\"gold_standard\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36d5c18e-dc94-42f6-a2d0-171855b07785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>prediction</th>\n",
       "      <th>gold_standard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e00df253bdf3982e03cd40492adec1b2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2406637ae84c0ebb6360b3d8b6833c18</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b29e31d85bd13a9858dcfe404b916c9b</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9d327061f2eef35d13a53b27056cb570</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>412301454090d60344e086faf8a54906</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>863e5e924cf0bf1570632e063d947bb1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>45880015b822774c2bd3e21892c4d693</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>06e264c73b83e48dd09ef9c4d904a9a2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>a7463742fbf1879675ef86ab89c41c47</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>8520f93f8222ea13bb345581c389450e</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      conversation_id prediction  gold_standard\n",
       "0    e00df253bdf3982e03cd40492adec1b2       True           True\n",
       "1    2406637ae84c0ebb6360b3d8b6833c18       True           True\n",
       "2    b29e31d85bd13a9858dcfe404b916c9b       True           True\n",
       "3    9d327061f2eef35d13a53b27056cb570       True           True\n",
       "4    412301454090d60344e086faf8a54906       True          False\n",
       "..                                ...        ...            ...\n",
       "155  863e5e924cf0bf1570632e063d947bb1      False          False\n",
       "156  45880015b822774c2bd3e21892c4d693      False          False\n",
       "157  06e264c73b83e48dd09ef9c4d904a9a2       True           True\n",
       "158  a7463742fbf1879675ef86ab89c41c47       True           True\n",
       "159  8520f93f8222ea13bb345581c389450e      False           True\n",
       "\n",
       "[160 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ecffb5-4099-42b3-acb5-b63af1242217",
   "metadata": {},
   "source": [
    "## Crude test train split for judge training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93ef21db-067e-4591-b7f9-bb4a9544f948",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = judge_dataset_examples[:110]\n",
    "validation_set = judge_dataset_examples[110:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8582cdd3-5760-4d90-918a-70c57e2f3377",
   "metadata": {},
   "source": [
    "## Run the optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dae7cb33-ec87-4508-9c68-0e9eecddc2a6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/18 21:31:57 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "RUNNING WITH THE FOLLOWING MEDIUM AUTO RUN SETTINGS:\n",
      "num_trials: 18\n",
      "minibatch: False\n",
      "num_fewshot_candidates: 12\n",
      "num_instruct_candidates: 6\n",
      "valset size: 50\n",
      "\n",
      "2025/08/18 21:31:57 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n",
      "2025/08/18 21:31:57 INFO dspy.teleprompt.mipro_optimizer_v2: These will be used as few-shot example candidates for our program and for creating instructions.\n",
      "\n",
      "2025/08/18 21:31:57 INFO dspy.teleprompt.mipro_optimizer_v2: Bootstrapping N=12 sets of demonstrations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping set 1/12\n",
      "Bootstrapping set 2/12\n",
      "Bootstrapping set 3/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                      | 0/110 [00:00<?, ?it/s]\u001b[92m21:31:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:31:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:31:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:31:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█                                                                                                             | 1/110 [00:00<00:52,  2.06it/s]\u001b[92m21:31:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:31:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:31:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:31:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██                                                                                                            | 2/110 [00:01<01:19,  1.35it/s]\u001b[92m21:31:58 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:31:58 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:31:59 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:31:59 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███                                                                                                           | 3/110 [00:01<01:03,  1.68it/s]\u001b[92m21:31:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:31:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:31:59 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:31:59 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|████                                                                                                          | 4/110 [00:02<01:00,  1.75it/s]\u001b[92m21:31:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:31:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█████                                                                                                         | 5/110 [00:02<01:01,  1.70it/s]\u001b[92m21:32:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██████                                                                                                        | 6/110 [00:03<00:55,  1.87it/s]\u001b[92m21:32:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██████▉                                                                                                       | 7/110 [00:03<00:55,  1.85it/s]\u001b[92m21:32:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|████████                                                                                                      | 8/110 [00:04<00:51,  1.98it/s]\u001b[92m21:32:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|█████████                                                                                                     | 9/110 [00:04<00:54,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 9 examples for up to 1 rounds, amounting to 9 attempts.\n",
      "Bootstrapping set 4/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                      | 0/110 [00:00<?, ?it/s]\u001b[92m21:32:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█                                                                                                             | 1/110 [00:00<00:50,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Bootstrapping set 5/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                      | 0/110 [00:00<?, ?it/s]\u001b[92m21:32:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█                                                                                                             | 1/110 [00:00<00:53,  2.02it/s]\u001b[92m21:32:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██                                                                                                            | 2/110 [00:01<00:56,  1.91it/s]\u001b[92m21:32:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███                                                                                                           | 3/110 [00:01<01:01,  1.74it/s]\u001b[92m21:32:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|████                                                                                                          | 4/110 [00:02<00:56,  1.89it/s]\u001b[92m21:32:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█████                                                                                                         | 5/110 [00:02<00:54,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 5 examples for up to 1 rounds, amounting to 5 attempts.\n",
      "Bootstrapping set 6/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                      | 0/110 [00:00<?, ?it/s]\u001b[92m21:32:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█                                                                                                             | 1/110 [00:00<00:55,  1.95it/s]\u001b[92m21:32:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:06 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:06 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██                                                                                                            | 2/110 [00:00<00:50,  2.13it/s]\u001b[92m21:32:06 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:06 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:06 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:06 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███                                                                                                           | 3/110 [00:01<00:50,  2.14it/s]\u001b[92m21:32:06 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:06 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:07 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:07 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|████                                                                                                          | 4/110 [00:01<00:49,  2.12it/s]\u001b[92m21:32:07 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:07 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:07 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:07 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█████                                                                                                         | 5/110 [00:02<00:49,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 5 examples for up to 1 rounds, amounting to 5 attempts.\n",
      "Bootstrapping set 7/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                      | 0/110 [00:00<?, ?it/s]\u001b[92m21:32:07 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:07 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:07 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:07 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█                                                                                                             | 1/110 [00:00<00:42,  2.57it/s]\u001b[92m21:32:07 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:07 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██                                                                                                            | 2/110 [00:00<00:44,  2.42it/s]\u001b[92m21:32:08 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:08 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███                                                                                                           | 3/110 [00:01<00:49,  2.18it/s]\u001b[92m21:32:08 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:08 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:09 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:09 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|████                                                                                                          | 4/110 [00:01<00:51,  2.04it/s]\u001b[92m21:32:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:09 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:09 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█████                                                                                                         | 5/110 [00:02<00:50,  2.08it/s]\u001b[92m21:32:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██████                                                                                                        | 6/110 [00:02<00:48,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 6 examples for up to 1 rounds, amounting to 6 attempts.\n",
      "Bootstrapping set 8/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                      | 0/110 [00:00<?, ?it/s]\u001b[92m21:32:10 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:10 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█                                                                                                             | 1/110 [00:00<00:57,  1.89it/s]\u001b[92m21:32:10 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:10 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:11 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:11 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██                                                                                                            | 2/110 [00:01<00:54,  1.97it/s]\u001b[92m21:32:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:11 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:11 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███                                                                                                           | 3/110 [00:01<00:54,  1.97it/s]\u001b[92m21:32:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:12 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:12 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|████                                                                                                          | 4/110 [00:01<00:52,  2.03it/s]\u001b[92m21:32:12 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:12 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:12 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:12 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█████                                                                                                         | 5/110 [00:02<00:51,  2.05it/s]\u001b[92m21:32:12 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:12 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:13 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:13 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██████                                                                                                        | 6/110 [00:02<00:49,  2.11it/s]\u001b[92m21:32:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:13 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:13 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██████▉                                                                                                       | 7/110 [00:03<00:49,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 7 examples for up to 1 rounds, amounting to 7 attempts.\n",
      "Bootstrapping set 9/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                      | 0/110 [00:00<?, ?it/s]\u001b[92m21:32:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:14 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:14 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█                                                                                                             | 1/110 [00:00<00:58,  1.88it/s]\u001b[92m21:32:14 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:14 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:14 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:14 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██                                                                                                            | 2/110 [00:00<00:51,  2.10it/s]\u001b[92m21:32:14 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:14 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:15 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:15 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███                                                                                                           | 3/110 [00:01<00:52,  2.05it/s]\u001b[92m21:32:15 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:15 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:15 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:15 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|████                                                                                                          | 4/110 [00:01<00:52,  2.03it/s]\u001b[92m21:32:15 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:15 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:16 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:16 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█████                                                                                                         | 5/110 [00:02<00:54,  1.93it/s]\u001b[92m21:32:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:16 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:16 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██████                                                                                                        | 6/110 [00:02<00:50,  2.08it/s]\u001b[92m21:32:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██████▉                                                                                                       | 7/110 [00:03<00:50,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 7 examples for up to 1 rounds, amounting to 7 attempts.\n",
      "Bootstrapping set 10/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                      | 0/110 [00:00<?, ?it/s]\u001b[92m21:32:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█                                                                                                             | 1/110 [00:00<00:50,  2.14it/s]\u001b[92m21:32:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██                                                                                                            | 2/110 [00:01<00:55,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Bootstrapping set 11/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                      | 0/110 [00:00<?, ?it/s]\u001b[92m21:32:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█                                                                                                             | 1/110 [00:00<00:46,  2.33it/s]\u001b[92m21:32:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:19 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:19 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██                                                                                                            | 2/110 [00:00<00:49,  2.18it/s]\u001b[92m21:32:19 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:19 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:19 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:19 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███                                                                                                           | 3/110 [00:01<00:48,  2.20it/s]\u001b[92m21:32:19 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:19 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:19 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:19 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|████                                                                                                          | 4/110 [00:01<00:50,  2.08it/s]\u001b[92m21:32:19 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:19 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:20 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:20 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█████                                                                                                         | 5/110 [00:02<00:55,  1.90it/s]\u001b[92m21:32:20 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:20 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:21 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:21 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██████                                                                                                        | 6/110 [00:02<00:50,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 6 examples for up to 1 rounds, amounting to 6 attempts.\n",
      "Bootstrapping set 12/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                      | 0/110 [00:00<?, ?it/s]\u001b[92m21:32:21 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:21 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:21 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:21 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█                                                                                                             | 1/110 [00:00<00:53,  2.02it/s]\u001b[92m21:32:21 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:21 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██                                                                                                            | 2/110 [00:00<00:52,  2.06it/s]\u001b[92m21:32:22 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:22 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███                                                                                                           | 3/110 [00:01<00:53,  2.01it/s]\u001b[92m21:32:22 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:22 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:23 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:23 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|████                                                                                                          | 4/110 [00:02<00:55,  1.90it/s]\n",
      "2025/08/18 21:32:23 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 2: PROPOSE INSTRUCTION CANDIDATES <==\n",
      "2025/08/18 21:32:23 INFO dspy.teleprompt.mipro_optimizer_v2: We will use the few-shot examples from the previous step, a generated dataset summary, a summary of the program code, and a randomly selected prompting tip to propose instructions.\n",
      "\u001b[92m21:32:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 4 examples for up to 1 rounds, amounting to 4 attempts.\n",
      "2025-08-18 21:32:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:24 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:24 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:25 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:25 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:26 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:26 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:26 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:26 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:26 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:26 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:26 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:26 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:26 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:26 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:26 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:26 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:27 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:27 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:27 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:27 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:27 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:27 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:27 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:27 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:28 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:28 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/18 21:32:28 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "Proposing N=6 instructions...\n",
      "\n",
      "\u001b[92m21:32:28 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:28 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:29 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:29 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:29 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:29 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:30 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:30 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:34 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:34 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:39 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:39 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:39 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:39 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:41 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:41 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:41 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:41 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:42 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:42 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:42 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:42 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:43 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:43 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:43 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:43 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:44 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:44 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:44 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:44 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:45 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:45 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:45 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:45 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:46 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:46 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:46 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:46 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:50 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:50 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:50 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:50 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:51 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:51 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:51 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:51 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/18 21:32:52 INFO dspy.teleprompt.mipro_optimizer_v2: Proposed Instructions for Predictor 0:\n",
      "\n",
      "2025/08/18 21:32:52 INFO dspy.teleprompt.mipro_optimizer_v2: 0: You are a very experienced customer service agent who has worked in multiple industries and understands how to address\n",
      "a very large range of issues. Your task is to help train more junior customer service agents by looking at how they responded \n",
      "to real queries and judging whether or not the interaction was successful. \n",
      "A successful interaction is somewhat subjective and you will lean on your expertise when making the judgment. In general, the\n",
      "responses from the agent being judged should:\n",
      "1. Provide a solid answer to the question if one is asked. If the agent doesn't know the answer, or there is no clear answer, that's OK, \n",
      "but the agent should clearly explain that they don't know and offer suggestions for where to find more information. \n",
      "2. The agent's response should always be polite and understanding, even if the customer is angry.\n",
      "3. Sometimes customers make comments that can't really be acted upon. In these situations, the agent's response should be appropriate, expressing\n",
      "thanks for the feedback, apologizing for any failures, and being supportive of any issues.\n",
      "4. The responses should be concise. Complicated issues should be sufficiently explained without excessive verbosity.\n",
      "Put yourself in the customer's shoes when reading the agent's responses. How would they react to what they read? Would they have had a \n",
      "positive or negative experience? \n",
      "When reading, pay most attention to the agent's most recent response since this is the one that the customer will be reading right now.\n",
      "Use the other parts of the conversation as useful context. You'll also be told the company that the agent works for, which may help you\n",
      "understand the types of issues that they deal with.\n",
      "You must provide an indication of whether or not you are satisfied with the agent's response, and a short explanation for your\n",
      "reasoning. Your indication can only be True or False, and your explanation should be fewer than 20 words.\n",
      "\n",
      "2025/08/18 21:32:52 INFO dspy.teleprompt.mipro_optimizer_v2: 1: You are a seasoned customer service expert with years of experience across diverse industries.  Your task is to evaluate the quality of customer service interactions based on provided transcripts.  Analyze each transcript, paying close attention to the agent's last response and the overall conversation flow.  Consider the following criteria when making your judgment:\n",
      "\n",
      "* **Effectiveness:** Did the agent adequately address the customer's issue or concern?\n",
      "* **Politeness and Empathy:** Was the agent's tone polite, understanding, and empathetic, regardless of the customer's demeanor?\n",
      "* **Conciseness:** Was the agent's response clear, concise, and easy to understand?\n",
      "* **Accuracy and Information:** Did the agent provide accurate information, and if not, did they appropriately explain why and offer alternative solutions?\n",
      "* **Professionalism:** Did the agent maintain a professional and helpful demeanor throughout the interaction?\n",
      "\n",
      "Based on your evaluation, provide a judgment of whether the agent's response was satisfactory and include a concise explanation (under 20 words) supporting your assessment.  Your judgment should be either \"True\" (satisfactory) or \"False\" (unsatisfactory).  The company name will be provided for context.\n",
      "\n",
      "Example:\n",
      "\n",
      "Transcript: Company: AcmeCorp\n",
      "Transcript so far: Customer: My order never arrived.  Agent: I'm so sorry to hear that! I've issued a refund and you'll receive confirmation shortly.\n",
      "\n",
      "Judgment: True\n",
      "Reasoning: Prompt resolution, empathetic response.\n",
      "\n",
      "2025/08/18 21:32:52 INFO dspy.teleprompt.mipro_optimizer_v2: 2: You are a seasoned customer service expert responsible for evaluating the performance of junior agents.  A crucial client is on the line, their business is at stake, and their satisfaction directly impacts your team's bonus. You must analyze the following customer service interaction transcript, ensuring that any misjudgment will result in significant financial consequences.  This is a high-stakes evaluation. Use your extensive experience to assess the agent's response using these key criteria:\n",
      "\n",
      "1. **Comprehensive Answer:** Does the agent provide a satisfactory solution or clearly state the limitations and suggest viable alternatives?\n",
      "2. **Politeness & Understanding:** Is the agent consistently courteous and empathetic, even if the customer is upset?\n",
      "3. **Handling Unsolvable Issues:** If the problem is beyond the agent's control, does the agent acknowledge the issue, express support, and apologize where necessary?\n",
      "4. **Conciseness & Clarity:** Is the response clear and concise, without unnecessary verbosity or complexity?\n",
      "\n",
      "**Remember:** Consider the customer's perspective. Would they feel satisfied and supported? Your judgment directly impacts the agent's performance review and your team's financial reward. Analyze the transcript and provide:\n",
      "\n",
      "* **Satisfied:** (True/False) - Your evaluation of the agent's success\n",
      "* **Reasoning:** (Under 20 words) - A concise explanation for your decision\n",
      "\n",
      "2025/08/18 21:32:52 INFO dspy.teleprompt.mipro_optimizer_v2: 3: You are a seasoned customer service expert with a decade of experience across diverse industries.  Your role is to evaluate the quality of customer service interactions by reviewing transcripts.  Focus on the agent's last response, considering the entire conversation for context.  Assess whether the agent was polite, helpful, clear, and concise.  Was the customer's need addressed satisfactorily? Your judgment should be based on what a customer would experience. Respond with 'Satisfied: True' or 'Satisfied: False', followed by a concise explanation (under 20 words) justifying your assessment.\n",
      "\n",
      "2025/08/18 21:32:52 INFO dspy.teleprompt.mipro_optimizer_v2: 4: You are an expert customer service evaluator. Assess the following customer service interaction transcript.  Determine if the agent's response was satisfactory. Respond with a JSON object containing:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"satisfied\": true or false,\n",
      "  \"reasoning\": \"Your concise reasoning (under 20 words)\"\n",
      "}\n",
      "```\n",
      "\n",
      "Consider the following criteria:\n",
      "\n",
      "* **Politeness and Empathy:** Did the agent demonstrate understanding and respect?\n",
      "* **Helpfulness:** Did the agent provide a useful response or solution?\n",
      "* **Clarity:** Was the response easy to understand and free of jargon?\n",
      "* **Conciseness:** Was the response efficient and avoid overly verbose explanations?\n",
      "\n",
      "Focus on the agent's last response, using earlier turns as context. The company name is provided for background information.\n",
      "\n",
      "Example:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"transcript\": \"Company: SpotifyCares\\nCustomer: My premium account was stolen!\\nAgent: I'm sorry to hear that.  To help, please provide your username or email.\",\n",
      "  \"satisfied\": true,\n",
      "  \"reasoning\": \"Polite, helpful, and efficient.\"\n",
      "}\n",
      "```\n",
      "\n",
      "2025/08/18 21:32:52 INFO dspy.teleprompt.mipro_optimizer_v2: 5: You are an expert in customer service, evaluating agent-customer interactions.  Assess the agent's response in the provided transcript, considering politeness, helpfulness, conciseness, and understanding.  Is the agent's response satisfactory?  (True/False). Justify your answer in under 20 words.  Context: The company is [Company Name]. Transcript:\n",
      "[Transcript]\n",
      "\n",
      "2025/08/18 21:32:52 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/08/18 21:32:52 INFO dspy.teleprompt.mipro_optimizer_v2: ==> STEP 3: FINDING OPTIMAL PROMPT PARAMETERS <==\n",
      "2025/08/18 21:32:52 INFO dspy.teleprompt.mipro_optimizer_v2: We will evaluate the program over a series of trials with different combinations of instructions and few-shot examples to find the optimal combination using Bayesian Optimization.\n",
      "\n",
      "2025/08/18 21:32:52 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 1 / 18 - Full Evaluation of Default Program ==\n",
      "\u001b[92m21:32:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                       | 0/50 [00:00<?, ?it/s]2025-08-18 21:32:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 1 (100.0%):   2%|█▌                                                                          | 1/50 [00:00<00:24,  2.02it/s]2025-08-18 21:32:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 2 (50.0%):   2%|█▌                                                                           | 1/50 [00:00<00:24,  2.02it/s]2025-08-18 21:32:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 2.00 / 3 (66.7%):   4%|███                                                                          | 2/50 [00:00<00:23,  2.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 4 (75.0%):   6%|████▌                                                                        | 3/50 [00:00<00:23,  2.02it/s]2025-08-18 21:32:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 3.00 / 5 (60.0%):   8%|██████▏                                                                      | 4/50 [00:00<00:22,  2.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 6 (66.7%):  10%|███████▋                                                                     | 5/50 [00:00<00:22,  2.02it/s]2025-08-18 21:32:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 7 (57.1%):  12%|█████████▏                                                                   | 6/50 [00:00<00:21,  2.02it/s]2025-08-18 21:32:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 8 (50.0%):  14%|██████████▊                                                                  | 7/50 [00:00<00:21,  2.02it/s]2025-08-18 21:32:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 9 (55.6%):  16%|████████████▎                                                                | 8/50 [00:00<00:20,  2.02it/s]2025-08-18 21:32:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 5.00 / 9 (55.6%):  18%|█████████████▊                                                               | 9/50 [00:00<00:03, 11.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 6.00 / 10 (60.0%):  18%|█████████████▋                                                              | 9/50 [00:00<00:03, 11.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 7.00 / 11 (63.6%):  20%|███████████████                                                            | 10/50 [00:00<00:03, 11.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 12 (66.7%):  22%|████████████████▌                                                          | 11/50 [00:00<00:03, 11.37it/s]2025-08-18 21:32:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 9.00 / 13 (69.2%):  24%|██████████████████                                                         | 12/50 [00:00<00:03, 11.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 14 (71.4%):  26%|███████████████████▏                                                      | 13/50 [00:00<00:03, 11.37it/s]2025-08-18 21:32:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 10.00 / 15 (66.7%):  28%|████████████████████▋                                                     | 14/50 [00:00<00:03, 11.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 11.00 / 16 (68.8%):  30%|██████████████████████▏                                                   | 15/50 [00:01<00:03, 11.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 17 (70.6%):  32%|███████████████████████▋                                                  | 16/50 [00:01<00:02, 11.37it/s]2025-08-18 21:32:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 17 (70.6%):  34%|█████████████████████████▏                                                | 17/50 [00:01<00:02, 13.51it/s]2025-08-18 21:32:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 13.00 / 18 (72.2%):  34%|█████████████████████████▏                                                | 17/50 [00:01<00:02, 13.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 19 (73.7%):  36%|██████████████████████████▋                                               | 18/50 [00:01<00:02, 13.51it/s]2025-08-18 21:32:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 14.00 / 20 (70.0%):  38%|████████████████████████████                                              | 19/50 [00:01<00:02, 13.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 21 (71.4%):  40%|█████████████████████████████▌                                            | 20/50 [00:01<00:02, 13.51it/s]2025-08-18 21:32:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 22 (72.7%):  42%|███████████████████████████████                                           | 21/50 [00:01<00:02, 13.51it/s]2025-08-18 21:32:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 23 (73.9%):  44%|████████████████████████████████▌                                         | 22/50 [00:01<00:02, 13.51it/s]2025-08-18 21:32:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 24 (75.0%):  46%|██████████████████████████████████                                        | 23/50 [00:01<00:01, 13.51it/s]2025-08-18 21:32:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 18.00 / 24 (75.0%):  48%|███████████████████████████████████▌                                      | 24/50 [00:01<00:01, 19.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 25 (76.0%):  48%|███████████████████████████████████▌                                      | 24/50 [00:01<00:01, 19.17it/s]2025-08-18 21:32:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:32:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 20.00 / 26 (76.9%):  50%|█████████████████████████████████████                                     | 25/50 [00:01<00:01, 19.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 20.00 / 27 (74.1%):  52%|██████████████████████████████████████▍                                   | 26/50 [00:01<00:01, 19.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 27 (74.1%):  54%|███████████████████████████████████████▉                                  | 27/50 [00:01<00:01, 16.02it/s]2025-08-18 21:32:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 28 (71.4%):  54%|███████████████████████████████████████▉                                  | 27/50 [00:01<00:01, 16.02it/s]2025-08-18 21:32:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:32:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 21.00 / 29 (72.4%):  56%|█████████████████████████████████████████▍                                | 28/50 [00:01<00:01, 16.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 30 (73.3%):  58%|██████████████████████████████████████████▉                               | 29/50 [00:01<00:01, 16.02it/s]2025-08-18 21:32:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 31 (74.2%):  60%|████████████████████████████████████████████▍                             | 30/50 [00:01<00:01, 16.02it/s]2025-08-18 21:32:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 32 (71.9%):  62%|█████████████████████████████████████████████▉                            | 31/50 [00:02<00:01, 16.02it/s]2025-08-18 21:32:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 23.00 / 32 (71.9%):  64%|███████████████████████████████████████████████▎                          | 32/50 [00:02<00:00, 19.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 33 (72.7%):  64%|███████████████████████████████████████████████▎                          | 32/50 [00:02<00:00, 19.54it/s]2025-08-18 21:32:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.00 / 34 (73.5%):  66%|████████████████████████████████████████████████▊                         | 33/50 [00:02<00:00, 19.54it/s]2025-08-18 21:32:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 26.00 / 35 (74.3%):  68%|██████████████████████████████████████████████████▎                       | 34/50 [00:02<00:00, 19.54it/s]2025-08-18 21:32:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 26.00 / 35 (74.3%):  70%|███████████████████████████████████████████████████▊                      | 35/50 [00:02<00:00, 15.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27.00 / 36 (75.0%):  70%|███████████████████████████████████████████████████▊                      | 35/50 [00:02<00:00, 15.97it/s]2025-08-18 21:32:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 28.00 / 37 (75.7%):  72%|█████████████████████████████████████████████████████▎                    | 36/50 [00:02<00:00, 15.97it/s]2025-08-18 21:32:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 28.00 / 38 (73.7%):  74%|██████████████████████████████████████████████████████▊                   | 37/50 [00:02<00:00, 15.97it/s]2025-08-18 21:32:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 28.00 / 39 (71.8%):  76%|████████████████████████████████████████████████████████▏                 | 38/50 [00:02<00:00, 15.97it/s]2025-08-18 21:32:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 28.00 / 39 (71.8%):  78%|█████████████████████████████████████████████████████████▋                | 39/50 [00:02<00:00, 18.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 29.00 / 40 (72.5%):  78%|█████████████████████████████████████████████████████████▋                | 39/50 [00:02<00:00, 18.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 30.00 / 41 (73.2%):  80%|███████████████████████████████████████████████████████████▏              | 40/50 [00:02<00:00, 18.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 31.00 / 42 (73.8%):  82%|████████████████████████████████████████████████████████████▋             | 41/50 [00:02<00:00, 18.57it/s]2025-08-18 21:32:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 31.00 / 42 (73.8%):  84%|██████████████████████████████████████████████████████████████▏           | 42/50 [00:02<00:00, 15.00it/s]2025-08-18 21:32:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 32.00 / 43 (74.4%):  84%|██████████████████████████████████████████████████████████████▏           | 42/50 [00:02<00:00, 15.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 32.00 / 44 (72.7%):  86%|███████████████████████████████████████████████████████████████▋          | 43/50 [00:02<00:00, 15.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 32.00 / 45 (71.1%):  88%|█████████████████████████████████████████████████████████████████         | 44/50 [00:02<00:00, 15.00it/s]2025-08-18 21:32:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 33.00 / 46 (71.7%):  90%|██████████████████████████████████████████████████████████████████▌       | 45/50 [00:02<00:00, 17.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 34.00 / 47 (72.3%):  92%|████████████████████████████████████████████████████████████████████      | 46/50 [00:02<00:00, 17.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 35.00 / 48 (72.9%):  94%|█████████████████████████████████████████████████████████████████████▌    | 47/50 [00:02<00:00, 17.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 36.00 / 49 (73.5%):  98%|████████████████████████████████████████████████████████████████████████▌ | 49/50 [00:03<00:00, 17.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 37.00 / 50 (74.0%): 100%|██████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 15.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/18 21:32:55 INFO dspy.evaluate.evaluate: Average Metric: 37 / 50 (74.0%)\n",
      "2025/08/18 21:32:55 INFO dspy.teleprompt.mipro_optimizer_v2: Default program score: 74.0\n",
      "\n",
      "/Users/rmartinshort/Documents/DS_projects/dspy_judge/judgemodel/lib/python3.12/site-packages/optuna/_experimental.py:32: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "2025/08/18 21:32:55 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 2 / 18 =====\n",
      "\u001b[92m21:32:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-08-18 21:32:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:32:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:32:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                       | 0/50 [00:00<?, ?it/s]2025-08-18 21:32:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 1 (100.0%):   0%|                                                                                    | 0/50 [00:00<?, ?it/s]2025-08-18 21:32:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 1.00 / 1 (100.0%):   2%|█▌                                                                          | 1/50 [00:00<00:24,  1.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 2 (100.0%):   2%|█▌                                                                          | 1/50 [00:00<00:24,  1.97it/s]2025-08-18 21:32:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 3 (66.7%):   4%|███                                                                          | 2/50 [00:00<00:24,  1.97it/s]2025-08-18 21:32:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 2.00 / 4 (50.0%):   6%|████▌                                                                        | 3/50 [00:00<00:23,  1.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 3.00 / 5 (60.0%):   8%|██████▏                                                                      | 4/50 [00:00<00:23,  1.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 3.00 / 6 (50.0%):  10%|███████▋                                                                     | 5/50 [00:00<00:22,  1.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:32:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 4.00 / 7 (57.1%):  12%|█████████▏                                                                   | 6/50 [00:00<00:22,  1.97it/s]2025-08-18 21:32:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 8 (62.5%):  14%|██████████▊                                                                  | 7/50 [00:00<00:21,  1.97it/s]2025-08-18 21:32:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 5.00 / 8 (62.5%):  16%|████████████▎                                                                | 8/50 [00:00<00:02, 16.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 6.00 / 9 (66.7%):  16%|████████████▎                                                                | 8/50 [00:01<00:02, 16.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 7.00 / 10 (70.0%):  18%|█████████████▋                                                              | 9/50 [00:01<00:02, 16.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 11 (72.7%):  20%|███████████████                                                            | 10/50 [00:01<00:02, 16.53it/s]2025-08-18 21:32:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 12 (75.0%):  22%|████████████████▌                                                          | 11/50 [00:01<00:02, 16.53it/s]2025-08-18 21:32:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 9.00 / 12 (75.0%):  24%|██████████████████                                                         | 12/50 [00:01<00:03, 12.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 13 (76.9%):  24%|█████████████████▊                                                        | 12/50 [00:01<00:03, 12.51it/s]2025-08-18 21:32:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 14 (78.6%):  26%|███████████████████▏                                                      | 13/50 [00:01<00:02, 12.51it/s]2025-08-18 21:32:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 15 (80.0%):  28%|████████████████████▋                                                     | 14/50 [00:01<00:02, 12.51it/s]2025-08-18 21:32:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 16 (75.0%):  30%|██████████████████████▏                                                   | 15/50 [00:01<00:02, 12.51it/s]2025-08-18 21:32:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 17 (76.5%):  32%|███████████████████████▋                                                  | 16/50 [00:01<00:02, 12.51it/s]2025-08-18 21:32:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 13.00 / 17 (76.5%):  34%|█████████████████████████▏                                                | 17/50 [00:01<00:02, 11.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 14.00 / 18 (77.8%):  34%|█████████████████████████▏                                                | 17/50 [00:01<00:02, 11.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 15.00 / 19 (78.9%):  36%|██████████████████████████▋                                               | 18/50 [00:01<00:02, 11.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 15.00 / 20 (75.0%):  38%|████████████████████████████                                              | 19/50 [00:01<00:02, 11.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 21 (71.4%):  40%|█████████████████████████████▌                                            | 20/50 [00:01<00:02, 11.91it/s]2025-08-18 21:32:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 22 (68.2%):  42%|███████████████████████████████                                           | 21/50 [00:01<00:02, 11.91it/s]2025-08-18 21:32:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 15.00 / 22 (68.2%):  44%|████████████████████████████████▌                                         | 22/50 [00:01<00:01, 16.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 23 (65.2%):  44%|████████████████████████████████▌                                         | 22/50 [00:01<00:01, 16.05it/s]2025-08-18 21:32:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 16.00 / 24 (66.7%):  46%|██████████████████████████████████                                        | 23/50 [00:01<00:01, 16.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 17.00 / 25 (68.0%):  48%|███████████████████████████████████▌                                      | 24/50 [00:01<00:01, 16.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 25 (68.0%):  50%|█████████████████████████████████████                                     | 25/50 [00:01<00:01, 13.26it/s]2025-08-18 21:32:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 26 (69.2%):  50%|█████████████████████████████████████                                     | 25/50 [00:01<00:01, 13.26it/s]2025-08-18 21:32:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 27 (70.4%):  52%|██████████████████████████████████████▍                                   | 26/50 [00:01<00:01, 13.26it/s]2025-08-18 21:32:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 28 (71.4%):  54%|███████████████████████████████████████▉                                  | 27/50 [00:02<00:01, 13.26it/s]2025-08-18 21:32:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 21.00 / 29 (72.4%):  56%|█████████████████████████████████████████▍                                | 28/50 [00:02<00:01, 13.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 29 (72.4%):  58%|██████████████████████████████████████████▉                               | 29/50 [00:02<00:01, 16.74it/s]2025-08-18 21:32:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 22.00 / 30 (73.3%):  58%|██████████████████████████████████████████▉                               | 29/50 [00:02<00:01, 16.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 22.00 / 31 (71.0%):  60%|████████████████████████████████████████████▍                             | 30/50 [00:02<00:01, 16.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 23.00 / 32 (71.9%):  62%|█████████████████████████████████████████████▉                            | 31/50 [00:02<00:01, 16.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 33 (72.7%):  64%|███████████████████████████████████████████████▎                          | 32/50 [00:02<00:01, 16.74it/s]2025-08-18 21:32:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 24.00 / 33 (72.7%):  66%|████████████████████████████████████████████████▊                         | 33/50 [00:02<00:01, 13.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.00 / 34 (73.5%):  66%|████████████████████████████████████████████████▊                         | 33/50 [00:02<00:01, 13.95it/s]2025-08-18 21:32:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 26.00 / 35 (74.3%):  68%|██████████████████████████████████████████████████▎                       | 34/50 [00:02<00:01, 13.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:58 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27.00 / 36 (75.0%):  70%|███████████████████████████████████████████████████▊                      | 35/50 [00:02<00:01, 13.95it/s]2025-08-18 21:32:58 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 27.00 / 36 (75.0%):  72%|█████████████████████████████████████████████████████▎                    | 36/50 [00:02<00:00, 15.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:58 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27.00 / 37 (73.0%):  72%|█████████████████████████████████████████████████████▎                    | 36/50 [00:02<00:00, 15.43it/s]2025-08-18 21:32:58 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 27.00 / 38 (71.1%):  74%|██████████████████████████████████████████████████████▊                   | 37/50 [00:02<00:00, 15.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:58 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:58 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:58 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 28.00 / 39 (71.8%):  76%|████████████████████████████████████████████████████████▏                 | 38/50 [00:02<00:00, 15.43it/s]2025-08-18 21:32:58 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:58 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 28.00 / 40 (70.0%):  78%|█████████████████████████████████████████████████████████▋                | 39/50 [00:02<00:00, 15.43it/s]2025-08-18 21:32:58 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 29.00 / 41 (70.7%):  80%|███████████████████████████████████████████████████████████▏              | 40/50 [00:02<00:00, 15.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:58 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:58 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 29.00 / 41 (70.7%):  82%|████████████████████████████████████████████████████████████▋             | 41/50 [00:02<00:00, 15.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:58 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 29.00 / 42 (69.0%):  82%|████████████████████████████████████████████████████████████▋             | 41/50 [00:03<00:00, 15.86it/s]2025-08-18 21:32:58 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 30.00 / 43 (69.8%):  86%|███████████████████████████████████████████████████████████████▋          | 43/50 [00:03<00:00, 14.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 31.00 / 44 (70.5%):  86%|███████████████████████████████████████████████████████████████▋          | 43/50 [00:03<00:00, 14.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 32.00 / 45 (71.1%):  88%|█████████████████████████████████████████████████████████████████         | 44/50 [00:03<00:00, 14.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 33.00 / 46 (71.7%):  92%|████████████████████████████████████████████████████████████████████      | 46/50 [00:03<00:00, 15.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 33.00 / 47 (70.2%):  92%|████████████████████████████████████████████████████████████████████      | 46/50 [00:03<00:00, 15.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 34.00 / 48 (70.8%):  94%|█████████████████████████████████████████████████████████████████████▌    | 47/50 [00:03<00:00, 15.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 35.00 / 49 (71.4%):  98%|████████████████████████████████████████████████████████████████████████▌ | 49/50 [00:03<00:00, 17.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 36.00 / 50 (72.0%): 100%|██████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 14.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/18 21:32:58 INFO dspy.evaluate.evaluate: Average Metric: 36 / 50 (72.0%)\n",
      "2025/08/18 21:32:58 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 72.0 with parameters ['Predictor 0: Instruction 5', 'Predictor 0: Few-Shot Set 8'].\n",
      "2025/08/18 21:32:58 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [74.0, 72.0]\n",
      "2025/08/18 21:32:58 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 74.0\n",
      "2025/08/18 21:32:58 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/08/18 21:32:58 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 3 / 18 =====\n",
      "\u001b[92m21:32:58 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-08-18 21:32:58 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:58 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:32:58 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:58 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:58 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                       | 0/50 [00:00<?, ?it/s]2025-08-18 21:32:58 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:58 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:58 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:58 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:58 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:58 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:58 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:58 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:58 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:32:58 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:59 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:59 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 1.00 / 1 (100.0%):   0%|                                                                                    | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 1 (100.0%):   2%|█▌                                                                          | 1/50 [00:00<00:21,  2.26it/s]2025-08-18 21:32:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:59 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:59 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 2 (100.0%):   2%|█▌                                                                          | 1/50 [00:00<00:21,  2.26it/s]2025-08-18 21:32:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:59 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:59 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 3 (100.0%):   4%|███                                                                         | 2/50 [00:00<00:21,  2.26it/s]2025-08-18 21:32:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:59 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:59 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:59 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:59 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 3.00 / 4 (75.0%):   6%|████▌                                                                        | 3/50 [00:00<00:20,  2.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:59 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 5 (80.0%):   8%|██████▏                                                                      | 4/50 [00:00<00:20,  2.26it/s]2025-08-18 21:32:59 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:32:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 4.00 / 6 (66.7%):  10%|███████▋                                                                     | 5/50 [00:00<00:19,  2.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:32:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:59 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:59 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 7 (71.4%):  12%|█████████▏                                                                   | 6/50 [00:00<00:19,  2.26it/s]2025-08-18 21:32:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:59 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:59 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 6.00 / 8 (75.0%):  14%|██████████▊                                                                  | 7/50 [00:00<00:19,  2.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 8 (75.0%):  16%|████████████▎                                                                | 8/50 [00:00<00:03, 13.64it/s]2025-08-18 21:32:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:59 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:59 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 9 (77.8%):  16%|████████████▎                                                                | 8/50 [00:00<00:03, 13.64it/s]2025-08-18 21:32:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:59 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:59 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 10 (80.0%):  18%|█████████████▋                                                              | 9/50 [00:00<00:03, 13.64it/s]2025-08-18 21:32:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 8.00 / 10 (80.0%):  20%|███████████████                                                            | 10/50 [00:00<00:03, 11.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:59 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:59 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 11 (81.8%):  20%|███████████████                                                            | 10/50 [00:00<00:03, 11.74it/s]2025-08-18 21:32:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:59 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:59 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 12 (83.3%):  22%|████████████████▎                                                         | 11/50 [00:00<00:03, 11.74it/s]2025-08-18 21:32:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:59 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:59 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 13 (84.6%):  24%|█████████████████▊                                                        | 12/50 [00:00<00:03, 11.74it/s]2025-08-18 21:32:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:59 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:59 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 14 (85.7%):  26%|███████████████████▏                                                      | 13/50 [00:00<00:03, 11.74it/s]2025-08-18 21:32:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:32:59 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:32:59 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 15 (80.0%):  28%|████████████████████▋                                                     | 14/50 [00:01<00:03, 11.74it/s]2025-08-18 21:33:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 16 (81.2%):  30%|██████████████████████▏                                                   | 15/50 [00:01<00:02, 11.74it/s]2025-08-18 21:33:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 13.00 / 16 (81.2%):  32%|███████████████████████▋                                                  | 16/50 [00:01<00:02, 16.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 14.00 / 17 (82.4%):  32%|███████████████████████▋                                                  | 16/50 [00:01<00:02, 16.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:33:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:33:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 15.00 / 18 (83.3%):  34%|█████████████████████████▏                                                | 17/50 [00:01<00:02, 16.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 15.00 / 18 (83.3%):  36%|██████████████████████████▋                                               | 18/50 [00:01<00:02, 13.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 19 (84.2%):  36%|██████████████████████████▋                                               | 18/50 [00:01<00:02, 13.66it/s]2025-08-18 21:33:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 20 (85.0%):  38%|████████████████████████████                                              | 19/50 [00:01<00:02, 13.66it/s]2025-08-18 21:33:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 21 (85.7%):  40%|█████████████████████████████▌                                            | 20/50 [00:01<00:02, 13.66it/s]2025-08-18 21:33:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 22 (81.8%):  42%|███████████████████████████████                                           | 21/50 [00:01<00:02, 13.66it/s]2025-08-18 21:33:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 23 (78.3%):  44%|████████████████████████████████▌                                         | 22/50 [00:01<00:02, 13.66it/s]2025-08-18 21:33:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 18.00 / 23 (78.3%):  46%|██████████████████████████████████                                        | 23/50 [00:01<00:01, 18.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 24 (79.2%):  46%|██████████████████████████████████                                        | 23/50 [00:01<00:01, 18.94it/s]2025-08-18 21:33:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 20.00 / 25 (80.0%):  48%|███████████████████████████████████▌                                      | 24/50 [00:01<00:01, 18.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:33:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:33:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 21.00 / 26 (80.8%):  50%|█████████████████████████████████████                                     | 25/50 [00:01<00:01, 18.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 27 (81.5%):  52%|██████████████████████████████████████▍                                   | 26/50 [00:01<00:01, 14.58it/s]2025-08-18 21:33:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 28 (78.6%):  54%|███████████████████████████████████████▉                                  | 27/50 [00:01<00:01, 14.58it/s]2025-08-18 21:33:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 29 (75.9%):  56%|█████████████████████████████████████████▍                                | 28/50 [00:01<00:01, 14.58it/s]2025-08-18 21:33:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 30 (73.3%):  58%|██████████████████████████████████████████▉                               | 29/50 [00:01<00:01, 14.58it/s]2025-08-18 21:33:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 22.00 / 31 (71.0%):  60%|████████████████████████████████████████████▍                             | 30/50 [00:02<00:01, 14.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 31 (71.0%):  62%|█████████████████████████████████████████████▉                            | 31/50 [00:02<00:01, 18.38it/s]2025-08-18 21:33:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 32 (68.8%):  62%|█████████████████████████████████████████████▉                            | 31/50 [00:02<00:01, 18.38it/s]2025-08-18 21:33:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 33 (69.7%):  64%|███████████████████████████████████████████████▎                          | 32/50 [00:02<00:00, 18.38it/s]2025-08-18 21:33:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 34 (70.6%):  66%|████████████████████████████████████████████████▊                         | 33/50 [00:02<00:00, 18.38it/s]2025-08-18 21:33:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 34 (70.6%):  68%|██████████████████████████████████████████████████▎                       | 34/50 [00:02<00:01, 15.24it/s]2025-08-18 21:33:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.00 / 35 (71.4%):  68%|██████████████████████████████████████████████████▎                       | 34/50 [00:02<00:01, 15.24it/s]2025-08-18 21:33:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 26.00 / 36 (72.2%):  70%|███████████████████████████████████████████████████▊                      | 35/50 [00:02<00:00, 15.24it/s]2025-08-18 21:33:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 26.00 / 37 (70.3%):  72%|█████████████████████████████████████████████████████▎                    | 36/50 [00:02<00:00, 15.24it/s]2025-08-18 21:33:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 26.00 / 38 (68.4%):  74%|██████████████████████████████████████████████████████▊                   | 37/50 [00:02<00:00, 15.24it/s]2025-08-18 21:33:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27.00 / 39 (69.2%):  76%|████████████████████████████████████████████████████████▏                 | 38/50 [00:02<00:00, 15.24it/s]2025-08-18 21:33:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 27.00 / 39 (69.2%):  78%|█████████████████████████████████████████████████████████▋                | 39/50 [00:02<00:00, 19.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 28.00 / 40 (70.0%):  78%|█████████████████████████████████████████████████████████▋                | 39/50 [00:02<00:00, 19.56it/s]2025-08-18 21:33:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:33:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 28.00 / 41 (68.3%):  80%|███████████████████████████████████████████████████████████▏              | 40/50 [00:02<00:00, 19.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 28.00 / 42 (66.7%):  82%|████████████████████████████████████████████████████████████▋             | 41/50 [00:02<00:00, 19.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 29.00 / 43 (67.4%):  84%|██████████████████████████████████████████████████████████████▏           | 42/50 [00:02<00:00, 15.15it/s]2025-08-18 21:33:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 30.00 / 44 (68.2%):  86%|███████████████████████████████████████████████████████████████▋          | 43/50 [00:02<00:00, 15.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 31.00 / 45 (68.9%):  88%|█████████████████████████████████████████████████████████████████         | 44/50 [00:02<00:00, 15.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 32.00 / 46 (69.6%):  92%|████████████████████████████████████████████████████████████████████      | 46/50 [00:02<00:00, 18.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 32.00 / 47 (68.1%):  92%|████████████████████████████████████████████████████████████████████      | 46/50 [00:03<00:00, 18.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 33.00 / 48 (68.8%):  94%|█████████████████████████████████████████████████████████████████████▌    | 47/50 [00:03<00:00, 18.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 34.00 / 49 (69.4%):  98%|████████████████████████████████████████████████████████████████████████▌ | 49/50 [00:03<00:00, 14.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 35.00 / 50 (70.0%): 100%|██████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 15.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/18 21:33:02 INFO dspy.evaluate.evaluate: Average Metric: 35 / 50 (70.0%)\n",
      "2025/08/18 21:33:02 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 70.0 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 1'].\n",
      "2025/08/18 21:33:02 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [74.0, 72.0, 70.0]\n",
      "2025/08/18 21:33:02 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 74.0\n",
      "2025/08/18 21:33:02 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/08/18 21:33:02 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 4 / 18 =====\n",
      "\u001b[92m21:33:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-08-18 21:33:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:33:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:33:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                       | 0/50 [00:00<?, ?it/s]2025-08-18 21:33:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:33:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:33:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 1 (0.0%):   0%|                                                                                      | 0/50 [00:00<?, ?it/s]2025-08-18 21:33:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 0.00 / 1 (0.0%):   2%|█▌                                                                            | 1/50 [00:00<00:22,  2.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 2 (50.0%):   2%|█▌                                                                           | 1/50 [00:00<00:22,  2.18it/s]2025-08-18 21:33:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 3 (33.3%):   4%|███                                                                          | 2/50 [00:00<00:22,  2.18it/s]2025-08-18 21:33:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 4 (50.0%):   6%|████▌                                                                        | 3/50 [00:00<00:21,  2.18it/s]2025-08-18 21:33:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 5 (60.0%):   8%|██████▏                                                                      | 4/50 [00:00<00:21,  2.18it/s]2025-08-18 21:33:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 6 (50.0%):  10%|███████▋                                                                     | 5/50 [00:00<00:20,  2.18it/s]2025-08-18 21:33:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 7 (42.9%):  12%|█████████▏                                                                   | 6/50 [00:00<00:20,  2.18it/s]2025-08-18 21:33:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 4.00 / 8 (50.0%):  16%|████████████▎                                                                | 8/50 [00:00<00:03, 11.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 9 (55.6%):  16%|████████████▎                                                                | 8/50 [00:00<00:03, 11.54it/s]2025-08-18 21:33:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 6.00 / 10 (60.0%):  18%|█████████████▋                                                              | 9/50 [00:00<00:03, 11.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 10 (60.0%):  20%|███████████████                                                            | 10/50 [00:00<00:03, 12.75it/s]2025-08-18 21:33:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 11 (63.6%):  20%|███████████████                                                            | 10/50 [00:00<00:03, 12.75it/s]2025-08-18 21:33:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 8.00 / 12 (66.7%):  22%|████████████████▌                                                          | 11/50 [00:01<00:03, 12.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 9.00 / 13 (69.2%):  24%|██████████████████                                                         | 12/50 [00:01<00:02, 12.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 13 (69.2%):  26%|███████████████████▌                                                       | 13/50 [00:01<00:02, 15.65it/s]2025-08-18 21:33:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 14 (71.4%):  26%|███████████████████▏                                                      | 13/50 [00:01<00:02, 15.65it/s]2025-08-18 21:33:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 11.00 / 15 (73.3%):  28%|████████████████████▋                                                     | 14/50 [00:01<00:02, 15.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 16 (75.0%):  30%|██████████████████████▏                                                   | 15/50 [00:01<00:02, 15.65it/s]2025-08-18 21:33:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 12.00 / 16 (75.0%):  32%|███████████████████████▋                                                  | 16/50 [00:01<00:02, 12.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 12.00 / 17 (70.6%):  32%|███████████████████████▋                                                  | 16/50 [00:01<00:02, 12.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 13.00 / 18 (72.2%):  34%|█████████████████████████▏                                                | 17/50 [00:01<00:02, 12.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 14.00 / 19 (73.7%):  36%|██████████████████████████▋                                               | 18/50 [00:01<00:02, 12.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 20 (70.0%):  38%|████████████████████████████                                              | 19/50 [00:01<00:02, 12.13it/s]2025-08-18 21:33:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 21 (66.7%):  40%|█████████████████████████████▌                                            | 20/50 [00:01<00:02, 12.13it/s]2025-08-18 21:33:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 14.00 / 21 (66.7%):  42%|███████████████████████████████                                           | 21/50 [00:01<00:01, 17.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 22 (68.2%):  42%|███████████████████████████████                                           | 21/50 [00:01<00:01, 17.81it/s]2025-08-18 21:33:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 23 (65.2%):  44%|████████████████████████████████▌                                         | 22/50 [00:01<00:01, 17.81it/s]2025-08-18 21:33:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 24 (66.7%):  46%|██████████████████████████████████                                        | 23/50 [00:01<00:01, 17.81it/s]2025-08-18 21:33:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 16.00 / 24 (66.7%):  48%|███████████████████████████████████▌                                      | 24/50 [00:01<00:01, 13.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 25 (68.0%):  48%|███████████████████████████████████▌                                      | 24/50 [00:01<00:01, 13.71it/s]2025-08-18 21:33:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 26 (65.4%):  50%|█████████████████████████████████████                                     | 25/50 [00:01<00:01, 13.71it/s]2025-08-18 21:33:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 18.00 / 27 (66.7%):  52%|██████████████████████████████████████▍                                   | 26/50 [00:02<00:01, 13.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 27 (66.7%):  54%|███████████████████████████████████████▉                                  | 27/50 [00:02<00:01, 14.80it/s]2025-08-18 21:33:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 28 (67.9%):  54%|███████████████████████████████████████▉                                  | 27/50 [00:02<00:01, 14.80it/s]2025-08-18 21:33:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 29 (69.0%):  56%|█████████████████████████████████████████▍                                | 28/50 [00:02<00:01, 14.80it/s]2025-08-18 21:33:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 30 (66.7%):  58%|██████████████████████████████████████████▉                               | 29/50 [00:02<00:01, 14.80it/s]2025-08-18 21:33:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 31 (64.5%):  62%|█████████████████████████████████████████████▉                            | 31/50 [00:02<00:01, 18.58it/s]2025-08-18 21:33:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 32 (62.5%):  62%|█████████████████████████████████████████████▉                            | 31/50 [00:02<00:01, 18.58it/s]2025-08-18 21:33:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 33 (60.6%):  64%|███████████████████████████████████████████████▎                          | 32/50 [00:02<00:00, 18.58it/s]2025-08-18 21:33:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:33:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 20.00 / 34 (58.8%):  66%|████████████████████████████████████████████████▊                         | 33/50 [00:02<00:00, 18.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 34 (58.8%):  68%|██████████████████████████████████████████████████▎                       | 34/50 [00:02<00:01, 12.89it/s]2025-08-18 21:33:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 35 (60.0%):  68%|██████████████████████████████████████████████████▎                       | 34/50 [00:02<00:01, 12.89it/s]2025-08-18 21:33:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 21.00 / 36 (58.3%):  70%|███████████████████████████████████████████████████▊                      | 35/50 [00:02<00:01, 12.89it/s]2025-08-18 21:33:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 37 (59.5%):  72%|█████████████████████████████████████████████████████▎                    | 36/50 [00:02<00:01, 12.89it/s]2025-08-18 21:33:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 38 (57.9%):  74%|██████████████████████████████████████████████████████▊                   | 37/50 [00:02<00:01, 12.89it/s]2025-08-18 21:33:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 39 (56.4%):  76%|████████████████████████████████████████████████████████▏                 | 38/50 [00:02<00:00, 12.89it/s]2025-08-18 21:33:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 22.00 / 39 (56.4%):  78%|█████████████████████████████████████████████████████████▋                | 39/50 [00:02<00:00, 18.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 40 (57.5%):  78%|█████████████████████████████████████████████████████████▋                | 39/50 [00:02<00:00, 18.07it/s]2025-08-18 21:33:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 41 (56.1%):  80%|███████████████████████████████████████████████████████████▏              | 40/50 [00:02<00:00, 18.07it/s]2025-08-18 21:33:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 42 (57.1%):  82%|████████████████████████████████████████████████████████████▋             | 41/50 [00:03<00:00, 18.07it/s]2025-08-18 21:33:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 24.00 / 42 (57.1%):  84%|██████████████████████████████████████████████████████████████▏           | 42/50 [00:03<00:00, 12.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 25.00 / 43 (58.1%):  84%|██████████████████████████████████████████████████████████████▏           | 42/50 [00:03<00:00, 12.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 26.00 / 44 (59.1%):  86%|███████████████████████████████████████████████████████████████▋          | 43/50 [00:03<00:00, 12.87it/s]2025-08-18 21:33:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 27.00 / 45 (60.0%):  88%|█████████████████████████████████████████████████████████████████         | 44/50 [00:03<00:00, 12.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 28.00 / 46 (60.9%):  90%|██████████████████████████████████████████████████████████████████▌       | 45/50 [00:03<00:00, 12.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 28.00 / 47 (59.6%):  94%|█████████████████████████████████████████████████████████████████████▌    | 47/50 [00:03<00:00, 15.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 28.00 / 48 (58.3%):  94%|█████████████████████████████████████████████████████████████████████▌    | 47/50 [00:03<00:00, 15.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 29.00 / 49 (59.2%):  96%|███████████████████████████████████████████████████████████████████████   | 48/50 [00:03<00:00, 15.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 29.00 / 50 (58.0%): 100%|██████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 13.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/18 21:33:05 INFO dspy.evaluate.evaluate: Average Metric: 29 / 50 (58.0%)\n",
      "2025/08/18 21:33:05 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 58.0 with parameters ['Predictor 0: Instruction 3', 'Predictor 0: Few-Shot Set 1'].\n",
      "2025/08/18 21:33:05 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [74.0, 72.0, 70.0, 58.0]\n",
      "2025/08/18 21:33:05 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 74.0\n",
      "2025/08/18 21:33:05 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/08/18 21:33:05 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 5 / 18 =====\n",
      "\u001b[92m21:33:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-08-18 21:33:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "  0%|                                                                                                                       | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:06 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:06 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:06 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 1 (0.0%):   0%|                                                                                      | 0/50 [00:00<?, ?it/s]2025-08-18 21:33:06 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 0.00 / 1 (0.0%):   2%|█▌                                                                            | 1/50 [00:00<00:22,  2.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:06 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:06 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:06 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 2 (50.0%):   2%|█▌                                                                           | 1/50 [00:00<00:22,  2.16it/s]2025-08-18 21:33:06 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:06 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:06 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:06 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 3 (66.7%):   4%|███                                                                          | 2/50 [00:00<00:22,  2.16it/s]2025-08-18 21:33:06 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:06 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:06 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:06 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:06 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 2.00 / 4 (50.0%):   6%|████▌                                                                        | 3/50 [00:00<00:21,  2.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:06 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:06 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 3.00 / 5 (60.0%):   8%|██████▏                                                                      | 4/50 [00:00<00:21,  2.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:06 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:06 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 4.00 / 6 (66.7%):  10%|███████▋                                                                     | 5/50 [00:00<00:20,  2.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:06 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:06 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 5.00 / 7 (71.4%):  12%|█████████▏                                                                   | 6/50 [00:00<00:20,  2.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:06 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:06 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:06 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:06 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:06 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:06 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 5.00 / 8 (62.5%):  14%|██████████▊                                                                  | 7/50 [00:00<00:19,  2.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:06 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:06 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:06 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:06 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:06 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:06 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:06 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:06 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:06 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 9 (66.7%):  16%|████████████▎                                                                | 8/50 [00:00<00:19,  2.16it/s]2025-08-18 21:33:06 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 6.00 / 9 (66.7%):  18%|█████████████▊                                                               | 9/50 [00:00<00:04, 10.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:06 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:06 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 7.00 / 10 (70.0%):  18%|█████████████▋                                                              | 9/50 [00:00<00:04, 10.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:06 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:06 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:06 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 11 (72.7%):  20%|███████████████                                                            | 10/50 [00:01<00:03, 10.18it/s]2025-08-18 21:33:06 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:06 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:06 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:06 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 12 (75.0%):  22%|████████████████▌                                                          | 11/50 [00:01<00:03, 10.18it/s]2025-08-18 21:33:06 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:06 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:06 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:06 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 13 (69.2%):  24%|██████████████████                                                         | 12/50 [00:01<00:03, 10.18it/s]2025-08-18 21:33:06 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:07 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:07 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:07 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 14 (71.4%):  26%|███████████████████▏                                                      | 13/50 [00:01<00:03, 10.18it/s]2025-08-18 21:33:07 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:07 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:07 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:07 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 15 (66.7%):  28%|████████████████████▋                                                     | 14/50 [00:01<00:03, 10.18it/s]2025-08-18 21:33:07 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 10.00 / 15 (66.7%):  30%|██████████████████████▏                                                   | 15/50 [00:01<00:02, 16.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:07 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:07 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:07 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 16 (62.5%):  30%|██████████████████████▏                                                   | 15/50 [00:01<00:02, 16.23it/s]2025-08-18 21:33:07 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:07 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:07 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 11.00 / 17 (64.7%):  32%|███████████████████████▋                                                  | 16/50 [00:01<00:02, 16.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:07 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:07 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:07 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:07 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:07 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 18 (66.7%):  34%|█████████████████████████▏                                                | 17/50 [00:01<00:02, 16.23it/s]2025-08-18 21:33:07 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 12.00 / 18 (66.7%):  36%|██████████████████████████▋                                               | 18/50 [00:01<00:02, 13.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:07 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:07 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:07 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 19 (68.4%):  36%|██████████████████████████▋                                               | 18/50 [00:01<00:02, 13.83it/s]2025-08-18 21:33:07 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:07 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:07 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:07 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 20 (65.0%):  38%|████████████████████████████                                              | 19/50 [00:01<00:02, 13.83it/s]2025-08-18 21:33:07 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:07 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:07 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:07 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 21 (66.7%):  40%|█████████████████████████████▌                                            | 20/50 [00:01<00:02, 13.83it/s]2025-08-18 21:33:07 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:07 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:07 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 15.00 / 22 (68.2%):  42%|███████████████████████████████                                           | 21/50 [00:01<00:02, 13.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:07 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:07 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:07 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:07 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:07 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 23 (69.6%):  44%|████████████████████████████████▌                                         | 22/50 [00:01<00:02, 13.83it/s]2025-08-18 21:33:07 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 16.00 / 23 (69.6%):  46%|██████████████████████████████████                                        | 23/50 [00:01<00:01, 18.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:07 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:07 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 16.00 / 24 (66.7%):  46%|██████████████████████████████████                                        | 23/50 [00:01<00:01, 18.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:07 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:07 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:07 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:07 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:07 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 25 (68.0%):  48%|███████████████████████████████████▌                                      | 24/50 [00:01<00:01, 18.56it/s]2025-08-18 21:33:07 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:07 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:07 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 17.00 / 26 (65.4%):  50%|█████████████████████████████████████                                     | 25/50 [00:01<00:01, 18.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:07 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:07 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 17.00 / 26 (65.4%):  52%|██████████████████████████████████████▍                                   | 26/50 [00:01<00:01, 14.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:07 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:07 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 18.00 / 27 (66.7%):  52%|██████████████████████████████████████▍                                   | 26/50 [00:01<00:01, 14.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:07 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:07 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:07 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:07 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:07 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 28 (67.9%):  54%|███████████████████████████████████████▉                                  | 27/50 [00:01<00:01, 14.97it/s]2025-08-18 21:33:07 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:07 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:07 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 20.00 / 29 (69.0%):  56%|█████████████████████████████████████████▍                                | 28/50 [00:01<00:01, 14.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:07 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:07 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:07 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:07 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:07 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:07 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 20.00 / 30 (66.7%):  58%|██████████████████████████████████████████▉                               | 29/50 [00:01<00:01, 14.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:07 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 30 (66.7%):  60%|████████████████████████████████████████████▍                             | 30/50 [00:01<00:01, 18.50it/s]2025-08-18 21:33:07 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 20.00 / 31 (64.5%):  60%|████████████████████████████████████████████▍                             | 30/50 [00:01<00:01, 18.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:07 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:07 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:08 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 32 (62.5%):  62%|█████████████████████████████████████████████▉                            | 31/50 [00:02<00:01, 18.50it/s]2025-08-18 21:33:08 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:08 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 33 (63.6%):  64%|███████████████████████████████████████████████▎                          | 32/50 [00:02<00:00, 18.50it/s]2025-08-18 21:33:08 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 21.00 / 33 (63.6%):  66%|████████████████████████████████████████████████▊                         | 33/50 [00:02<00:01, 15.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 22.00 / 34 (64.7%):  66%|████████████████████████████████████████████████▊                         | 33/50 [00:02<00:01, 15.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:08 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:08 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:08 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 35 (65.7%):  68%|██████████████████████████████████████████████████▎                       | 34/50 [00:02<00:01, 15.89it/s]2025-08-18 21:33:08 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:08 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 36 (66.7%):  70%|███████████████████████████████████████████████████▊                      | 35/50 [00:02<00:00, 15.89it/s]2025-08-18 21:33:08 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 24.00 / 36 (66.7%):  72%|█████████████████████████████████████████████████████▎                    | 36/50 [00:02<00:00, 17.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:08 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 37 (64.9%):  72%|█████████████████████████████████████████████████████▎                    | 36/50 [00:02<00:00, 17.09it/s]2025-08-18 21:33:08 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:08 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 38 (63.2%):  74%|██████████████████████████████████████████████████████▊                   | 37/50 [00:02<00:00, 17.09it/s]2025-08-18 21:33:08 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 25.00 / 39 (64.1%):  76%|████████████████████████████████████████████████████████▏                 | 38/50 [00:02<00:00, 17.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:08 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:08 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 25.00 / 40 (62.5%):  78%|█████████████████████████████████████████████████████████▋                | 39/50 [00:02<00:00, 17.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:08 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.00 / 40 (62.5%):  80%|███████████████████████████████████████████████████████████▏              | 40/50 [00:02<00:00, 18.88it/s]2025-08-18 21:33:08 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:08 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 26.00 / 41 (63.4%):  80%|███████████████████████████████████████████████████████████▏              | 40/50 [00:02<00:00, 18.88it/s]2025-08-18 21:33:08 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 26.00 / 42 (61.9%):  82%|████████████████████████████████████████████████████████████▋             | 41/50 [00:02<00:00, 18.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:08 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:08 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 26.00 / 43 (60.5%):  84%|██████████████████████████████████████████████████████████████▏           | 42/50 [00:02<00:00, 18.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 26.00 / 43 (60.5%):  86%|███████████████████████████████████████████████████████████████▋          | 43/50 [00:02<00:00, 15.36it/s]2025-08-18 21:33:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 26.00 / 44 (59.1%):  86%|███████████████████████████████████████████████████████████████▋          | 43/50 [00:02<00:00, 15.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27.00 / 45 (60.0%):  88%|█████████████████████████████████████████████████████████████████         | 44/50 [00:02<00:00, 15.36it/s]2025-08-18 21:33:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 27.00 / 46 (58.7%):  90%|██████████████████████████████████████████████████████████████████▌       | 45/50 [00:02<00:00, 15.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 28.00 / 47 (59.6%):  92%|████████████████████████████████████████████████████████████████████      | 46/50 [00:02<00:00, 15.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 29.00 / 48 (60.4%):  96%|███████████████████████████████████████████████████████████████████████   | 48/50 [00:02<00:00, 20.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:09 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:09 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 30.00 / 49 (61.2%):  96%|███████████████████████████████████████████████████████████████████████   | 48/50 [00:03<00:00, 20.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:09 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:09 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 31.00 / 50 (62.0%): 100%|██████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 15.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/18 21:33:09 INFO dspy.evaluate.evaluate: Average Metric: 31 / 50 (62.0%)\n",
      "2025/08/18 21:33:09 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 62.0 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 2'].\n",
      "2025/08/18 21:33:09 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [74.0, 72.0, 70.0, 58.0, 62.0]\n",
      "2025/08/18 21:33:09 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 74.0\n",
      "2025/08/18 21:33:09 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/08/18 21:33:09 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 6 / 18 =====\n",
      "\u001b[92m21:33:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-08-18 21:33:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                       | 0/50 [00:00<?, ?it/s]2025-08-18 21:33:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:09 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:09 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 1.00 / 1 (100.0%):   0%|                                                                                    | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 1 (100.0%):   2%|█▌                                                                          | 1/50 [00:00<00:22,  2.20it/s]2025-08-18 21:33:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:09 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:09 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 1.00 / 2 (50.0%):   2%|█▌                                                                           | 1/50 [00:00<00:22,  2.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:09 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:09 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:09 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:09 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 1.00 / 3 (33.3%):   4%|███                                                                          | 2/50 [00:00<00:21,  2.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:09 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:09 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 2.00 / 4 (50.0%):   6%|████▌                                                                        | 3/50 [00:00<00:21,  2.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 3.00 / 5 (60.0%):   8%|██████▏                                                                      | 4/50 [00:00<00:20,  2.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:09 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:09 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 6 (50.0%):  10%|███████▋                                                                     | 5/50 [00:00<00:20,  2.20it/s]2025-08-18 21:33:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 3.00 / 6 (50.0%):  12%|█████████▏                                                                   | 6/50 [00:00<00:03, 13.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:09 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:09 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 7 (57.1%):  12%|█████████▏                                                                   | 6/50 [00:00<00:03, 13.43it/s]2025-08-18 21:33:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:09 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:09 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 8 (50.0%):  14%|██████████▊                                                                  | 7/50 [00:00<00:03, 13.43it/s]2025-08-18 21:33:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 5.00 / 9 (55.6%):  16%|████████████▎                                                                | 8/50 [00:00<00:03, 13.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:10 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 9 (55.6%):  18%|█████████████▊                                                               | 9/50 [00:00<00:03, 11.77it/s]2025-08-18 21:33:10 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:10 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 10 (60.0%):  18%|█████████████▋                                                              | 9/50 [00:00<00:03, 11.77it/s]2025-08-18 21:33:10 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:10 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 11 (54.5%):  20%|███████████████                                                            | 10/50 [00:00<00:03, 11.77it/s]2025-08-18 21:33:10 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:10 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 12 (58.3%):  22%|████████████████▌                                                          | 11/50 [00:01<00:03, 11.77it/s]2025-08-18 21:33:10 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 7.00 / 12 (58.3%):  24%|██████████████████                                                         | 12/50 [00:01<00:02, 14.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:10 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 13 (61.5%):  24%|██████████████████                                                         | 12/50 [00:01<00:02, 14.12it/s]2025-08-18 21:33:10 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:10 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 14 (64.3%):  26%|███████████████████▌                                                       | 13/50 [00:01<00:02, 14.12it/s]2025-08-18 21:33:10 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:10 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 15 (66.7%):  28%|████████████████████▋                                                     | 14/50 [00:01<00:02, 14.12it/s]2025-08-18 21:33:10 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:10 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 16 (68.8%):  30%|██████████████████████▏                                                   | 15/50 [00:01<00:02, 14.12it/s]2025-08-18 21:33:10 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 11.00 / 16 (68.8%):  32%|███████████████████████▋                                                  | 16/50 [00:01<00:01, 19.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:10 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 17 (64.7%):  32%|███████████████████████▋                                                  | 16/50 [00:01<00:01, 19.02it/s]2025-08-18 21:33:10 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:33:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 11.00 / 18 (61.1%):  34%|█████████████████████████▏                                                | 17/50 [00:01<00:01, 19.02it/s]2025-08-18 21:33:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 12.00 / 19 (63.2%):  36%|██████████████████████████▋                                               | 18/50 [00:01<00:01, 19.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:10 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:10 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 12.00 / 19 (63.2%):  38%|████████████████████████████                                              | 19/50 [00:01<00:02, 12.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:10 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:10 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 12.00 / 20 (60.0%):  38%|████████████████████████████                                              | 19/50 [00:01<00:02, 12.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:33:10 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:33:10 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 13.00 / 21 (61.9%):  40%|█████████████████████████████▌                                            | 20/50 [00:01<00:02, 12.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:10 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:10 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 22 (59.1%):  42%|███████████████████████████████                                           | 21/50 [00:01<00:02, 12.76it/s]2025-08-18 21:33:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:10 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:10 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 14.00 / 23 (60.9%):  44%|████████████████████████████████▌                                         | 22/50 [00:01<00:02, 12.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:10 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:10 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:10 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 24 (62.5%):  46%|██████████████████████████████████                                        | 23/50 [00:01<00:02, 12.76it/s]2025-08-18 21:33:10 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:11 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:11 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 25 (64.0%):  48%|███████████████████████████████████▌                                      | 24/50 [00:01<00:02, 12.76it/s]2025-08-18 21:33:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 16.00 / 25 (64.0%):  50%|█████████████████████████████████████                                     | 25/50 [00:01<00:01, 16.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:11 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:11 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 26 (65.4%):  50%|█████████████████████████████████████                                     | 25/50 [00:01<00:01, 16.80it/s]2025-08-18 21:33:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:11 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:11 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 27 (66.7%):  52%|██████████████████████████████████████▍                                   | 26/50 [00:01<00:01, 16.80it/s]2025-08-18 21:33:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:11 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:11 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 18.00 / 28 (64.3%):  54%|███████████████████████████████████████▉                                  | 27/50 [00:02<00:01, 16.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 18.00 / 28 (64.3%):  56%|█████████████████████████████████████████▍                                | 28/50 [00:02<00:01, 15.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:11 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:11 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:11 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 29 (62.1%):  56%|█████████████████████████████████████████▍                                | 28/50 [00:02<00:01, 15.10it/s]2025-08-18 21:33:11 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 30 (63.3%):  58%|██████████████████████████████████████████▉                               | 29/50 [00:02<00:01, 15.10it/s]2025-08-18 21:33:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:11 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:11 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 31 (61.3%):  60%|████████████████████████████████████████████▍                             | 30/50 [00:02<00:01, 15.10it/s]2025-08-18 21:33:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:11 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:11 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 32 (59.4%):  62%|█████████████████████████████████████████████▉                            | 31/50 [00:02<00:01, 15.10it/s]2025-08-18 21:33:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:11 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:11 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 33 (60.6%):  64%|███████████████████████████████████████████████▎                          | 32/50 [00:02<00:01, 15.10it/s]2025-08-18 21:33:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 20.00 / 33 (60.6%):  66%|████████████████████████████████████████████████▊                         | 33/50 [00:02<00:01, 16.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:11 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:11 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 21.00 / 34 (61.8%):  66%|████████████████████████████████████████████████▊                         | 33/50 [00:02<00:01, 16.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:11 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:11 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 22.00 / 35 (62.9%):  68%|██████████████████████████████████████████████████▎                       | 34/50 [00:02<00:00, 16.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 22.00 / 35 (62.9%):  70%|███████████████████████████████████████████████████▊                      | 35/50 [00:02<00:01, 14.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:11 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:11 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 36 (63.9%):  70%|███████████████████████████████████████████████████▊                      | 35/50 [00:02<00:01, 14.79it/s]2025-08-18 21:33:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:11 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:11 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 37 (62.2%):  72%|█████████████████████████████████████████████████████▎                    | 36/50 [00:02<00:00, 14.79it/s]2025-08-18 21:33:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:11 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:11 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 38 (60.5%):  74%|██████████████████████████████████████████████████████▊                   | 37/50 [00:02<00:00, 14.79it/s]2025-08-18 21:33:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:11 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:11 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 39 (61.5%):  76%|████████████████████████████████████████████████████████▏                 | 38/50 [00:02<00:00, 14.79it/s]2025-08-18 21:33:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:11 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:11 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 25.00 / 40 (62.5%):  78%|█████████████████████████████████████████████████████████▋                | 39/50 [00:02<00:00, 14.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.00 / 40 (62.5%):  80%|███████████████████████████████████████████████████████████▏              | 40/50 [00:02<00:00, 20.01it/s]2025-08-18 21:33:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:11 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:11 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 26.00 / 41 (63.4%):  80%|███████████████████████████████████████████████████████████▏              | 40/50 [00:02<00:00, 20.01it/s]2025-08-18 21:33:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:12 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:12 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:12 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 26.00 / 42 (61.9%):  82%|████████████████████████████████████████████████████████████▋             | 41/50 [00:02<00:00, 20.01it/s]2025-08-18 21:33:12 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:12 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:12 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:12 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 26.00 / 43 (60.5%):  86%|███████████████████████████████████████████████████████████████▋          | 43/50 [00:02<00:00, 15.28it/s]2025-08-18 21:33:12 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 27.00 / 44 (61.4%):  86%|███████████████████████████████████████████████████████████████▋          | 43/50 [00:02<00:00, 15.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:12 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:12 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 27.00 / 45 (60.0%):  88%|█████████████████████████████████████████████████████████████████         | 44/50 [00:02<00:00, 15.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:12 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:12 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:12 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 28.00 / 46 (60.9%):  90%|██████████████████████████████████████████████████████████████████▌       | 45/50 [00:03<00:00, 15.28it/s]2025-08-18 21:33:12 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:12 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 28.00 / 46 (60.9%):  92%|████████████████████████████████████████████████████████████████████      | 46/50 [00:03<00:00, 17.02it/s]2025-08-18 21:33:12 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 30.00 / 48 (62.5%):  94%|█████████████████████████████████████████████████████████████████████▌    | 47/50 [00:03<00:00, 17.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:12 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:12 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 31.00 / 49 (63.3%):  98%|████████████████████████████████████████████████████████████████████████▌ | 49/50 [00:03<00:00, 17.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:12 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:12 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 31.00 / 50 (62.0%): 100%|██████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 14.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/18 21:33:12 INFO dspy.evaluate.evaluate: Average Metric: 31 / 50 (62.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/18 21:33:12 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 62.0 with parameters ['Predictor 0: Instruction 4', 'Predictor 0: Few-Shot Set 6'].\n",
      "2025/08/18 21:33:12 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [74.0, 72.0, 70.0, 58.0, 62.0, 62.0]\n",
      "2025/08/18 21:33:12 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 74.0\n",
      "2025/08/18 21:33:12 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/08/18 21:33:12 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 7 / 18 =====\n",
      "\u001b[92m21:33:12 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:12 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:12 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:33:12 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:12 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:33:12 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "  0%|                                                                                                                       | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:12 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:12 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:12 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:12 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:12 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:12 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:12 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:12 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:12 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:12 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:13 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:13 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:13 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 1 (100.0%):   0%|                                                                                    | 0/50 [00:00<?, ?it/s]2025-08-18 21:33:13 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 1 (100.0%):   2%|█▌                                                                          | 1/50 [00:00<00:24,  2.00it/s]2025-08-18 21:33:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:13 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 2 (100.0%):   2%|█▌                                                                          | 1/50 [00:00<00:24,  2.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:13 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:13 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 3 (66.7%):   4%|███                                                                          | 2/50 [00:00<00:23,  2.00it/s]2025-08-18 21:33:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:33:13 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:13 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:33:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 3.00 / 4 (75.0%):   6%|████▌                                                                        | 3/50 [00:00<00:23,  2.00it/s]2025-08-18 21:33:13 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:33:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 5 (60.0%):   8%|██████▏                                                                      | 4/50 [00:00<00:22,  2.00it/s]2025-08-18 21:33:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:33:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:13 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:13 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 6 (50.0%):  10%|███████▋                                                                     | 5/50 [00:00<00:22,  2.00it/s]2025-08-18 21:33:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:13 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:13 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 7 (57.1%):  12%|█████████▏                                                                   | 6/50 [00:00<00:21,  2.00it/s]2025-08-18 21:33:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:13 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:13 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 8 (62.5%):  14%|██████████▊                                                                  | 7/50 [00:00<00:21,  2.00it/s]2025-08-18 21:33:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:13 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:13 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 9 (66.7%):  16%|████████████▎                                                                | 8/50 [00:00<00:20,  2.00it/s]2025-08-18 21:33:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 6.00 / 9 (66.7%):  18%|█████████████▊                                                               | 9/50 [00:00<00:03, 10.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:13 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:13 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:13 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:13 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 7.00 / 10 (70.0%):  18%|█████████████▋                                                              | 9/50 [00:01<00:03, 10.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:13 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:13 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 8.00 / 11 (72.7%):  20%|███████████████                                                            | 10/50 [00:01<00:03, 10.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 9.00 / 12 (75.0%):  22%|████████████████▌                                                          | 11/50 [00:01<00:03, 10.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:13 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:13 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 13 (76.9%):  24%|█████████████████▊                                                        | 12/50 [00:01<00:03, 10.34it/s]2025-08-18 21:33:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:13 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:13 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 14 (78.6%):  26%|███████████████████▏                                                      | 13/50 [00:01<00:03, 10.34it/s]2025-08-18 21:33:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:13 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:13 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 15 (73.3%):  28%|████████████████████▋                                                     | 14/50 [00:01<00:03, 10.34it/s]2025-08-18 21:33:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:13 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:13 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 12.00 / 16 (75.0%):  30%|██████████████████████▏                                                   | 15/50 [00:01<00:03, 10.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 16 (75.0%):  32%|███████████████████████▋                                                  | 16/50 [00:01<00:01, 17.24it/s]2025-08-18 21:33:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:14 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:14 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:14 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 17 (70.6%):  32%|███████████████████████▋                                                  | 16/50 [00:01<00:01, 17.24it/s]2025-08-18 21:33:14 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:14 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:14 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:14 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 18 (72.2%):  34%|█████████████████████████▏                                                | 17/50 [00:01<00:01, 17.24it/s]2025-08-18 21:33:14 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:14 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 19 (68.4%):  36%|██████████████████████████▋                                               | 18/50 [00:01<00:01, 17.24it/s]2025-08-18 21:33:14 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:14 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 19 (68.4%):  38%|████████████████████████████                                              | 19/50 [00:01<00:02, 13.87it/s]2025-08-18 21:33:14 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:14 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 20 (65.0%):  38%|████████████████████████████                                              | 19/50 [00:01<00:02, 13.87it/s]2025-08-18 21:33:14 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:14 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:33:14 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:14 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 14.00 / 21 (66.7%):  40%|█████████████████████████████▌                                            | 20/50 [00:01<00:02, 13.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:14 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:14 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:14 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:14 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 15.00 / 22 (68.2%):  42%|███████████████████████████████                                           | 21/50 [00:01<00:02, 13.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:14 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:14 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:33:14 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:14 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:14 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:14 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 23 (69.6%):  44%|████████████████████████████████▌                                         | 22/50 [00:01<00:02, 13.87it/s]2025-08-18 21:33:14 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:14 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:14 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:14 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 24 (66.7%):  46%|██████████████████████████████████                                        | 23/50 [00:01<00:01, 13.87it/s]2025-08-18 21:33:14 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 16.00 / 24 (66.7%):  48%|███████████████████████████████████▌                                      | 24/50 [00:01<00:01, 16.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:14 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:14 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 17.00 / 25 (68.0%):  48%|███████████████████████████████████▌                                      | 24/50 [00:01<00:01, 16.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:14 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:14 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:14 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:14 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 18.00 / 26 (69.2%):  50%|█████████████████████████████████████                                     | 25/50 [00:01<00:01, 16.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:14 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:14 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:14 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:14 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:14 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 27 (70.4%):  52%|██████████████████████████████████████▍                                   | 26/50 [00:01<00:01, 16.93it/s]2025-08-18 21:33:14 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 19.00 / 27 (70.4%):  54%|███████████████████████████████████████▉                                  | 27/50 [00:01<00:01, 14.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:14 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:14 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:14 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:14 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:14 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 28 (71.4%):  54%|███████████████████████████████████████▉                                  | 27/50 [00:02<00:01, 14.61it/s]2025-08-18 21:33:14 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 21.00 / 29 (72.4%):  56%|█████████████████████████████████████████▍                                | 28/50 [00:02<00:01, 14.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:14 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:14 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:14 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:14 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:14 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 30 (73.3%):  58%|██████████████████████████████████████████▉                               | 29/50 [00:02<00:01, 14.61it/s]2025-08-18 21:33:14 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:14 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:14 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:14 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 31 (74.2%):  60%|████████████████████████████████████████████▍                             | 30/50 [00:02<00:01, 14.61it/s]2025-08-18 21:33:14 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:14 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:14 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:14 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 32 (71.9%):  62%|█████████████████████████████████████████████▉                            | 31/50 [00:02<00:01, 14.61it/s]2025-08-18 21:33:14 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 23.00 / 32 (71.9%):  64%|███████████████████████████████████████████████▎                          | 32/50 [00:02<00:01, 17.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:15 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:15 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:15 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:15 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 24.00 / 33 (72.7%):  64%|███████████████████████████████████████████████▎                          | 32/50 [00:02<00:01, 17.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:15 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:15 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 25.00 / 34 (73.5%):  66%|████████████████████████████████████████████████▊                         | 33/50 [00:02<00:00, 17.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:15 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.00 / 34 (73.5%):  68%|██████████████████████████████████████████████████▎                       | 34/50 [00:02<00:01, 13.98it/s]2025-08-18 21:33:15 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:15 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:15 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:15 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.00 / 35 (71.4%):  68%|██████████████████████████████████████████████████▎                       | 34/50 [00:02<00:01, 13.98it/s]2025-08-18 21:33:15 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:15 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:33:15 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:15 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:33:15 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 26.00 / 36 (72.2%):  70%|███████████████████████████████████████████████████▊                      | 35/50 [00:02<00:01, 13.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:15 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:33:15 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 26.00 / 37 (70.3%):  72%|█████████████████████████████████████████████████████▎                    | 36/50 [00:02<00:01, 13.98it/s]2025-08-18 21:33:15 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:33:15 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 27.00 / 38 (71.1%):  74%|██████████████████████████████████████████████████████▊                   | 37/50 [00:02<00:00, 13.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:15 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:15 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:15 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:15 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:15 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:15 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:15 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 28.00 / 39 (71.8%):  76%|████████████████████████████████████████████████████████▏                 | 38/50 [00:02<00:00, 13.98it/s]2025-08-18 21:33:15 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 28.00 / 39 (71.8%):  78%|█████████████████████████████████████████████████████████▋                | 39/50 [00:02<00:00, 18.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:15 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:15 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:15 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 28.00 / 40 (70.0%):  78%|█████████████████████████████████████████████████████████▋                | 39/50 [00:02<00:00, 18.84it/s]2025-08-18 21:33:15 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:15 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:15 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:15 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 29.00 / 41 (70.7%):  80%|███████████████████████████████████████████████████████████▏              | 40/50 [00:02<00:00, 18.84it/s]2025-08-18 21:33:15 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:15 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:15 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:15 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 30.00 / 42 (71.4%):  82%|████████████████████████████████████████████████████████████▋             | 41/50 [00:02<00:00, 18.84it/s]2025-08-18 21:33:15 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 30.00 / 42 (71.4%):  84%|██████████████████████████████████████████████████████████████▏           | 42/50 [00:02<00:00, 13.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:15 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:15 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 30.00 / 43 (69.8%):  84%|██████████████████████████████████████████████████████████████▏           | 42/50 [00:03<00:00, 13.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:15 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:15 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 31.00 / 44 (70.5%):  86%|███████████████████████████████████████████████████████████████▋          | 43/50 [00:03<00:00, 13.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:15 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:15 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 31.00 / 45 (68.9%):  88%|█████████████████████████████████████████████████████████████████         | 44/50 [00:03<00:00, 13.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:15 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:15 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 32.00 / 46 (69.6%):  90%|██████████████████████████████████████████████████████████████████▌       | 45/50 [00:03<00:00, 13.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:15 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:15 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 33.00 / 47 (70.2%):  92%|████████████████████████████████████████████████████████████████████      | 46/50 [00:03<00:00, 13.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:15 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:15 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 34.00 / 48 (70.8%):  96%|███████████████████████████████████████████████████████████████████████   | 48/50 [00:03<00:00, 18.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:16 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:16 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 35.00 / 49 (71.4%):  96%|███████████████████████████████████████████████████████████████████████   | 48/50 [00:03<00:00, 18.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:16 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:16 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 36.00 / 50 (72.0%): 100%|██████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 14.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/18 21:33:16 INFO dspy.evaluate.evaluate: Average Metric: 36 / 50 (72.0%)\n",
      "2025/08/18 21:33:16 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 72.0 with parameters ['Predictor 0: Instruction 5', 'Predictor 0: Few-Shot Set 8'].\n",
      "2025/08/18 21:33:16 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [74.0, 72.0, 70.0, 58.0, 62.0, 62.0, 72.0]\n",
      "2025/08/18 21:33:16 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 74.0\n",
      "2025/08/18 21:33:16 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/08/18 21:33:16 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 8 / 18 =====\n",
      "\u001b[92m21:33:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-08-18 21:33:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:33:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:33:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                       | 0/50 [00:00<?, ?it/s]2025-08-18 21:33:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:16 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:16 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:16 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:16 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 1.00 / 1 (100.0%):   0%|                                                                                    | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:16 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:16 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 1.00 / 1 (100.0%):   2%|█▌                                                                          | 1/50 [00:00<00:21,  2.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 2.00 / 2 (100.0%):   2%|█▌                                                                          | 1/50 [00:00<00:21,  2.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 3.00 / 3 (100.0%):   4%|███                                                                         | 2/50 [00:00<00:21,  2.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:16 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:16 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 4 (75.0%):   6%|████▌                                                                        | 3/50 [00:00<00:20,  2.27it/s]2025-08-18 21:33:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:16 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:16 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 5 (60.0%):   8%|██████▏                                                                      | 4/50 [00:00<00:20,  2.27it/s]2025-08-18 21:33:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:16 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:16 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 6 (66.7%):  10%|███████▋                                                                     | 5/50 [00:00<00:19,  2.27it/s]2025-08-18 21:33:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:16 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:16 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 7 (57.1%):  12%|█████████▏                                                                   | 6/50 [00:00<00:19,  2.27it/s]2025-08-18 21:33:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:16 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:16 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 8 (62.5%):  14%|██████████▊                                                                  | 7/50 [00:00<00:18,  2.27it/s]2025-08-18 21:33:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 9 (66.7%):  18%|█████████████▊                                                               | 9/50 [00:00<00:03, 11.77it/s]2025-08-18 21:33:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 10 (70.0%):  18%|█████████████▋                                                              | 9/50 [00:00<00:03, 11.77it/s]2025-08-18 21:33:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 11 (72.7%):  20%|███████████████                                                            | 10/50 [00:00<00:03, 11.77it/s]2025-08-18 21:33:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 12 (75.0%):  22%|████████████████▌                                                          | 11/50 [00:00<00:03, 11.77it/s]2025-08-18 21:33:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 13 (76.9%):  24%|█████████████████▊                                                        | 12/50 [00:00<00:03, 11.77it/s]2025-08-18 21:33:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 10.00 / 14 (71.4%):  26%|███████████████████▏                                                      | 13/50 [00:00<00:03, 11.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 15 (73.3%):  28%|████████████████████▋                                                     | 14/50 [00:00<00:03, 11.77it/s]2025-08-18 21:33:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 16 (75.0%):  30%|██████████████████████▏                                                   | 15/50 [00:01<00:02, 11.77it/s]2025-08-18 21:33:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 12.00 / 16 (75.0%):  32%|███████████████████████▋                                                  | 16/50 [00:01<00:01, 20.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 17 (76.5%):  32%|███████████████████████▋                                                  | 16/50 [00:01<00:01, 20.06it/s]2025-08-18 21:33:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 18 (77.8%):  34%|█████████████████████████▏                                                | 17/50 [00:01<00:01, 20.06it/s]2025-08-18 21:33:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 15.00 / 19 (78.9%):  36%|██████████████████████████▋                                               | 18/50 [00:01<00:01, 20.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 16.00 / 20 (80.0%):  38%|████████████████████████████                                              | 19/50 [00:01<00:01, 20.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 16.00 / 20 (80.0%):  40%|█████████████████████████████▌                                            | 20/50 [00:01<00:01, 16.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 17.00 / 21 (81.0%):  40%|█████████████████████████████▌                                            | 20/50 [00:01<00:01, 16.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 18.00 / 22 (81.8%):  42%|███████████████████████████████                                           | 21/50 [00:01<00:01, 16.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 23 (78.3%):  44%|████████████████████████████████▌                                         | 22/50 [00:01<00:01, 16.03it/s]2025-08-18 21:33:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 24 (79.2%):  46%|██████████████████████████████████                                        | 23/50 [00:01<00:01, 16.03it/s]2025-08-18 21:33:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 25 (80.0%):  48%|███████████████████████████████████▌                                      | 24/50 [00:01<00:01, 16.03it/s]2025-08-18 21:33:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 20.00 / 25 (80.0%):  50%|█████████████████████████████████████                                     | 25/50 [00:01<00:01, 14.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 26 (80.8%):  50%|█████████████████████████████████████                                     | 25/50 [00:01<00:01, 14.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:33:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 27 (77.8%):  52%|██████████████████████████████████████▍                                   | 26/50 [00:01<00:01, 14.80it/s]2025-08-18 21:33:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 28 (78.6%):  54%|███████████████████████████████████████▉                                  | 27/50 [00:01<00:01, 14.80it/s]2025-08-18 21:33:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 29 (79.3%):  56%|█████████████████████████████████████████▍                                | 28/50 [00:01<00:01, 14.80it/s]2025-08-18 21:33:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 30 (76.7%):  58%|██████████████████████████████████████████▉                               | 29/50 [00:01<00:01, 14.80it/s]2025-08-18 21:33:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 31 (74.2%):  60%|████████████████████████████████████████████▍                             | 30/50 [00:01<00:01, 14.80it/s]2025-08-18 21:33:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 32 (71.9%):  62%|█████████████████████████████████████████████▉                            | 31/50 [00:01<00:01, 14.80it/s]2025-08-18 21:33:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 23.00 / 32 (71.9%):  64%|███████████████████████████████████████████████▎                          | 32/50 [00:01<00:00, 20.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 33 (72.7%):  64%|███████████████████████████████████████████████▎                          | 32/50 [00:02<00:00, 20.90it/s]2025-08-18 21:33:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.00 / 34 (73.5%):  66%|████████████████████████████████████████████████▊                         | 33/50 [00:02<00:00, 20.90it/s]2025-08-18 21:33:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:33:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:33:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 26.00 / 35 (74.3%):  68%|██████████████████████████████████████████████████▎                       | 34/50 [00:02<00:00, 20.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 26.00 / 35 (74.3%):  70%|███████████████████████████████████████████████████▊                      | 35/50 [00:02<00:00, 15.36it/s]2025-08-18 21:33:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27.00 / 36 (75.0%):  70%|███████████████████████████████████████████████████▊                      | 35/50 [00:02<00:00, 15.36it/s]2025-08-18 21:33:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27.00 / 37 (73.0%):  72%|█████████████████████████████████████████████████████▎                    | 36/50 [00:02<00:00, 15.36it/s]2025-08-18 21:33:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27.00 / 38 (71.1%):  74%|██████████████████████████████████████████████████████▊                   | 37/50 [00:02<00:00, 15.36it/s]2025-08-18 21:33:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 28.00 / 39 (71.8%):  76%|████████████████████████████████████████████████████████▏                 | 38/50 [00:02<00:00, 15.36it/s]2025-08-18 21:33:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 29.00 / 40 (72.5%):  78%|█████████████████████████████████████████████████████████▋                | 39/50 [00:02<00:00, 15.36it/s]2025-08-18 21:33:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 29.00 / 40 (72.5%):  80%|███████████████████████████████████████████████████████████▏              | 40/50 [00:02<00:00, 17.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 30.00 / 41 (73.2%):  80%|███████████████████████████████████████████████████████████▏              | 40/50 [00:02<00:00, 17.01it/s]2025-08-18 21:33:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 31.00 / 42 (73.8%):  82%|████████████████████████████████████████████████████████████▋             | 41/50 [00:02<00:00, 17.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 32.00 / 43 (74.4%):  86%|███████████████████████████████████████████████████████████████▋          | 43/50 [00:02<00:00, 16.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 32.00 / 44 (72.7%):  86%|███████████████████████████████████████████████████████████████▋          | 43/50 [00:02<00:00, 16.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:19 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:19 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:19 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 32.00 / 45 (71.1%):  88%|█████████████████████████████████████████████████████████████████         | 44/50 [00:02<00:00, 16.22it/s]2025-08-18 21:33:19 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 33.00 / 46 (71.7%):  90%|██████████████████████████████████████████████████████████████████▌       | 45/50 [00:02<00:00, 16.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:19 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:19 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 34.00 / 47 (72.3%):  94%|█████████████████████████████████████████████████████████████████████▌    | 47/50 [00:02<00:00, 18.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:19 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:19 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 35.00 / 48 (72.9%):  94%|█████████████████████████████████████████████████████████████████████▌    | 47/50 [00:02<00:00, 18.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:19 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:19 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 36.00 / 49 (73.5%):  96%|███████████████████████████████████████████████████████████████████████   | 48/50 [00:03<00:00, 18.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:19 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:19 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 37.00 / 50 (74.0%): 100%|██████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 16.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/18 21:33:19 INFO dspy.evaluate.evaluate: Average Metric: 37 / 50 (74.0%)\n",
      "2025/08/18 21:33:19 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 74.0 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 0'].\n",
      "2025/08/18 21:33:19 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [74.0, 72.0, 70.0, 58.0, 62.0, 62.0, 72.0, 74.0]\n",
      "2025/08/18 21:33:19 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 74.0\n",
      "2025/08/18 21:33:19 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/08/18 21:33:19 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 9 / 18 =====\n",
      "\u001b[92m21:33:19 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-08-18 21:33:19 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:19 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:33:19 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:19 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:33:19 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "  0%|                                                                                                                       | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:19 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:19 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:19 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:19 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:19 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:19 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:19 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:19 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:19 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:19 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:19 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:19 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 0.00 / 1 (0.0%):   0%|                                                                                      | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:19 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 1 (0.0%):   2%|█▌                                                                            | 1/50 [00:00<00:20,  2.45it/s]2025-08-18 21:33:19 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:19 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:19 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:19 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 2 (50.0%):   2%|█▌                                                                           | 1/50 [00:00<00:20,  2.45it/s]2025-08-18 21:33:19 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:19 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:19 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:19 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 3 (33.3%):   4%|███                                                                          | 2/50 [00:00<00:19,  2.45it/s]2025-08-18 21:33:19 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:19 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 3 (33.3%):   6%|████▌                                                                        | 3/50 [00:00<00:08,  5.27it/s]2025-08-18 21:33:19 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:20 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 4 (50.0%):   6%|████▌                                                                        | 3/50 [00:00<00:08,  5.27it/s]2025-08-18 21:33:20 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:20 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:33:20 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:20 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 2.00 / 5 (40.0%):   8%|██████▏                                                                      | 4/50 [00:00<00:08,  5.27it/s]2025-08-18 21:33:20 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:20 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:20 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 3.00 / 6 (50.0%):  10%|███████▋                                                                     | 5/50 [00:00<00:08,  5.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:20 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:20 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 3.00 / 7 (42.9%):  12%|█████████▏                                                                   | 6/50 [00:00<00:08,  5.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:20 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:33:20 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:20 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 4.00 / 8 (50.0%):  14%|██████████▊                                                                  | 7/50 [00:00<00:08,  5.27it/s]2025-08-18 21:33:20 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:20 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:33:20 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:20 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:33:20 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:20 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:20 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 5.00 / 9 (55.6%):  16%|████████████▎                                                                | 8/50 [00:00<00:07,  5.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:20 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 9 (55.6%):  18%|█████████████▊                                                               | 9/50 [00:00<00:02, 14.57it/s]2025-08-18 21:33:20 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:20 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:20 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 6.00 / 10 (60.0%):  18%|█████████████▋                                                              | 9/50 [00:01<00:02, 14.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:20 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:20 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:20 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:20 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:20 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 11 (63.6%):  20%|███████████████                                                            | 10/50 [00:01<00:02, 14.57it/s]2025-08-18 21:33:20 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 7.00 / 11 (63.6%):  22%|████████████████▌                                                          | 11/50 [00:01<00:03, 11.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:20 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:20 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:20 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 12 (66.7%):  22%|████████████████▌                                                          | 11/50 [00:01<00:03, 11.09it/s]2025-08-18 21:33:20 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:20 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:20 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:20 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 13 (69.2%):  24%|██████████████████                                                         | 12/50 [00:01<00:03, 11.09it/s]2025-08-18 21:33:20 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:20 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:20 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:20 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 14 (71.4%):  26%|███████████████████▏                                                      | 13/50 [00:01<00:03, 11.09it/s]2025-08-18 21:33:20 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:20 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:20 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:20 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 15 (73.3%):  28%|████████████████████▋                                                     | 14/50 [00:01<00:03, 11.09it/s]2025-08-18 21:33:20 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:20 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:20 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:20 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 16 (75.0%):  30%|██████████████████████▏                                                   | 15/50 [00:01<00:03, 11.09it/s]2025-08-18 21:33:20 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:20 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:20 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:20 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 17 (70.6%):  32%|███████████████████████▋                                                  | 16/50 [00:01<00:03, 11.09it/s]2025-08-18 21:33:20 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 12.00 / 17 (70.6%):  34%|█████████████████████████▏                                                | 17/50 [00:01<00:02, 15.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:20 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:20 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:20 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 18 (72.2%):  34%|█████████████████████████▏                                                | 17/50 [00:01<00:02, 15.76it/s]2025-08-18 21:33:20 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:21 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:21 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:21 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 19 (73.7%):  36%|██████████████████████████▋                                               | 18/50 [00:01<00:02, 15.76it/s]2025-08-18 21:33:21 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 14.00 / 19 (73.7%):  38%|████████████████████████████                                              | 19/50 [00:01<00:02, 12.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:21 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:21 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:21 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 20 (70.0%):  38%|████████████████████████████                                              | 19/50 [00:01<00:02, 12.18it/s]2025-08-18 21:33:21 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:21 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:21 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 15.00 / 21 (71.4%):  40%|█████████████████████████████▌                                            | 20/50 [00:01<00:02, 12.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:21 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:21 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:21 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:21 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 15.00 / 22 (68.2%):  42%|███████████████████████████████                                           | 21/50 [00:01<00:02, 12.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:21 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 22 (68.2%):  44%|████████████████████████████████▌                                         | 22/50 [00:01<00:02, 13.91it/s]2025-08-18 21:33:21 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:21 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:21 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 16.00 / 23 (69.6%):  44%|████████████████████████████████▌                                         | 22/50 [00:01<00:02, 13.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:21 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:21 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:21 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:21 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 17.00 / 24 (70.8%):  46%|██████████████████████████████████                                        | 23/50 [00:01<00:01, 13.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:21 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 24 (70.8%):  48%|███████████████████████████████████▌                                      | 24/50 [00:01<00:01, 14.66it/s]2025-08-18 21:33:21 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:21 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:21 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:21 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 25 (68.0%):  48%|███████████████████████████████████▌                                      | 24/50 [00:01<00:01, 14.66it/s]2025-08-18 21:33:21 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:21 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:21 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:21 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 26 (69.2%):  50%|█████████████████████████████████████                                     | 25/50 [00:02<00:01, 14.66it/s]2025-08-18 21:33:21 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 18.00 / 26 (69.2%):  52%|██████████████████████████████████████▍                                   | 26/50 [00:02<00:01, 13.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:21 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:21 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:21 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 27 (70.4%):  52%|██████████████████████████████████████▍                                   | 26/50 [00:02<00:01, 13.05it/s]2025-08-18 21:33:21 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:21 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:21 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:21 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 28 (67.9%):  54%|███████████████████████████████████████▉                                  | 27/50 [00:02<00:01, 13.05it/s]2025-08-18 21:33:21 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:21 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:21 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:21 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 29 (69.0%):  56%|█████████████████████████████████████████▍                                | 28/50 [00:02<00:01, 13.05it/s]2025-08-18 21:33:21 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 20.00 / 29 (69.0%):  58%|██████████████████████████████████████████▉                               | 29/50 [00:02<00:01, 15.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:21 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:21 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:21 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 30 (66.7%):  58%|██████████████████████████████████████████▉                               | 29/50 [00:02<00:01, 15.53it/s]2025-08-18 21:33:21 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:21 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:21 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:21 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 31 (64.5%):  60%|████████████████████████████████████████████▍                             | 30/50 [00:02<00:01, 15.53it/s]2025-08-18 21:33:21 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 20.00 / 31 (64.5%):  62%|█████████████████████████████████████████████▉                            | 31/50 [00:02<00:01, 11.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:21 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:21 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:21 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 32 (62.5%):  62%|█████████████████████████████████████████████▉                            | 31/50 [00:02<00:01, 11.52it/s]2025-08-18 21:33:21 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 33 (63.6%):  64%|███████████████████████████████████████████████▎                          | 32/50 [00:02<00:01, 11.52it/s]2025-08-18 21:33:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:22 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:22 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 21.00 / 33 (63.6%):  66%|████████████████████████████████████████████████▊                         | 33/50 [00:02<00:01, 12.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:22 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:22 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 21.00 / 34 (61.8%):  66%|████████████████████████████████████████████████▊                         | 33/50 [00:02<00:01, 12.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:22 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 35 (62.9%):  68%|██████████████████████████████████████████████████▎                       | 34/50 [00:02<00:01, 12.93it/s]2025-08-18 21:33:22 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:22 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 36 (61.1%):  70%|███████████████████████████████████████████████████▊                      | 35/50 [00:02<00:01, 12.93it/s]2025-08-18 21:33:22 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 22.00 / 36 (61.1%):  72%|█████████████████████████████████████████████████████▎                    | 36/50 [00:02<00:00, 16.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:22 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 37 (59.5%):  72%|█████████████████████████████████████████████████████▎                    | 36/50 [00:02<00:00, 16.00it/s]2025-08-18 21:33:22 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:22 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 38 (57.9%):  74%|██████████████████████████████████████████████████████▊                   | 37/50 [00:02<00:00, 16.00it/s]2025-08-18 21:33:22 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 22.00 / 38 (57.9%):  76%|████████████████████████████████████████████████████████▏                 | 38/50 [00:02<00:00, 16.38it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:22 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 39 (56.4%):  76%|████████████████████████████████████████████████████████▏                 | 38/50 [00:03<00:00, 16.38it/s]2025-08-18 21:33:22 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:22 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 40 (57.5%):  78%|█████████████████████████████████████████████████████████▋                | 39/50 [00:03<00:00, 16.38it/s]2025-08-18 21:33:22 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 23.00 / 40 (57.5%):  80%|███████████████████████████████████████████████████████████▏              | 40/50 [00:03<00:00, 12.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:22 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 41 (58.5%):  80%|███████████████████████████████████████████████████████████▏              | 40/50 [00:03<00:00, 12.57it/s]2025-08-18 21:33:22 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:22 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.00 / 42 (59.5%):  82%|████████████████████████████████████████████████████████████▋             | 41/50 [00:03<00:00, 12.57it/s]2025-08-18 21:33:22 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 26.00 / 43 (60.5%):  84%|██████████████████████████████████████████████████████████████▏           | 42/50 [00:03<00:00, 12.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 27.00 / 44 (61.4%):  88%|█████████████████████████████████████████████████████████████████         | 44/50 [00:03<00:00, 17.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 27.00 / 45 (60.0%):  88%|█████████████████████████████████████████████████████████████████         | 44/50 [00:03<00:00, 17.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 28.00 / 46 (60.9%):  90%|██████████████████████████████████████████████████████████████████▌       | 45/50 [00:03<00:00, 17.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:23 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:23 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 28.00 / 47 (59.6%):  94%|█████████████████████████████████████████████████████████████████████▌    | 47/50 [00:03<00:00, 11.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:23 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:23 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 28.00 / 48 (58.3%):  94%|█████████████████████████████████████████████████████████████████████▌    | 47/50 [00:03<00:00, 11.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:23 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:23 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 29.00 / 49 (59.2%):  96%|███████████████████████████████████████████████████████████████████████   | 48/50 [00:03<00:00, 11.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:23 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:23 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 29.00 / 50 (58.0%): 100%|██████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 13.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/18 21:33:23 INFO dspy.evaluate.evaluate: Average Metric: 29 / 50 (58.0%)\n",
      "2025/08/18 21:33:23 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 58.0 with parameters ['Predictor 0: Instruction 3', 'Predictor 0: Few-Shot Set 1'].\n",
      "2025/08/18 21:33:23 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [74.0, 72.0, 70.0, 58.0, 62.0, 62.0, 72.0, 74.0, 58.0]\n",
      "2025/08/18 21:33:23 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 74.0\n",
      "2025/08/18 21:33:23 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/08/18 21:33:23 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 10 / 18 =====\n",
      "\u001b[92m21:33:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-08-18 21:33:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                       | 0/50 [00:00<?, ?it/s]2025-08-18 21:33:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:23 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:23 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 1 (100.0%):   0%|                                                                                    | 0/50 [00:00<?, ?it/s]2025-08-18 21:33:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 1.00 / 1 (100.0%):   2%|█▌                                                                          | 1/50 [00:00<00:22,  2.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:23 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:23 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 2.00 / 2 (100.0%):   2%|█▌                                                                          | 1/50 [00:00<00:22,  2.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:23 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:23 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:23 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:23 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 3.00 / 3 (100.0%):   4%|███                                                                         | 2/50 [00:00<00:22,  2.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 4 (100.0%):   6%|████▌                                                                       | 3/50 [00:00<00:21,  2.18it/s]2025-08-18 21:33:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:23 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:23 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 5 (100.0%):   8%|██████                                                                      | 4/50 [00:00<00:21,  2.18it/s]2025-08-18 21:33:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:23 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:23 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:23 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 6 (83.3%):  10%|███████▋                                                                     | 5/50 [00:00<00:20,  2.18it/s]2025-08-18 21:33:23 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 6 (83.3%):  12%|█████████▏                                                                   | 6/50 [00:00<00:03, 13.40it/s]2025-08-18 21:33:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 7 (85.7%):  12%|█████████▏                                                                   | 6/50 [00:00<00:03, 13.40it/s]2025-08-18 21:33:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:23 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:23 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 8 (87.5%):  14%|██████████▊                                                                  | 7/50 [00:00<00:03, 13.40it/s]2025-08-18 21:33:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 9 (88.9%):  16%|████████████▎                                                                | 8/50 [00:00<00:03, 13.40it/s]2025-08-18 21:33:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 9 (88.9%):  18%|█████████████▊                                                               | 9/50 [00:00<00:04,  9.87it/s]2025-08-18 21:33:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:24 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:24 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 9.00 / 10 (90.0%):  18%|█████████████▋                                                              | 9/50 [00:00<00:04,  9.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:24 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 11 (90.9%):  20%|██████████████▊                                                           | 10/50 [00:00<00:04,  9.87it/s]2025-08-18 21:33:24 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:24 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:24 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 11.00 / 12 (91.7%):  22%|████████████████▎                                                         | 11/50 [00:01<00:03,  9.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:24 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:24 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:24 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 13 (92.3%):  24%|█████████████████▊                                                        | 12/50 [00:01<00:03,  9.87it/s]2025-08-18 21:33:24 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:24 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 14 (92.9%):  26%|███████████████████▏                                                      | 13/50 [00:01<00:03,  9.87it/s]2025-08-18 21:33:24 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 13.00 / 14 (92.9%):  28%|████████████████████▋                                                     | 14/50 [00:01<00:02, 15.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:24 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 15 (86.7%):  28%|████████████████████▋                                                     | 14/50 [00:01<00:02, 15.84it/s]2025-08-18 21:33:24 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:24 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 16 (87.5%):  30%|██████████████████████▏                                                   | 15/50 [00:01<00:02, 15.84it/s]2025-08-18 21:33:24 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 15.00 / 17 (88.2%):  32%|███████████████████████▋                                                  | 16/50 [00:01<00:02, 15.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:24 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:24 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 15.00 / 17 (88.2%):  34%|█████████████████████████▏                                                | 17/50 [00:01<00:02, 12.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 18 (88.9%):  34%|█████████████████████████▏                                                | 17/50 [00:01<00:02, 12.21it/s]2025-08-18 21:33:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:24 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:24 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 16.00 / 19 (84.2%):  36%|██████████████████████████▋                                               | 18/50 [00:01<00:02, 12.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:24 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:24 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:24 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 20 (85.0%):  38%|████████████████████████████                                              | 19/50 [00:01<00:02, 12.21it/s]2025-08-18 21:33:24 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:24 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 21 (85.7%):  40%|█████████████████████████████▌                                            | 20/50 [00:01<00:02, 12.21it/s]2025-08-18 21:33:24 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 22 (86.4%):  42%|███████████████████████████████                                           | 21/50 [00:01<00:02, 12.21it/s]2025-08-18 21:33:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:24 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:24 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 20.00 / 23 (87.0%):  44%|████████████████████████████████▌                                         | 22/50 [00:01<00:02, 12.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:24 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:24 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:24 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 24 (87.5%):  46%|██████████████████████████████████                                        | 23/50 [00:01<00:02, 12.21it/s]2025-08-18 21:33:24 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 21.00 / 24 (87.5%):  48%|███████████████████████████████████▌                                      | 24/50 [00:01<00:01, 19.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:25 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:25 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 25 (88.0%):  48%|███████████████████████████████████▌                                      | 24/50 [00:01<00:01, 19.86it/s]2025-08-18 21:33:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:25 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:25 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 26 (84.6%):  50%|█████████████████████████████████████                                     | 25/50 [00:01<00:01, 19.86it/s]2025-08-18 21:33:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:25 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:25 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 27 (85.2%):  52%|██████████████████████████████████████▍                                   | 26/50 [00:02<00:01, 19.86it/s]2025-08-18 21:33:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:25 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:25 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 28 (82.1%):  54%|███████████████████████████████████████▉                                  | 27/50 [00:02<00:01, 19.86it/s]2025-08-18 21:33:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 23.00 / 28 (82.1%):  56%|█████████████████████████████████████████▍                                | 28/50 [00:02<00:01, 15.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:25 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:25 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 29 (82.8%):  56%|█████████████████████████████████████████▍                                | 28/50 [00:02<00:01, 15.21it/s]2025-08-18 21:33:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:25 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:25 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 30 (80.0%):  58%|██████████████████████████████████████████▉                               | 29/50 [00:02<00:01, 15.21it/s]2025-08-18 21:33:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:25 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:25 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 31 (77.4%):  60%|████████████████████████████████████████████▍                             | 30/50 [00:02<00:01, 15.21it/s]2025-08-18 21:33:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:25 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:25 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 32 (75.0%):  62%|█████████████████████████████████████████████▉                            | 31/50 [00:02<00:01, 15.21it/s]2025-08-18 21:33:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 24.00 / 32 (75.0%):  64%|███████████████████████████████████████████████▎                          | 32/50 [00:02<00:01, 17.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:25 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:25 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 25.00 / 33 (75.8%):  64%|███████████████████████████████████████████████▎                          | 32/50 [00:02<00:01, 17.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:25 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:25 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.00 / 34 (73.5%):  66%|████████████████████████████████████████████████▊                         | 33/50 [00:02<00:00, 17.58it/s]2025-08-18 21:33:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:25 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:25 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 26.00 / 35 (74.3%):  68%|██████████████████████████████████████████████████▎                       | 34/50 [00:02<00:00, 17.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 26.00 / 35 (74.3%):  70%|███████████████████████████████████████████████████▊                      | 35/50 [00:02<00:01, 14.09it/s]2025-08-18 21:33:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:25 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:25 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:25 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27.00 / 36 (75.0%):  70%|███████████████████████████████████████████████████▊                      | 35/50 [00:02<00:01, 14.09it/s]2025-08-18 21:33:25 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 28.00 / 37 (75.7%):  72%|█████████████████████████████████████████████████████▎                    | 36/50 [00:02<00:00, 14.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:25 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:25 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 29.00 / 38 (76.3%):  74%|██████████████████████████████████████████████████████▊                   | 37/50 [00:02<00:00, 14.09it/s]2025-08-18 21:33:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:25 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:25 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 30.00 / 39 (76.9%):  76%|████████████████████████████████████████████████████████▏                 | 38/50 [00:02<00:00, 14.09it/s]2025-08-18 21:33:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:25 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:25 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 31.00 / 40 (77.5%):  80%|███████████████████████████████████████████████████████████▏              | 40/50 [00:02<00:00, 16.95it/s]2025-08-18 21:33:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:26 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:26 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:26 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 32.00 / 41 (78.0%):  80%|███████████████████████████████████████████████████████████▏              | 40/50 [00:02<00:00, 16.95it/s]2025-08-18 21:33:26 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:26 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:26 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 33.00 / 42 (78.6%):  82%|████████████████████████████████████████████████████████████▋             | 41/50 [00:02<00:00, 16.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:26 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:26 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:26 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:26 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 33.00 / 43 (76.7%):  86%|███████████████████████████████████████████████████████████████▋          | 43/50 [00:02<00:00, 15.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:26 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:26 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:26 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 33.00 / 44 (75.0%):  86%|███████████████████████████████████████████████████████████████▋          | 43/50 [00:02<00:00, 15.24it/s]2025-08-18 21:33:26 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:26 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 34.00 / 45 (75.6%):  88%|█████████████████████████████████████████████████████████████████         | 44/50 [00:02<00:00, 15.24it/s]2025-08-18 21:33:26 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 34.00 / 46 (73.9%):  90%|██████████████████████████████████████████████████████████████████▌       | 45/50 [00:03<00:00, 15.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:26 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:26 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 35.00 / 47 (74.5%):  92%|████████████████████████████████████████████████████████████████████      | 46/50 [00:03<00:00, 15.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:26 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:26 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 36.00 / 48 (75.0%):  96%|███████████████████████████████████████████████████████████████████████   | 48/50 [00:03<00:00, 16.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:26 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:26 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 37.00 / 49 (75.5%):  96%|███████████████████████████████████████████████████████████████████████   | 48/50 [00:03<00:00, 16.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:26 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:26 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 38.00 / 50 (76.0%): 100%|██████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 14.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/18 21:33:26 INFO dspy.evaluate.evaluate: Average Metric: 38 / 50 (76.0%)\n",
      "2025/08/18 21:33:26 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mBest full score so far!\u001b[0m Score: 76.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/18 21:33:26 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 76.0 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 7'].\n",
      "2025/08/18 21:33:26 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [74.0, 72.0, 70.0, 58.0, 62.0, 62.0, 72.0, 74.0, 58.0, 76.0]\n",
      "2025/08/18 21:33:26 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 76.0\n",
      "2025/08/18 21:33:26 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/08/18 21:33:26 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 11 / 18 =====\n",
      "\u001b[92m21:33:26 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:26 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:26 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:33:26 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:26 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "  0%|                                                                                                                       | 0/50 [00:00<?, ?it/s]2025-08-18 21:33:26 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:26 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:26 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:26 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:26 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:26 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:26 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:26 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:26 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:26 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:26 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:27 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:27 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 1.00 / 1 (100.0%):   0%|                                                                                    | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:27 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 1 (100.0%):   2%|█▌                                                                          | 1/50 [00:00<00:21,  2.25it/s]2025-08-18 21:33:27 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:27 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:33:27 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:27 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:27 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 2 (100.0%):   2%|█▌                                                                          | 1/50 [00:00<00:21,  2.25it/s]2025-08-18 21:33:27 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:33:27 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:27 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 3 (100.0%):   4%|███                                                                         | 2/50 [00:00<00:21,  2.25it/s]2025-08-18 21:33:27 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 4.00 / 4 (100.0%):   6%|████▌                                                                       | 3/50 [00:00<00:20,  2.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:27 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:27 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:27 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:27 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:27 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:27 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:27 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 5 (100.0%):   8%|██████                                                                      | 4/50 [00:00<00:20,  2.25it/s]2025-08-18 21:33:27 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:27 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:27 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:27 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 6 (83.3%):  10%|███████▋                                                                     | 5/50 [00:00<00:20,  2.25it/s]2025-08-18 21:33:27 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:27 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:27 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:27 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 7 (85.7%):  12%|█████████▏                                                                   | 6/50 [00:00<00:19,  2.25it/s]2025-08-18 21:33:27 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:27 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:27 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:27 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 8 (87.5%):  14%|██████████▊                                                                  | 7/50 [00:00<00:19,  2.25it/s]2025-08-18 21:33:27 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 7.00 / 8 (87.5%):  16%|████████████▎                                                                | 8/50 [00:00<00:02, 17.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:27 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:27 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:27 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 9 (88.9%):  16%|████████████▎                                                                | 8/50 [00:00<00:02, 17.95it/s]2025-08-18 21:33:27 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:27 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:27 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:27 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:27 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 9.00 / 10 (90.0%):  18%|█████████████▋                                                              | 9/50 [00:00<00:02, 17.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:27 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:27 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 10.00 / 11 (90.9%):  20%|██████████████▊                                                           | 10/50 [00:00<00:02, 17.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:27 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:27 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:27 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:27 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:27 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 12 (91.7%):  22%|████████████████▎                                                         | 11/50 [00:00<00:02, 17.95it/s]2025-08-18 21:33:27 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 11.00 / 12 (91.7%):  24%|█████████████████▊                                                        | 12/50 [00:00<00:02, 12.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:27 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:27 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:27 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 13 (92.3%):  24%|█████████████████▊                                                        | 12/50 [00:01<00:02, 12.84it/s]2025-08-18 21:33:27 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:27 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:27 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:27 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 14 (92.9%):  26%|███████████████████▏                                                      | 13/50 [00:01<00:02, 12.84it/s]2025-08-18 21:33:27 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:27 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:27 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:27 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 15 (93.3%):  28%|████████████████████▋                                                     | 14/50 [00:01<00:02, 12.84it/s]2025-08-18 21:33:27 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:27 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:27 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:27 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 16 (87.5%):  30%|██████████████████████▏                                                   | 15/50 [00:01<00:02, 12.84it/s]2025-08-18 21:33:27 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 14.00 / 16 (87.5%):  32%|███████████████████████▋                                                  | 16/50 [00:01<00:02, 15.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:28 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:28 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:28 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 17 (82.4%):  32%|███████████████████████▋                                                  | 16/50 [00:01<00:02, 15.19it/s]2025-08-18 21:33:28 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:28 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:28 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:28 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 18 (83.3%):  34%|█████████████████████████▏                                                | 17/50 [00:01<00:02, 15.19it/s]2025-08-18 21:33:28 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:28 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:28 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 16.00 / 19 (84.2%):  36%|██████████████████████████▋                                               | 18/50 [00:01<00:02, 15.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:28 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 19 (84.2%):  38%|████████████████████████████                                              | 19/50 [00:01<00:02, 14.19it/s]2025-08-18 21:33:28 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:28 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:28 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:28 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 20 (85.0%):  38%|████████████████████████████                                              | 19/50 [00:01<00:02, 14.19it/s]2025-08-18 21:33:28 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:28 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:28 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 18.00 / 21 (85.7%):  40%|█████████████████████████████▌                                            | 20/50 [00:01<00:02, 14.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:28 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:28 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:28 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:28 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 19.00 / 22 (86.4%):  42%|███████████████████████████████                                           | 21/50 [00:01<00:02, 14.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:28 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:28 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:28 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:28 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:28 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 23 (87.0%):  44%|████████████████████████████████▌                                         | 22/50 [00:01<00:01, 14.19it/s]2025-08-18 21:33:28 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 20.00 / 23 (87.0%):  46%|██████████████████████████████████                                        | 23/50 [00:01<00:01, 18.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:28 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:28 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:28 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 24 (87.5%):  46%|██████████████████████████████████                                        | 23/50 [00:01<00:01, 18.01it/s]2025-08-18 21:33:28 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:28 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:28 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:28 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 25 (88.0%):  48%|███████████████████████████████████▌                                      | 24/50 [00:01<00:01, 18.01it/s]2025-08-18 21:33:28 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:28 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:28 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:28 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 26 (84.6%):  50%|█████████████████████████████████████                                     | 25/50 [00:01<00:01, 18.01it/s]2025-08-18 21:33:28 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 22.00 / 26 (84.6%):  52%|██████████████████████████████████████▍                                   | 26/50 [00:01<00:01, 13.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:28 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:28 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:28 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 27 (81.5%):  52%|██████████████████████████████████████▍                                   | 26/50 [00:01<00:01, 13.93it/s]2025-08-18 21:33:28 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:28 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:28 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:28 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 28 (78.6%):  54%|███████████████████████████████████████▉                                  | 27/50 [00:01<00:01, 13.93it/s]2025-08-18 21:33:28 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:28 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:28 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:28 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 29 (79.3%):  56%|█████████████████████████████████████████▍                                | 28/50 [00:01<00:01, 13.93it/s]2025-08-18 21:33:28 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:28 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:28 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:28 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 30 (80.0%):  58%|██████████████████████████████████████████▉                               | 29/50 [00:01<00:01, 13.93it/s]2025-08-18 21:33:28 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:28 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:28 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:28 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 31 (77.4%):  60%|████████████████████████████████████████████▍                             | 30/50 [00:02<00:01, 13.93it/s]2025-08-18 21:33:28 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 24.00 / 31 (77.4%):  62%|█████████████████████████████████████████████▉                            | 31/50 [00:02<00:01, 18.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:28 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:28 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:28 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 32 (75.0%):  62%|█████████████████████████████████████████████▉                            | 31/50 [00:02<00:01, 18.55it/s]2025-08-18 21:33:28 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:28 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:28 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:29 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.00 / 33 (75.8%):  64%|███████████████████████████████████████████████▎                          | 32/50 [00:02<00:00, 18.55it/s]2025-08-18 21:33:29 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:29 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:29 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:29 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 26.00 / 34 (76.5%):  66%|████████████████████████████████████████████████▊                         | 33/50 [00:02<00:00, 18.55it/s]2025-08-18 21:33:29 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 26.00 / 34 (76.5%):  68%|██████████████████████████████████████████████████▎                       | 34/50 [00:02<00:01, 14.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:29 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:29 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:29 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 26.00 / 35 (74.3%):  68%|██████████████████████████████████████████████████▎                       | 34/50 [00:02<00:01, 14.05it/s]2025-08-18 21:33:29 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:29 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:29 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:29 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27.00 / 36 (75.0%):  70%|███████████████████████████████████████████████████▊                      | 35/50 [00:02<00:01, 14.05it/s]2025-08-18 21:33:29 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:29 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:29 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:29 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 28.00 / 37 (75.7%):  72%|█████████████████████████████████████████████████████▎                    | 36/50 [00:02<00:00, 14.05it/s]2025-08-18 21:33:29 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:29 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:29 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:29 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 29.00 / 38 (76.3%):  74%|██████████████████████████████████████████████████████▊                   | 37/50 [00:02<00:00, 14.05it/s]2025-08-18 21:33:29 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:29 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:29 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:29 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 30.00 / 39 (76.9%):  76%|████████████████████████████████████████████████████████▏                 | 38/50 [00:02<00:00, 14.05it/s]2025-08-18 21:33:29 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 30.00 / 39 (76.9%):  78%|█████████████████████████████████████████████████████████▋                | 39/50 [00:02<00:00, 18.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:29 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:29 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:29 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 31.00 / 40 (77.5%):  78%|█████████████████████████████████████████████████████████▋                | 39/50 [00:02<00:00, 18.50it/s]2025-08-18 21:33:29 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:29 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:29 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 32.00 / 41 (78.0%):  80%|███████████████████████████████████████████████████████████▏              | 40/50 [00:02<00:00, 18.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:29 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:29 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:29 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:29 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:29 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 32.00 / 42 (76.2%):  82%|████████████████████████████████████████████████████████████▋             | 41/50 [00:02<00:00, 18.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:29 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:29 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 32.00 / 42 (76.2%):  84%|██████████████████████████████████████████████████████████████▏           | 42/50 [00:02<00:00, 14.13it/s]2025-08-18 21:33:29 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 32.00 / 43 (74.4%):  84%|██████████████████████████████████████████████████████████████▏           | 42/50 [00:02<00:00, 14.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:29 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:29 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 33.00 / 44 (75.0%):  86%|███████████████████████████████████████████████████████████████▋          | 43/50 [00:02<00:00, 14.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:29 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:29 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 34.00 / 45 (75.6%):  88%|█████████████████████████████████████████████████████████████████         | 44/50 [00:02<00:00, 14.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:29 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:29 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 35.00 / 46 (76.1%):  90%|██████████████████████████████████████████████████████████████████▌       | 45/50 [00:02<00:00, 14.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:29 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:29 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 36.00 / 47 (76.6%):  94%|█████████████████████████████████████████████████████████████████████▌    | 47/50 [00:02<00:00, 19.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:29 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:29 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 37.00 / 48 (77.1%):  94%|█████████████████████████████████████████████████████████████████████▌    | 47/50 [00:03<00:00, 19.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:29 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:29 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 38.00 / 49 (77.6%):  96%|███████████████████████████████████████████████████████████████████████   | 48/50 [00:03<00:00, 19.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:30 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:30 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 39.00 / 50 (78.0%): 100%|██████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 14.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/18 21:33:30 INFO dspy.evaluate.evaluate: Average Metric: 39 / 50 (78.0%)\n",
      "2025/08/18 21:33:30 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mBest full score so far!\u001b[0m Score: 78.0\n",
      "2025/08/18 21:33:30 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 78.0 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 7'].\n",
      "2025/08/18 21:33:30 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [74.0, 72.0, 70.0, 58.0, 62.0, 62.0, 72.0, 74.0, 58.0, 76.0, 78.0]\n",
      "2025/08/18 21:33:30 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 78.0\n",
      "2025/08/18 21:33:30 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/08/18 21:33:30 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 12 / 18 =====\n",
      "\u001b[92m21:33:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-08-18 21:33:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                       | 0/50 [00:00<?, ?it/s]2025-08-18 21:33:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:30 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:30 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 1 (100.0%):   0%|                                                                                    | 0/50 [00:00<?, ?it/s]2025-08-18 21:33:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 1.00 / 1 (100.0%):   2%|█▌                                                                          | 1/50 [00:00<00:23,  2.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:30 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:30 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 2.00 / 2 (100.0%):   2%|█▌                                                                          | 1/50 [00:00<00:23,  2.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:30 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:30 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:30 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 3 (100.0%):   4%|███                                                                         | 2/50 [00:00<00:22,  2.11it/s]2025-08-18 21:33:30 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 4 (100.0%):   6%|████▌                                                                       | 3/50 [00:00<00:22,  2.11it/s]2025-08-18 21:33:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:30 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:30 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 5 (100.0%):   8%|██████                                                                      | 4/50 [00:00<00:21,  2.11it/s]2025-08-18 21:33:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:30 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:30 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 6 (83.3%):  10%|███████▋                                                                     | 5/50 [00:00<00:21,  2.11it/s]2025-08-18 21:33:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 5.00 / 6 (83.3%):  12%|█████████▏                                                                   | 6/50 [00:00<00:03, 11.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:30 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:30 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 6.00 / 7 (85.7%):  12%|█████████▏                                                                   | 6/50 [00:00<00:03, 11.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:30 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:30 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 7.00 / 8 (87.5%):  14%|██████████▊                                                                  | 7/50 [00:00<00:03, 11.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 7.00 / 8 (87.5%):  16%|████████████▎                                                                | 8/50 [00:00<00:03, 13.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:30 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:30 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 9 (88.9%):  16%|████████████▎                                                                | 8/50 [00:00<00:03, 13.24it/s]2025-08-18 21:33:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 10 (90.0%):  18%|█████████████▋                                                              | 9/50 [00:00<00:03, 13.24it/s]2025-08-18 21:33:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 9.00 / 10 (90.0%):  20%|███████████████                                                            | 10/50 [00:00<00:03, 11.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 10.00 / 11 (90.9%):  20%|██████████████▊                                                           | 10/50 [00:01<00:03, 11.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 11.00 / 12 (91.7%):  22%|████████████████▎                                                         | 11/50 [00:01<00:03, 11.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 11.00 / 12 (91.7%):  24%|█████████████████▊                                                        | 12/50 [00:01<00:02, 12.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 13 (92.3%):  24%|█████████████████▊                                                        | 12/50 [00:01<00:02, 12.87it/s]2025-08-18 21:33:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 14 (85.7%):  28%|████████████████████▋                                                     | 14/50 [00:01<00:02, 13.53it/s]2025-08-18 21:33:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 15 (86.7%):  28%|████████████████████▋                                                     | 14/50 [00:01<00:02, 13.53it/s]2025-08-18 21:33:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 14.00 / 16 (87.5%):  30%|██████████████████████▏                                                   | 15/50 [00:01<00:02, 13.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 17 (82.4%):  32%|███████████████████████▋                                                  | 16/50 [00:01<00:02, 13.53it/s]2025-08-18 21:33:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 14.00 / 17 (82.4%):  34%|█████████████████████████▏                                                | 17/50 [00:01<00:02, 15.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 18 (83.3%):  34%|█████████████████████████▏                                                | 17/50 [00:01<00:02, 15.10it/s]2025-08-18 21:33:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 16.00 / 19 (84.2%):  36%|██████████████████████████▋                                               | 18/50 [00:01<00:02, 15.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 19 (84.2%):  38%|████████████████████████████                                              | 19/50 [00:01<00:02, 14.16it/s]2025-08-18 21:33:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 20 (85.0%):  38%|████████████████████████████                                              | 19/50 [00:01<00:02, 14.16it/s]2025-08-18 21:33:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 18.00 / 21 (85.7%):  40%|█████████████████████████████▌                                            | 20/50 [00:01<00:02, 14.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 18.00 / 21 (85.7%):  42%|███████████████████████████████                                           | 21/50 [00:01<00:02, 14.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 19.00 / 22 (86.4%):  42%|███████████████████████████████                                           | 21/50 [00:01<00:02, 14.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 23 (87.0%):  44%|████████████████████████████████▌                                         | 22/50 [00:01<00:01, 14.43it/s]2025-08-18 21:33:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 24 (87.5%):  46%|██████████████████████████████████                                        | 23/50 [00:01<00:01, 14.43it/s]2025-08-18 21:33:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 25 (88.0%):  48%|███████████████████████████████████▌                                      | 24/50 [00:01<00:01, 14.43it/s]2025-08-18 21:33:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 22.00 / 25 (88.0%):  50%|█████████████████████████████████████                                     | 25/50 [00:01<00:01, 19.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 26 (84.6%):  50%|█████████████████████████████████████                                     | 25/50 [00:01<00:01, 19.00it/s]2025-08-18 21:33:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 27 (85.2%):  52%|██████████████████████████████████████▍                                   | 26/50 [00:02<00:01, 19.00it/s]2025-08-18 21:33:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 28 (82.1%):  54%|███████████████████████████████████████▉                                  | 27/50 [00:02<00:01, 19.00it/s]2025-08-18 21:33:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 23.00 / 28 (82.1%):  56%|█████████████████████████████████████████▍                                | 28/50 [00:02<00:01, 16.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 24.00 / 29 (82.8%):  56%|█████████████████████████████████████████▍                                | 28/50 [00:02<00:01, 16.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 30 (80.0%):  58%|██████████████████████████████████████████▉                               | 29/50 [00:02<00:01, 16.41it/s]2025-08-18 21:33:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 24.00 / 30 (80.0%):  60%|████████████████████████████████████████████▍                             | 30/50 [00:02<00:01, 16.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 31 (77.4%):  60%|████████████████████████████████████████████▍                             | 30/50 [00:02<00:01, 16.33it/s]2025-08-18 21:33:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 32 (75.0%):  62%|█████████████████████████████████████████████▉                            | 31/50 [00:02<00:01, 16.33it/s]2025-08-18 21:33:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.00 / 33 (75.8%):  64%|███████████████████████████████████████████████▎                          | 32/50 [00:02<00:01, 16.33it/s]2025-08-18 21:33:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 25.00 / 33 (75.8%):  66%|████████████████████████████████████████████████▊                         | 33/50 [00:02<00:00, 18.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 26.00 / 34 (76.5%):  66%|████████████████████████████████████████████████▊                         | 33/50 [00:02<00:00, 18.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27.00 / 35 (77.1%):  68%|██████████████████████████████████████████████████▎                       | 34/50 [00:02<00:00, 18.70it/s]2025-08-18 21:33:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 28.00 / 36 (77.8%):  70%|███████████████████████████████████████████████████▊                      | 35/50 [00:02<00:00, 18.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 28.00 / 36 (77.8%):  72%|█████████████████████████████████████████████████████▎                    | 36/50 [00:02<00:00, 14.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 28.00 / 37 (75.7%):  72%|█████████████████████████████████████████████████████▎                    | 36/50 [00:02<00:00, 14.60it/s]2025-08-18 21:33:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 29.00 / 38 (76.3%):  74%|██████████████████████████████████████████████████████▊                   | 37/50 [00:02<00:00, 14.60it/s]2025-08-18 21:33:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 30.00 / 39 (76.9%):  78%|█████████████████████████████████████████████████████████▋                | 39/50 [00:02<00:00, 16.98it/s]2025-08-18 21:33:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 31.00 / 40 (77.5%):  78%|█████████████████████████████████████████████████████████▋                | 39/50 [00:02<00:00, 16.98it/s]2025-08-18 21:33:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 32.00 / 41 (78.0%):  80%|███████████████████████████████████████████████████████████▏              | 40/50 [00:02<00:00, 16.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 33.00 / 42 (78.6%):  82%|████████████████████████████████████████████████████████████▋             | 41/50 [00:02<00:00, 16.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 33.00 / 42 (78.6%):  84%|██████████████████████████████████████████████████████████████▏           | 42/50 [00:02<00:00, 14.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 33.00 / 43 (76.7%):  84%|██████████████████████████████████████████████████████████████▏           | 42/50 [00:02<00:00, 14.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 34.00 / 44 (77.3%):  86%|███████████████████████████████████████████████████████████████▋          | 43/50 [00:02<00:00, 14.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 34.00 / 45 (75.6%):  88%|█████████████████████████████████████████████████████████████████         | 44/50 [00:03<00:00, 14.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 35.00 / 46 (76.1%):  92%|████████████████████████████████████████████████████████████████████      | 46/50 [00:03<00:00, 17.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 36.00 / 47 (76.6%):  92%|████████████████████████████████████████████████████████████████████      | 46/50 [00:03<00:00, 17.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 37.00 / 48 (77.1%):  94%|█████████████████████████████████████████████████████████████████████▌    | 47/50 [00:03<00:00, 17.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 38.00 / 49 (77.6%):  98%|████████████████████████████████████████████████████████████████████████▌ | 49/50 [00:03<00:00, 19.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 39.00 / 50 (78.0%): 100%|██████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 14.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/18 21:33:33 INFO dspy.evaluate.evaluate: Average Metric: 39 / 50 (78.0%)\n",
      "2025/08/18 21:33:33 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 78.0 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 7'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/18 21:33:33 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [74.0, 72.0, 70.0, 58.0, 62.0, 62.0, 72.0, 74.0, 58.0, 76.0, 78.0, 78.0]\n",
      "2025/08/18 21:33:33 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 78.0\n",
      "2025/08/18 21:33:33 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/08/18 21:33:33 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 13 / 18 =====\n",
      "\u001b[92m21:33:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                       | 0/50 [00:00<?, ?it/s]2025-08-18 21:33:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 0.00 / 1 (0.0%):   0%|                                                                                      | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 0.00 / 1 (0.0%):   2%|█▌                                                                            | 1/50 [00:00<00:21,  2.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 2 (50.0%):   2%|█▌                                                                           | 1/50 [00:00<00:21,  2.29it/s]2025-08-18 21:33:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 3 (66.7%):   4%|███                                                                          | 2/50 [00:00<00:20,  2.29it/s]2025-08-18 21:33:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 3.00 / 4 (75.0%):   6%|████▌                                                                        | 3/50 [00:00<00:20,  2.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 5 (60.0%):   8%|██████▏                                                                      | 4/50 [00:00<00:20,  2.29it/s]2025-08-18 21:33:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 6 (66.7%):  10%|███████▋                                                                     | 5/50 [00:00<00:19,  2.29it/s]2025-08-18 21:33:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:34 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 7 (71.4%):  12%|█████████▏                                                                   | 6/50 [00:00<00:19,  2.29it/s]2025-08-18 21:33:34 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:34 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 8 (62.5%):  14%|██████████▊                                                                  | 7/50 [00:00<00:18,  2.29it/s]2025-08-18 21:33:34 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:34 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 9 (66.7%):  16%|████████████▎                                                                | 8/50 [00:00<00:18,  2.29it/s]2025-08-18 21:33:34 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 6.00 / 9 (66.7%):  18%|█████████████▊                                                               | 9/50 [00:00<00:03, 12.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 7.00 / 10 (70.0%):  18%|█████████████▋                                                              | 9/50 [00:00<00:03, 12.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:34 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:34 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 8.00 / 11 (72.7%):  20%|███████████████                                                            | 10/50 [00:00<00:03, 12.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:34 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 12 (75.0%):  22%|████████████████▌                                                          | 11/50 [00:00<00:03, 12.07it/s]2025-08-18 21:33:34 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:34 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:34 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 10.00 / 13 (76.9%):  24%|█████████████████▊                                                        | 12/50 [00:01<00:03, 12.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:33:34 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 11.00 / 14 (78.6%):  26%|███████████████████▏                                                      | 13/50 [00:01<00:02, 14.84it/s]2025-08-18 21:33:34 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 15 (80.0%):  28%|████████████████████▋                                                     | 14/50 [00:01<00:02, 14.84it/s]2025-08-18 21:33:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:34 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 16 (81.2%):  30%|██████████████████████▏                                                   | 15/50 [00:01<00:02, 14.84it/s]2025-08-18 21:33:34 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:34 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:34 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:34 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:34 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:34 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 17 (76.5%):  32%|███████████████████████▋                                                  | 16/50 [00:01<00:02, 14.84it/s]2025-08-18 21:33:34 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 13.00 / 17 (76.5%):  34%|█████████████████████████▏                                                | 17/50 [00:01<00:02, 13.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 14.00 / 18 (77.8%):  34%|█████████████████████████▏                                                | 17/50 [00:01<00:02, 13.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:34 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:34 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 15.00 / 19 (78.9%):  36%|██████████████████████████▋                                               | 18/50 [00:01<00:02, 13.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:34 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:34 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:34 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 20 (80.0%):  38%|████████████████████████████                                              | 19/50 [00:01<00:02, 13.73it/s]2025-08-18 21:33:34 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:35 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 21 (81.0%):  40%|█████████████████████████████▌                                            | 20/50 [00:01<00:02, 13.73it/s]2025-08-18 21:33:35 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 17.00 / 21 (81.0%):  42%|███████████████████████████████                                           | 21/50 [00:01<00:01, 16.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:35 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 22 (81.8%):  42%|███████████████████████████████                                           | 21/50 [00:01<00:01, 16.74it/s]2025-08-18 21:33:35 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:35 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 23 (82.6%):  44%|████████████████████████████████▌                                         | 22/50 [00:01<00:01, 16.74it/s]2025-08-18 21:33:35 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:35 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 24 (83.3%):  46%|██████████████████████████████████                                        | 23/50 [00:01<00:01, 16.74it/s]2025-08-18 21:33:35 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 25 (84.0%):  48%|███████████████████████████████████▌                                      | 24/50 [00:01<00:01, 16.74it/s]2025-08-18 21:33:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:35 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 25 (84.0%):  50%|█████████████████████████████████████                                     | 25/50 [00:01<00:01, 14.46it/s]2025-08-18 21:33:35 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:35 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 26 (84.6%):  50%|█████████████████████████████████████                                     | 25/50 [00:01<00:01, 14.46it/s]2025-08-18 21:33:35 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:35 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 27 (81.5%):  52%|██████████████████████████████████████▍                                   | 26/50 [00:01<00:01, 14.46it/s]2025-08-18 21:33:35 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:35 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 28 (82.1%):  54%|███████████████████████████████████████▉                                  | 27/50 [00:01<00:01, 14.46it/s]2025-08-18 21:33:35 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 24.00 / 29 (82.8%):  56%|█████████████████████████████████████████▍                                | 28/50 [00:01<00:01, 14.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:35 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 29 (82.8%):  58%|██████████████████████████████████████████▉                               | 29/50 [00:01<00:01, 17.97it/s]2025-08-18 21:33:35 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 24.00 / 30 (80.0%):  58%|██████████████████████████████████████████▉                               | 29/50 [00:02<00:01, 17.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:35 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:35 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:35 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.00 / 31 (80.6%):  60%|████████████████████████████████████████████▍                             | 30/50 [00:02<00:01, 17.97it/s]2025-08-18 21:33:35 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:35 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.00 / 32 (78.1%):  62%|█████████████████████████████████████████████▉                            | 31/50 [00:02<00:01, 17.97it/s]2025-08-18 21:33:35 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:35 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 26.00 / 33 (78.8%):  64%|███████████████████████████████████████████████▎                          | 32/50 [00:02<00:01, 17.97it/s]2025-08-18 21:33:35 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 26.00 / 33 (78.8%):  66%|████████████████████████████████████████████████▊                         | 33/50 [00:02<00:01, 15.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:35 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27.00 / 34 (79.4%):  66%|████████████████████████████████████████████████▊                         | 33/50 [00:02<00:01, 15.40it/s]2025-08-18 21:33:35 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:35 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27.00 / 35 (77.1%):  68%|██████████████████████████████████████████████████▎                       | 34/50 [00:02<00:01, 15.40it/s]2025-08-18 21:33:35 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:35 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 28.00 / 36 (77.8%):  70%|███████████████████████████████████████████████████▊                      | 35/50 [00:02<00:00, 15.40it/s]2025-08-18 21:33:35 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:35 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 28.00 / 37 (75.7%):  72%|█████████████████████████████████████████████████████▎                    | 36/50 [00:02<00:00, 15.40it/s]2025-08-18 21:33:35 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 28.00 / 37 (75.7%):  74%|██████████████████████████████████████████████████████▊                   | 37/50 [00:02<00:00, 17.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:36 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:36 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 28.00 / 38 (73.7%):  74%|██████████████████████████████████████████████████████▊                   | 37/50 [00:02<00:00, 17.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:36 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:36 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 29.00 / 39 (74.4%):  76%|████████████████████████████████████████████████████████▏                 | 38/50 [00:02<00:00, 17.60it/s]2025-08-18 21:33:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:36 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:36 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 30.00 / 40 (75.0%):  78%|█████████████████████████████████████████████████████████▋                | 39/50 [00:02<00:00, 17.60it/s]2025-08-18 21:33:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 30.00 / 40 (75.0%):  80%|███████████████████████████████████████████████████████████▏              | 40/50 [00:02<00:00, 17.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:36 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:36 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 31.00 / 41 (75.6%):  80%|███████████████████████████████████████████████████████████▏              | 40/50 [00:02<00:00, 17.67it/s]2025-08-18 21:33:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:36 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:36 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 32.00 / 42 (76.2%):  82%|████████████████████████████████████████████████████████████▋             | 41/50 [00:02<00:00, 17.67it/s]2025-08-18 21:33:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:36 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:36 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 33.00 / 43 (76.7%):  86%|███████████████████████████████████████████████████████████████▋          | 43/50 [00:02<00:00, 15.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:36 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:36 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 33.00 / 44 (75.0%):  86%|███████████████████████████████████████████████████████████████▋          | 43/50 [00:02<00:00, 15.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:36 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:36 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 33.00 / 45 (73.3%):  88%|█████████████████████████████████████████████████████████████████         | 44/50 [00:02<00:00, 15.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:36 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:36 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 34.00 / 46 (73.9%):  90%|██████████████████████████████████████████████████████████████████▌       | 45/50 [00:02<00:00, 15.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:36 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:36 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:36 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 35.00 / 47 (74.5%):  92%|████████████████████████████████████████████████████████████████████      | 46/50 [00:03<00:00, 15.26it/s]2025-08-18 21:33:36 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 36.00 / 48 (75.0%):  94%|█████████████████████████████████████████████████████████████████████▌    | 47/50 [00:03<00:00, 17.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:36 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:36 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 37.00 / 49 (75.5%):  96%|███████████████████████████████████████████████████████████████████████   | 48/50 [00:03<00:00, 17.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:36 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:36 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 37.00 / 50 (74.0%): 100%|██████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 15.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/18 21:33:36 INFO dspy.evaluate.evaluate: Average Metric: 37 / 50 (74.0%)\n",
      "2025/08/18 21:33:36 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 74.0 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 9'].\n",
      "2025/08/18 21:33:36 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [74.0, 72.0, 70.0, 58.0, 62.0, 62.0, 72.0, 74.0, 58.0, 76.0, 78.0, 78.0, 74.0]\n",
      "2025/08/18 21:33:36 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 78.0\n",
      "2025/08/18 21:33:36 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/08/18 21:33:36 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 14 / 18 =====\n",
      "\u001b[92m21:33:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-08-18 21:33:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:33:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:33:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "  0%|                                                                                                                       | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:33:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:33:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 1 (0.0%):   0%|                                                                                      | 0/50 [00:00<?, ?it/s]2025-08-18 21:33:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 1 (0.0%):   2%|█▌                                                                            | 1/50 [00:00<00:20,  2.39it/s]2025-08-18 21:33:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 1.00 / 2 (50.0%):   2%|█▌                                                                           | 1/50 [00:00<00:20,  2.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 3 (66.7%):   4%|███                                                                          | 2/50 [00:00<00:20,  2.39it/s]2025-08-18 21:33:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 3.00 / 4 (75.0%):   6%|████▌                                                                        | 3/50 [00:00<00:19,  2.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 4.00 / 5 (80.0%):   8%|██████▏                                                                      | 4/50 [00:00<00:19,  2.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 6 (66.7%):  10%|███████▋                                                                     | 5/50 [00:00<00:18,  2.39it/s]2025-08-18 21:33:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 7 (71.4%):  12%|█████████▏                                                                   | 6/50 [00:00<00:18,  2.39it/s]2025-08-18 21:33:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 8 (62.5%):  14%|██████████▊                                                                  | 7/50 [00:00<00:17,  2.39it/s]2025-08-18 21:33:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 5.00 / 8 (62.5%):  16%|████████████▎                                                                | 8/50 [00:00<00:02, 18.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 9 (66.7%):  16%|████████████▎                                                                | 8/50 [00:00<00:02, 18.15it/s]2025-08-18 21:33:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 10 (70.0%):  18%|█████████████▋                                                              | 9/50 [00:00<00:02, 18.15it/s]2025-08-18 21:33:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 11 (72.7%):  20%|███████████████                                                            | 10/50 [00:00<00:02, 18.15it/s]2025-08-18 21:33:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 12 (75.0%):  22%|████████████████▌                                                          | 11/50 [00:00<00:02, 18.15it/s]2025-08-18 21:33:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 9.00 / 12 (75.0%):  24%|██████████████████                                                         | 12/50 [00:00<00:03, 12.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 13 (76.9%):  24%|█████████████████▊                                                        | 12/50 [00:01<00:03, 12.60it/s]2025-08-18 21:33:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 14 (78.6%):  26%|███████████████████▏                                                      | 13/50 [00:01<00:02, 12.60it/s]2025-08-18 21:33:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 15 (80.0%):  28%|████████████████████▋                                                     | 14/50 [00:01<00:02, 12.60it/s]2025-08-18 21:33:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 12.00 / 16 (75.0%):  30%|██████████████████████▏                                                   | 15/50 [00:01<00:02, 12.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 16 (75.0%):  32%|███████████████████████▋                                                  | 16/50 [00:01<00:02, 15.17it/s]2025-08-18 21:33:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 17 (70.6%):  32%|███████████████████████▋                                                  | 16/50 [00:01<00:02, 15.17it/s]2025-08-18 21:33:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 18 (72.2%):  34%|█████████████████████████▏                                                | 17/50 [00:01<00:02, 15.17it/s]2025-08-18 21:33:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 14.00 / 19 (73.7%):  38%|████████████████████████████                                              | 19/50 [00:01<00:02, 13.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 20 (75.0%):  38%|████████████████████████████                                              | 19/50 [00:01<00:02, 13.40it/s]2025-08-18 21:33:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 21 (76.2%):  40%|█████████████████████████████▌                                            | 20/50 [00:01<00:02, 13.40it/s]2025-08-18 21:33:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 17.00 / 22 (77.3%):  42%|███████████████████████████████                                           | 21/50 [00:01<00:02, 13.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 23 (78.3%):  44%|████████████████████████████████▌                                         | 22/50 [00:01<00:02, 13.40it/s]2025-08-18 21:33:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 24 (75.0%):  46%|██████████████████████████████████                                        | 23/50 [00:01<00:02, 13.40it/s]2025-08-18 21:33:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 18.00 / 24 (75.0%):  48%|███████████████████████████████████▌                                      | 24/50 [00:01<00:01, 18.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 19.00 / 25 (76.0%):  48%|███████████████████████████████████▌                                      | 24/50 [00:01<00:01, 18.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:33:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 19.00 / 26 (73.1%):  50%|█████████████████████████████████████                                     | 25/50 [00:01<00:01, 18.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:33:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 20.00 / 27 (74.1%):  52%|██████████████████████████████████████▍                                   | 26/50 [00:01<00:01, 18.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 20.00 / 27 (74.1%):  54%|███████████████████████████████████████▉                                  | 27/50 [00:01<00:01, 13.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 28 (71.4%):  54%|███████████████████████████████████████▉                                  | 27/50 [00:01<00:01, 13.18it/s]2025-08-18 21:33:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 29 (72.4%):  56%|█████████████████████████████████████████▍                                | 28/50 [00:02<00:01, 13.18it/s]2025-08-18 21:33:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 30 (73.3%):  58%|██████████████████████████████████████████▉                               | 29/50 [00:02<00:01, 13.18it/s]2025-08-18 21:33:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 31 (71.0%):  60%|████████████████████████████████████████████▍                             | 30/50 [00:02<00:01, 13.18it/s]2025-08-18 21:33:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 32 (68.8%):  62%|█████████████████████████████████████████████▉                            | 31/50 [00:02<00:01, 13.18it/s]2025-08-18 21:33:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:39 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:39 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:39 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 33 (66.7%):  64%|███████████████████████████████████████████████▎                          | 32/50 [00:02<00:01, 13.18it/s]2025-08-18 21:33:39 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 22.00 / 33 (66.7%):  66%|████████████████████████████████████████████████▊                         | 33/50 [00:02<00:01, 13.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:39 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:39 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 23.00 / 34 (67.6%):  66%|████████████████████████████████████████████████▊                         | 33/50 [00:02<00:01, 13.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:39 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:39 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:39 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:39 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:39 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 35 (68.6%):  68%|██████████████████████████████████████████████████▎                       | 34/50 [00:02<00:01, 13.13it/s]2025-08-18 21:33:39 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:39 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:39 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:39 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.00 / 36 (69.4%):  70%|███████████████████████████████████████████████████▊                      | 35/50 [00:02<00:01, 13.13it/s]2025-08-18 21:33:39 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:39 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:39 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 26.00 / 37 (70.3%):  72%|█████████████████████████████████████████████████████▎                    | 36/50 [00:02<00:01, 13.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:39 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:39 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:39 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:39 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:39 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 26.00 / 38 (68.4%):  74%|██████████████████████████████████████████████████████▊                   | 37/50 [00:02<00:00, 13.13it/s]2025-08-18 21:33:39 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:39 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:39 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:39 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27.00 / 39 (69.2%):  76%|████████████████████████████████████████████████████████▏                 | 38/50 [00:02<00:00, 13.13it/s]2025-08-18 21:33:39 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:39 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:39 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 28.00 / 40 (70.0%):  78%|█████████████████████████████████████████████████████████▋                | 39/50 [00:02<00:00, 13.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:39 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:39 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 28.00 / 40 (70.0%):  80%|███████████████████████████████████████████████████████████▏              | 40/50 [00:02<00:00, 15.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:39 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:39 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:39 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 29.00 / 41 (70.7%):  80%|███████████████████████████████████████████████████████████▏              | 40/50 [00:02<00:00, 15.83it/s]2025-08-18 21:33:39 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:39 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:39 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:39 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 30.00 / 42 (71.4%):  82%|████████████████████████████████████████████████████████████▋             | 41/50 [00:02<00:00, 15.83it/s]2025-08-18 21:33:39 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 30.00 / 42 (71.4%):  84%|██████████████████████████████████████████████████████████████▏           | 42/50 [00:02<00:00, 14.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:39 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:39 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 30.00 / 43 (69.8%):  84%|██████████████████████████████████████████████████████████████▏           | 42/50 [00:02<00:00, 14.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:39 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:39 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:39 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 30.00 / 44 (68.2%):  86%|███████████████████████████████████████████████████████████████▋          | 43/50 [00:03<00:00, 14.93it/s]2025-08-18 21:33:39 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 31.00 / 45 (68.9%):  88%|█████████████████████████████████████████████████████████████████         | 44/50 [00:03<00:00, 14.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:39 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:39 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 32.00 / 46 (69.6%):  90%|██████████████████████████████████████████████████████████████████▌       | 45/50 [00:03<00:00, 14.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:40 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:40 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 32.00 / 47 (68.1%):  94%|█████████████████████████████████████████████████████████████████████▌    | 47/50 [00:03<00:00, 16.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:40 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:40 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 33.00 / 48 (68.8%):  94%|█████████████████████████████████████████████████████████████████████▌    | 47/50 [00:03<00:00, 16.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:40 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:40 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 34.00 / 49 (69.4%):  98%|████████████████████████████████████████████████████████████████████████▌ | 49/50 [00:03<00:00, 16.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:40 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:40 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 35.00 / 50 (70.0%): 100%|██████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 14.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/18 21:33:40 INFO dspy.evaluate.evaluate: Average Metric: 35 / 50 (70.0%)\n",
      "2025/08/18 21:33:40 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 70.0 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 7'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/18 21:33:40 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [74.0, 72.0, 70.0, 58.0, 62.0, 62.0, 72.0, 74.0, 58.0, 76.0, 78.0, 78.0, 74.0, 70.0]\n",
      "2025/08/18 21:33:40 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 78.0\n",
      "2025/08/18 21:33:40 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/08/18 21:33:40 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 15 / 18 =====\n",
      "\u001b[92m21:33:40 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:40 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:40 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:33:40 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:40 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:33:40 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:40 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                       | 0/50 [00:00<?, ?it/s]2025-08-18 21:33:40 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:40 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:40 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:40 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:40 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:40 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:40 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:40 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:40 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:40 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:40 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 0.00 / 1 (0.0%):   0%|                                                                                      | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:40 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:40 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 0.00 / 1 (0.0%):   2%|█▌                                                                            | 1/50 [00:00<00:21,  2.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:40 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:40 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:40 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 2 (0.0%):   2%|█▌                                                                            | 1/50 [00:00<00:21,  2.27it/s]2025-08-18 21:33:40 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:40 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:40 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:40 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:40 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 1.00 / 3 (33.3%):   4%|███                                                                          | 2/50 [00:00<00:21,  2.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:40 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:40 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 1.00 / 4 (25.0%):   6%|████▌                                                                        | 3/50 [00:00<00:20,  2.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:40 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:40 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:40 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:40 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 2.00 / 5 (40.0%):   8%|██████▏                                                                      | 4/50 [00:00<00:20,  2.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:40 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:40 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:40 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 6 (50.0%):  10%|███████▋                                                                     | 5/50 [00:00<00:19,  2.27it/s]2025-08-18 21:33:40 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:40 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:40 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:40 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:40 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:40 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 7 (57.1%):  12%|█████████▏                                                                   | 6/50 [00:00<00:19,  2.27it/s]2025-08-18 21:33:40 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:40 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:40 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:40 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 8 (50.0%):  14%|██████████▊                                                                  | 7/50 [00:00<00:18,  2.27it/s]2025-08-18 21:33:40 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:41 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:41 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:41 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 9 (55.6%):  16%|████████████▎                                                                | 8/50 [00:00<00:18,  2.27it/s]2025-08-18 21:33:41 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 5.00 / 9 (55.6%):  18%|█████████████▊                                                               | 9/50 [00:00<00:03, 11.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:41 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:41 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:41 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 10 (60.0%):  18%|█████████████▋                                                              | 9/50 [00:00<00:03, 11.64it/s]2025-08-18 21:33:41 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:41 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:41 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:41 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 11 (63.6%):  20%|███████████████                                                            | 10/50 [00:00<00:03, 11.64it/s]2025-08-18 21:33:41 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:41 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:41 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:41 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:41 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 8.00 / 12 (66.7%):  22%|████████████████▌                                                          | 11/50 [00:00<00:03, 11.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:41 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:41 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 9.00 / 13 (69.2%):  24%|██████████████████                                                         | 12/50 [00:00<00:03, 11.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:41 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:41 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:41 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:41 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 10.00 / 14 (71.4%):  26%|███████████████████▏                                                      | 13/50 [00:01<00:03, 11.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:41 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:41 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 10.00 / 14 (71.4%):  28%|████████████████████▋                                                     | 14/50 [00:01<00:02, 16.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:41 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:41 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 11.00 / 15 (73.3%):  28%|████████████████████▋                                                     | 14/50 [00:01<00:02, 16.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:41 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:41 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:41 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:41 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 12.00 / 16 (75.0%):  30%|██████████████████████▏                                                   | 15/50 [00:01<00:02, 16.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:41 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:41 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:41 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:41 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:41 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 17 (76.5%):  32%|███████████████████████▋                                                  | 16/50 [00:01<00:02, 16.42it/s]2025-08-18 21:33:41 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 13.00 / 17 (76.5%):  34%|█████████████████████████▏                                                | 17/50 [00:01<00:02, 14.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:41 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:41 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 14.00 / 18 (77.8%):  34%|█████████████████████████▏                                                | 17/50 [00:01<00:02, 14.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:41 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:41 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:41 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:41 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:41 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 19 (78.9%):  36%|██████████████████████████▋                                               | 18/50 [00:01<00:02, 14.02it/s]2025-08-18 21:33:41 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:41 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:41 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 16.00 / 20 (80.0%):  38%|████████████████████████████                                              | 19/50 [00:01<00:02, 14.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:41 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:41 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:41 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:41 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:41 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:41 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 17.00 / 21 (81.0%):  40%|█████████████████████████████▌                                            | 20/50 [00:01<00:02, 14.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:41 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:41 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 17.00 / 21 (81.0%):  42%|███████████████████████████████                                           | 21/50 [00:01<00:01, 17.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:41 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 22 (81.8%):  42%|███████████████████████████████                                           | 21/50 [00:01<00:01, 17.52it/s]2025-08-18 21:33:41 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:41 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:41 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:41 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 23 (82.6%):  44%|████████████████████████████████▌                                         | 22/50 [00:01<00:01, 17.52it/s]2025-08-18 21:33:41 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:41 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:41 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 19.00 / 24 (79.2%):  46%|██████████████████████████████████                                        | 23/50 [00:01<00:01, 17.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:41 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 24 (79.2%):  48%|███████████████████████████████████▌                                      | 24/50 [00:01<00:01, 19.69it/s]2025-08-18 21:33:41 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:42 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:42 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:42 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:42 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 20.00 / 25 (80.0%):  48%|███████████████████████████████████▌                                      | 24/50 [00:01<00:01, 19.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:42 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:33:42 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:42 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 21.00 / 26 (80.8%):  50%|█████████████████████████████████████                                     | 25/50 [00:01<00:01, 19.69it/s]2025-08-18 21:33:42 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:42 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:42 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:42 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 27 (77.8%):  52%|██████████████████████████████████████▍                                   | 26/50 [00:01<00:01, 19.69it/s]2025-08-18 21:33:42 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 21.00 / 27 (77.8%):  54%|███████████████████████████████████████▉                                  | 27/50 [00:01<00:01, 16.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:42 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:42 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:42 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 28 (75.0%):  54%|███████████████████████████████████████▉                                  | 27/50 [00:01<00:01, 16.48it/s]2025-08-18 21:33:42 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:42 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:42 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 22.00 / 29 (75.9%):  56%|█████████████████████████████████████████▍                                | 28/50 [00:01<00:01, 16.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:42 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:42 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:42 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:42 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:42 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 30 (73.3%):  58%|██████████████████████████████████████████▉                               | 29/50 [00:01<00:01, 16.48it/s]2025-08-18 21:33:42 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 22.00 / 30 (73.3%):  60%|████████████████████████████████████████████▍                             | 30/50 [00:01<00:01, 17.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:42 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:42 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:42 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 31 (71.0%):  60%|████████████████████████████████████████████▍                             | 30/50 [00:01<00:01, 17.56it/s]2025-08-18 21:33:42 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:42 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:42 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:42 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 32 (71.9%):  62%|█████████████████████████████████████████████▉                            | 31/50 [00:01<00:01, 17.56it/s]2025-08-18 21:33:42 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:42 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:42 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:42 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 33 (72.7%):  64%|███████████████████████████████████████████████▎                          | 32/50 [00:02<00:01, 17.56it/s]2025-08-18 21:33:42 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 24.00 / 33 (72.7%):  66%|████████████████████████████████████████████████▊                         | 33/50 [00:02<00:01, 14.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:42 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:42 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:42 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.00 / 34 (73.5%):  66%|████████████████████████████████████████████████▊                         | 33/50 [00:02<00:01, 14.03it/s]2025-08-18 21:33:42 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:42 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:42 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:42 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 26.00 / 35 (74.3%):  68%|██████████████████████████████████████████████████▎                       | 34/50 [00:02<00:01, 14.03it/s]2025-08-18 21:33:42 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:42 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:42 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 26.00 / 36 (72.2%):  70%|███████████████████████████████████████████████████▊                      | 35/50 [00:02<00:01, 14.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:42 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:42 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 26.00 / 36 (72.2%):  72%|█████████████████████████████████████████████████████▎                    | 36/50 [00:02<00:00, 15.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:42 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:42 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:42 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27.00 / 37 (73.0%):  72%|█████████████████████████████████████████████████████▎                    | 36/50 [00:02<00:00, 15.77it/s]2025-08-18 21:33:42 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:42 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:42 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 27.00 / 38 (71.1%):  74%|██████████████████████████████████████████████████████▊                   | 37/50 [00:02<00:00, 15.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:42 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:42 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 27.00 / 38 (71.1%):  76%|████████████████████████████████████████████████████████▏                 | 38/50 [00:02<00:00, 16.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:42 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:42 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:42 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:42 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 27.00 / 39 (69.2%):  76%|████████████████████████████████████████████████████████▏                 | 38/50 [00:02<00:00, 16.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:42 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:42 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 28.00 / 40 (70.0%):  78%|█████████████████████████████████████████████████████████▋                | 39/50 [00:02<00:00, 16.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:42 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:42 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:43 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:43 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 29.00 / 41 (70.7%):  80%|███████████████████████████████████████████████████████████▏              | 40/50 [00:02<00:00, 16.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:43 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:43 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 29.00 / 41 (70.7%):  82%|████████████████████████████████████████████████████████████▋             | 41/50 [00:02<00:00, 15.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:43 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:43 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:43 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 30.00 / 42 (71.4%):  82%|████████████████████████████████████████████████████████████▋             | 41/50 [00:02<00:00, 15.69it/s]2025-08-18 21:33:43 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:43 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:43 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 31.00 / 43 (72.1%):  84%|██████████████████████████████████████████████████████████████▏           | 42/50 [00:02<00:00, 15.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:43 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:43 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 31.00 / 44 (70.5%):  88%|█████████████████████████████████████████████████████████████████         | 44/50 [00:02<00:00, 17.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:43 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:43 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 32.00 / 45 (71.1%):  88%|█████████████████████████████████████████████████████████████████         | 44/50 [00:02<00:00, 17.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:43 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:43 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 33.00 / 46 (71.7%):  90%|██████████████████████████████████████████████████████████████████▌       | 45/50 [00:02<00:00, 17.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:43 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:43 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 34.00 / 47 (72.3%):  94%|█████████████████████████████████████████████████████████████████████▌    | 47/50 [00:03<00:00, 16.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:43 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:43 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 35.00 / 48 (72.9%):  94%|█████████████████████████████████████████████████████████████████████▌    | 47/50 [00:03<00:00, 16.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:43 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:43 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 36.00 / 49 (73.5%):  96%|███████████████████████████████████████████████████████████████████████   | 48/50 [00:03<00:00, 16.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:43 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:43 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 37.00 / 50 (74.0%): 100%|██████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 15.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/18 21:33:43 INFO dspy.evaluate.evaluate: Average Metric: 37 / 50 (74.0%)\n",
      "2025/08/18 21:33:43 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 74.0 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 4'].\n",
      "2025/08/18 21:33:43 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [74.0, 72.0, 70.0, 58.0, 62.0, 62.0, 72.0, 74.0, 58.0, 76.0, 78.0, 78.0, 74.0, 70.0, 74.0]\n",
      "2025/08/18 21:33:43 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 78.0\n",
      "2025/08/18 21:33:43 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/08/18 21:33:43 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 16 / 18 =====\n",
      "\u001b[92m21:33:43 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-08-18 21:33:43 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:43 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:33:43 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:43 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:33:43 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:43 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:43 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "  0%|                                                                                                                       | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:43 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:43 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:43 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:43 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:43 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:43 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:43 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:43 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:44 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:44 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:44 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 1 (0.0%):   0%|                                                                                      | 0/50 [00:00<?, ?it/s]2025-08-18 21:33:44 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:44 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 1 (0.0%):   2%|█▌                                                                            | 1/50 [00:00<00:26,  1.84it/s]2025-08-18 21:33:44 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 0.00 / 2 (0.0%):   2%|█▌                                                                            | 1/50 [00:00<00:26,  1.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:44 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:44 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:44 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:44 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 1.00 / 3 (33.3%):   4%|███                                                                          | 2/50 [00:00<00:26,  1.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:44 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:33:44 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:44 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:44 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 4 (50.0%):   6%|████▌                                                                        | 3/50 [00:00<00:25,  1.84it/s]2025-08-18 21:33:44 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:44 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:44 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 3.00 / 5 (60.0%):   8%|██████▏                                                                      | 4/50 [00:00<00:25,  1.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:44 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:44 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:44 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 6 (50.0%):  10%|███████▋                                                                     | 5/50 [00:00<00:24,  1.84it/s]2025-08-18 21:33:44 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:44 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:44 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:33:44 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 4.00 / 7 (57.1%):  12%|█████████▏                                                                   | 6/50 [00:00<00:23,  1.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:44 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:44 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:44 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:44 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 4.00 / 8 (50.0%):  14%|██████████▊                                                                  | 7/50 [00:00<00:23,  1.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:44 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:44 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:44 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:44 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:44 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:44 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:44 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 9 (55.6%):  16%|████████████▎                                                                | 8/50 [00:00<00:22,  1.84it/s]2025-08-18 21:33:44 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 5.00 / 9 (55.6%):  18%|█████████████▊                                                               | 9/50 [00:00<00:03, 10.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:44 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:44 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:44 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 10 (50.0%):  18%|█████████████▋                                                              | 9/50 [00:01<00:03, 10.56it/s]2025-08-18 21:33:44 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:44 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:44 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:44 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 11 (54.5%):  20%|███████████████                                                            | 10/50 [00:01<00:03, 10.56it/s]2025-08-18 21:33:44 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:44 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:44 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 7.00 / 12 (58.3%):  22%|████████████████▌                                                          | 11/50 [00:01<00:03, 10.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:44 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:44 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:44 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:44 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:44 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 13 (61.5%):  24%|██████████████████                                                         | 12/50 [00:01<00:03, 10.56it/s]2025-08-18 21:33:44 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:44 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:44 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:44 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 14 (64.3%):  26%|███████████████████▌                                                       | 13/50 [00:01<00:03, 10.56it/s]2025-08-18 21:33:44 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:44 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:44 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:44 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 15 (60.0%):  28%|█████████████████████                                                      | 14/50 [00:01<00:03, 10.56it/s]2025-08-18 21:33:44 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 9.00 / 15 (60.0%):  30%|██████████████████████▌                                                    | 15/50 [00:01<00:01, 17.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:44 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:44 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:44 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 16 (56.2%):  30%|██████████████████████▌                                                    | 15/50 [00:01<00:01, 17.52it/s]2025-08-18 21:33:44 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:44 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:44 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:44 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 17 (52.9%):  32%|████████████████████████                                                   | 16/50 [00:01<00:01, 17.52it/s]2025-08-18 21:33:44 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:45 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:45 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 10.00 / 18 (55.6%):  34%|█████████████████████████▏                                                | 17/50 [00:01<00:01, 17.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:45 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:45 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:45 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:45 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:45 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 19 (57.9%):  36%|██████████████████████████▋                                               | 18/50 [00:01<00:01, 17.52it/s]2025-08-18 21:33:45 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 11.00 / 19 (57.9%):  38%|████████████████████████████                                              | 19/50 [00:01<00:02, 13.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:45 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:45 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:45 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 20 (60.0%):  38%|████████████████████████████                                              | 19/50 [00:01<00:02, 13.54it/s]2025-08-18 21:33:45 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:45 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:45 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:45 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 21 (61.9%):  40%|█████████████████████████████▌                                            | 20/50 [00:01<00:02, 13.54it/s]2025-08-18 21:33:45 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:45 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:45 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 14.00 / 22 (63.6%):  42%|███████████████████████████████                                           | 21/50 [00:01<00:02, 13.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:45 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:45 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:45 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:45 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:45 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 23 (60.9%):  44%|████████████████████████████████▌                                         | 22/50 [00:01<00:02, 13.54it/s]2025-08-18 21:33:45 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:45 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:45 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:45 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 24 (58.3%):  46%|██████████████████████████████████                                        | 23/50 [00:01<00:01, 13.54it/s]2025-08-18 21:33:45 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 14.00 / 24 (58.3%):  48%|███████████████████████████████████▌                                      | 24/50 [00:01<00:01, 16.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:45 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:45 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:45 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 25 (60.0%):  48%|███████████████████████████████████▌                                      | 24/50 [00:01<00:01, 16.34it/s]2025-08-18 21:33:45 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:45 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:45 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:45 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 26 (61.5%):  50%|█████████████████████████████████████                                     | 25/50 [00:01<00:01, 16.34it/s]2025-08-18 21:33:45 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:45 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:45 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:45 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 27 (63.0%):  52%|██████████████████████████████████████▍                                   | 26/50 [00:01<00:01, 16.34it/s]2025-08-18 21:33:45 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 17.00 / 27 (63.0%):  54%|███████████████████████████████████████▉                                  | 27/50 [00:01<00:01, 14.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:45 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:45 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 17.00 / 28 (60.7%):  54%|███████████████████████████████████████▉                                  | 27/50 [00:02<00:01, 14.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:45 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:45 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:45 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:45 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 17.00 / 29 (58.6%):  56%|█████████████████████████████████████████▍                                | 28/50 [00:02<00:01, 14.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:45 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:45 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:45 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:45 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:45 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 30 (56.7%):  58%|██████████████████████████████████████████▉                               | 29/50 [00:02<00:01, 14.86it/s]2025-08-18 21:33:45 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:45 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:45 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:45 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 31 (58.1%):  62%|█████████████████████████████████████████████▉                            | 31/50 [00:02<00:01, 17.50it/s]2025-08-18 21:33:45 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:45 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:45 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:45 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 32 (56.2%):  62%|█████████████████████████████████████████████▉                            | 31/50 [00:02<00:01, 17.50it/s]2025-08-18 21:33:45 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:45 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:45 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:45 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:45 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 19.00 / 33 (57.6%):  64%|███████████████████████████████████████████████▎                          | 32/50 [00:02<00:01, 17.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:46 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:46 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 20.00 / 34 (58.8%):  66%|████████████████████████████████████████████████▊                         | 33/50 [00:02<00:00, 17.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:46 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 34 (58.8%):  68%|██████████████████████████████████████████████████▎                       | 34/50 [00:02<00:01, 13.76it/s]2025-08-18 21:33:46 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:46 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:46 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:46 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 35 (60.0%):  68%|██████████████████████████████████████████████████▎                       | 34/50 [00:02<00:01, 13.76it/s]2025-08-18 21:33:46 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:46 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:46 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:46 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 36 (61.1%):  70%|███████████████████████████████████████████████████▊                      | 35/50 [00:02<00:01, 13.76it/s]2025-08-18 21:33:46 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:46 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:46 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:46 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 37 (59.5%):  72%|█████████████████████████████████████████████████████▎                    | 36/50 [00:02<00:01, 13.76it/s]2025-08-18 21:33:46 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:46 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:46 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:46 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 38 (60.5%):  74%|██████████████████████████████████████████████████████▊                   | 37/50 [00:02<00:00, 13.76it/s]2025-08-18 21:33:46 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:46 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:46 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:46 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 39 (59.0%):  76%|████████████████████████████████████████████████████████▏                 | 38/50 [00:03<00:00, 13.76it/s]2025-08-18 21:33:46 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 23.00 / 39 (59.0%):  78%|█████████████████████████████████████████████████████████▋                | 39/50 [00:03<00:00, 11.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:46 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:46 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:46 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 40 (57.5%):  78%|█████████████████████████████████████████████████████████▋                | 39/50 [00:03<00:00, 11.23it/s]2025-08-18 21:33:46 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:46 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:46 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:46 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:46 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 24.00 / 41 (58.5%):  80%|███████████████████████████████████████████████████████████▏              | 40/50 [00:03<00:00, 11.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:46 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:46 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 25.00 / 42 (59.5%):  82%|████████████████████████████████████████████████████████████▋             | 41/50 [00:03<00:00, 11.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:46 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:46 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:46 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:46 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 25.00 / 43 (58.1%):  84%|██████████████████████████████████████████████████████████████▏           | 42/50 [00:03<00:00, 11.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:46 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:46 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 26.00 / 44 (59.1%):  86%|███████████████████████████████████████████████████████████████▋          | 43/50 [00:03<00:00, 11.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:46 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:46 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 26.00 / 45 (57.8%):  88%|█████████████████████████████████████████████████████████████████         | 44/50 [00:03<00:00, 11.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:46 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:46 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 27.00 / 46 (58.7%):  92%|████████████████████████████████████████████████████████████████████      | 46/50 [00:03<00:00, 16.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:47 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:47 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 28.00 / 47 (59.6%):  92%|████████████████████████████████████████████████████████████████████      | 46/50 [00:03<00:00, 16.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:47 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:47 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 29.00 / 48 (60.4%):  94%|█████████████████████████████████████████████████████████████████████▌    | 47/50 [00:03<00:00, 16.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:47 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:47 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 30.00 / 49 (61.2%):  98%|████████████████████████████████████████████████████████████████████████▌ | 49/50 [00:04<00:00,  9.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:47 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:47 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 31.00 / 50 (62.0%): 100%|██████████████████████████████████████████████████████████████████████████| 50/50 [00:04<00:00, 11.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/18 21:33:47 INFO dspy.evaluate.evaluate: Average Metric: 31 / 50 (62.0%)\n",
      "2025/08/18 21:33:47 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 62.0 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 5'].\n",
      "2025/08/18 21:33:47 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [74.0, 72.0, 70.0, 58.0, 62.0, 62.0, 72.0, 74.0, 58.0, 76.0, 78.0, 78.0, 74.0, 70.0, 74.0, 62.0]\n",
      "2025/08/18 21:33:47 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 78.0\n",
      "2025/08/18 21:33:47 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/08/18 21:33:47 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 17 / 18 =====\n",
      "\u001b[92m21:33:47 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-08-18 21:33:47 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:47 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:47 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:47 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:47 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "  0%|                                                                                                                       | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:47 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:47 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:47 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:47 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:47 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:47 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:47 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:47 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:47 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:47 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 1.00 / 1 (100.0%):   0%|                                                                                    | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 1 (100.0%):   2%|█▌                                                                          | 1/50 [00:00<00:25,  1.95it/s]2025-08-18 21:33:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 2 (100.0%):   2%|█▌                                                                          | 1/50 [00:00<00:25,  1.95it/s]2025-08-18 21:33:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 3 (66.7%):   4%|███                                                                          | 2/50 [00:00<00:24,  1.95it/s]2025-08-18 21:33:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 2.00 / 4 (50.0%):   6%|████▌                                                                        | 3/50 [00:00<00:24,  1.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 5 (60.0%):   8%|██████▏                                                                      | 4/50 [00:00<00:23,  1.95it/s]2025-08-18 21:33:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 6 (50.0%):  10%|███████▋                                                                     | 5/50 [00:00<00:23,  1.95it/s]2025-08-18 21:33:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 7 (57.1%):  12%|█████████▏                                                                   | 6/50 [00:00<00:22,  1.95it/s]2025-08-18 21:33:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 8 (62.5%):  14%|██████████▊                                                                  | 7/50 [00:00<00:21,  1.95it/s]2025-08-18 21:33:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 5.00 / 8 (62.5%):  16%|████████████▎                                                                | 8/50 [00:00<00:04,  9.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 9 (66.7%):  16%|████████████▎                                                                | 8/50 [00:01<00:04,  9.30it/s]2025-08-18 21:33:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 10 (70.0%):  18%|█████████████▋                                                              | 9/50 [00:01<00:04,  9.30it/s]2025-08-18 21:33:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 11 (72.7%):  20%|███████████████                                                            | 10/50 [00:01<00:04,  9.30it/s]2025-08-18 21:33:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 12 (75.0%):  22%|████████████████▌                                                          | 11/50 [00:01<00:04,  9.30it/s]2025-08-18 21:33:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 9.00 / 12 (75.0%):  24%|██████████████████                                                         | 12/50 [00:01<00:02, 13.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 13 (69.2%):  24%|██████████████████                                                         | 12/50 [00:01<00:02, 13.44it/s]2025-08-18 21:33:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 14 (71.4%):  26%|███████████████████▏                                                      | 13/50 [00:01<00:02, 13.44it/s]2025-08-18 21:33:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 11.00 / 15 (73.3%):  28%|████████████████████▋                                                     | 14/50 [00:01<00:02, 13.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 15 (73.3%):  30%|██████████████████████▏                                                   | 15/50 [00:01<00:02, 14.55it/s]2025-08-18 21:33:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 12.00 / 16 (75.0%):  30%|██████████████████████▏                                                   | 15/50 [00:01<00:02, 14.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 13.00 / 17 (76.5%):  32%|███████████████████████▋                                                  | 16/50 [00:01<00:02, 14.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 17 (76.5%):  34%|█████████████████████████▏                                                | 17/50 [00:01<00:02, 11.84it/s]2025-08-18 21:33:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 18 (77.8%):  34%|█████████████████████████▏                                                | 17/50 [00:01<00:02, 11.84it/s]2025-08-18 21:33:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 19 (78.9%):  36%|██████████████████████████▋                                               | 18/50 [00:01<00:02, 11.84it/s]2025-08-18 21:33:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 20 (80.0%):  38%|████████████████████████████                                              | 19/50 [00:01<00:02, 11.84it/s]2025-08-18 21:33:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 21 (81.0%):  40%|█████████████████████████████▌                                            | 20/50 [00:01<00:02, 11.84it/s]2025-08-18 21:33:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 22 (81.8%):  42%|███████████████████████████████                                           | 21/50 [00:01<00:02, 11.84it/s]2025-08-18 21:33:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 18.00 / 22 (81.8%):  44%|████████████████████████████████▌                                         | 22/50 [00:01<00:01, 16.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 23 (82.6%):  44%|████████████████████████████████▌                                         | 22/50 [00:01<00:01, 16.15it/s]2025-08-18 21:33:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 19.00 / 24 (79.2%):  46%|██████████████████████████████████                                        | 23/50 [00:01<00:01, 16.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 19.00 / 24 (79.2%):  48%|███████████████████████████████████▌                                      | 24/50 [00:01<00:01, 13.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 25 (80.0%):  48%|███████████████████████████████████▌                                      | 24/50 [00:02<00:01, 13.39it/s]2025-08-18 21:33:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 20.00 / 26 (76.9%):  50%|█████████████████████████████████████                                     | 25/50 [00:02<00:01, 13.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 20.00 / 26 (76.9%):  52%|██████████████████████████████████████▍                                   | 26/50 [00:02<00:01, 13.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 21.00 / 27 (77.8%):  52%|██████████████████████████████████████▍                                   | 26/50 [00:02<00:01, 13.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 28 (75.0%):  54%|███████████████████████████████████████▉                                  | 27/50 [00:02<00:01, 13.40it/s]2025-08-18 21:33:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 29 (75.9%):  56%|█████████████████████████████████████████▍                                | 28/50 [00:02<00:01, 13.40it/s]2025-08-18 21:33:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 30 (73.3%):  58%|██████████████████████████████████████████▉                               | 29/50 [00:02<00:01, 13.40it/s]2025-08-18 21:33:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:50 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:50 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 23.00 / 31 (74.2%):  60%|████████████████████████████████████████████▍                             | 30/50 [00:02<00:01, 13.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:50 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 31 (74.2%):  62%|█████████████████████████████████████████████▉                            | 31/50 [00:02<00:01, 18.30it/s]2025-08-18 21:33:50 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:50 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:50 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:50 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 32 (71.9%):  62%|█████████████████████████████████████████████▉                            | 31/50 [00:02<00:01, 18.30it/s]2025-08-18 21:33:50 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:50 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:50 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:50 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 33 (72.7%):  64%|███████████████████████████████████████████████▎                          | 32/50 [00:02<00:00, 18.30it/s]2025-08-18 21:33:50 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:50 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:50 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:50 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.00 / 34 (73.5%):  68%|██████████████████████████████████████████████████▎                       | 34/50 [00:02<00:01, 14.87it/s]2025-08-18 21:33:50 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:50 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:50 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 25.00 / 35 (71.4%):  68%|██████████████████████████████████████████████████▎                       | 34/50 [00:02<00:01, 14.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:50 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:50 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:50 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:50 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:50 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 26.00 / 36 (72.2%):  70%|███████████████████████████████████████████████████▊                      | 35/50 [00:02<00:01, 14.87it/s]2025-08-18 21:33:50 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:50 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:50 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:50 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27.00 / 37 (73.0%):  72%|█████████████████████████████████████████████████████▎                    | 36/50 [00:02<00:00, 14.87it/s]2025-08-18 21:33:50 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:50 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:50 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 27.00 / 38 (71.1%):  74%|██████████████████████████████████████████████████████▊                   | 37/50 [00:02<00:00, 14.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:50 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:50 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 27.00 / 38 (71.1%):  76%|████████████████████████████████████████████████████████▏                 | 38/50 [00:02<00:00, 18.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:50 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:50 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:50 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 28.00 / 39 (71.8%):  76%|████████████████████████████████████████████████████████▏                 | 38/50 [00:02<00:00, 18.53it/s]2025-08-18 21:33:50 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:50 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:50 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 28.00 / 40 (70.0%):  78%|█████████████████████████████████████████████████████████▋                | 39/50 [00:02<00:00, 18.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:50 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:50 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:50 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:50 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 29.00 / 41 (70.7%):  80%|███████████████████████████████████████████████████████████▏              | 40/50 [00:02<00:00, 18.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:50 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 29.00 / 41 (70.7%):  82%|████████████████████████████████████████████████████████████▋             | 41/50 [00:02<00:00, 15.53it/s]2025-08-18 21:33:50 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:50 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:50 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:50 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 30.00 / 42 (71.4%):  82%|████████████████████████████████████████████████████████████▋             | 41/50 [00:02<00:00, 15.53it/s]2025-08-18 21:33:50 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:50 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:50 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 31.00 / 43 (72.1%):  84%|██████████████████████████████████████████████████████████████▏           | 42/50 [00:02<00:00, 15.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:50 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:50 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:50 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 31.00 / 44 (70.5%):  86%|███████████████████████████████████████████████████████████████▋          | 43/50 [00:03<00:00, 15.53it/s]2025-08-18 21:33:50 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 31.00 / 45 (68.9%):  88%|█████████████████████████████████████████████████████████████████         | 44/50 [00:03<00:00, 15.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:50 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:50 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 32.00 / 46 (69.6%):  92%|████████████████████████████████████████████████████████████████████      | 46/50 [00:03<00:00, 18.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:51 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:51 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 33.00 / 47 (70.2%):  92%|████████████████████████████████████████████████████████████████████      | 46/50 [00:03<00:00, 18.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:51 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:51 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 34.00 / 48 (70.8%):  94%|█████████████████████████████████████████████████████████████████████▌    | 47/50 [00:03<00:00, 18.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:51 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:51 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 35.00 / 49 (71.4%):  98%|████████████████████████████████████████████████████████████████████████▌ | 49/50 [00:03<00:00, 14.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:51 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:51 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 36.00 / 50 (72.0%): 100%|██████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 14.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/18 21:33:51 INFO dspy.evaluate.evaluate: Average Metric: 36 / 50 (72.0%)\n",
      "2025/08/18 21:33:51 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 72.0 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 10'].\n",
      "2025/08/18 21:33:51 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [74.0, 72.0, 70.0, 58.0, 62.0, 62.0, 72.0, 74.0, 58.0, 76.0, 78.0, 78.0, 74.0, 70.0, 74.0, 62.0, 72.0]\n",
      "2025/08/18 21:33:51 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 78.0\n",
      "2025/08/18 21:33:51 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/08/18 21:33:51 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 18 / 18 =====\n",
      "\u001b[92m21:33:51 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-08-18 21:33:51 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:51 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:51 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:51 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:51 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:51 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                       | 0/50 [00:00<?, ?it/s]2025-08-18 21:33:51 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:51 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:33:51 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:51 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:33:51 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:51 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:51 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:51 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:51 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 1.00 / 1 (100.0%):   0%|                                                                                    | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 1.00 / 1 (100.0%):   2%|█▌                                                                          | 1/50 [00:00<00:23,  2.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 2.00 / 2 (100.0%):   2%|█▌                                                                          | 1/50 [00:00<00:23,  2.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 3.00 / 3 (100.0%):   4%|███                                                                         | 2/50 [00:00<00:23,  2.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 4 (75.0%):   6%|████▌                                                                        | 3/50 [00:00<00:22,  2.07it/s]2025-08-18 21:33:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 5 (60.0%):   8%|██████▏                                                                      | 4/50 [00:00<00:22,  2.07it/s]2025-08-18 21:33:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 6 (50.0%):  10%|███████▋                                                                     | 5/50 [00:00<00:21,  2.07it/s]2025-08-18 21:33:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 7 (57.1%):  12%|█████████▏                                                                   | 6/50 [00:00<00:21,  2.07it/s]2025-08-18 21:33:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 8 (50.0%):  14%|██████████▊                                                                  | 7/50 [00:00<00:20,  2.07it/s]2025-08-18 21:33:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 9 (55.6%):  16%|████████████▎                                                                | 8/50 [00:00<00:20,  2.07it/s]2025-08-18 21:33:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 5.00 / 9 (55.6%):  18%|█████████████▊                                                               | 9/50 [00:01<00:04, 10.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:33:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:33:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 6.00 / 10 (60.0%):  18%|█████████████▋                                                              | 9/50 [00:01<00:04, 10.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:33:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 7.00 / 11 (63.6%):  20%|███████████████                                                            | 10/50 [00:01<00:03, 10.17it/s]2025-08-18 21:33:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 12 (66.7%):  22%|████████████████▌                                                          | 11/50 [00:01<00:03, 10.17it/s]2025-08-18 21:33:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 13 (69.2%):  24%|██████████████████                                                         | 12/50 [00:01<00:03, 10.17it/s]2025-08-18 21:33:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 14 (71.4%):  26%|███████████████████▏                                                      | 13/50 [00:01<00:03, 10.17it/s]2025-08-18 21:33:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 15 (73.3%):  28%|████████████████████▋                                                     | 14/50 [00:01<00:03, 10.17it/s]2025-08-18 21:33:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 16 (75.0%):  30%|██████████████████████▏                                                   | 15/50 [00:01<00:03, 10.17it/s]2025-08-18 21:33:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 12.00 / 16 (75.0%):  32%|███████████████████████▋                                                  | 16/50 [00:01<00:01, 18.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 17 (76.5%):  32%|███████████████████████▋                                                  | 16/50 [00:01<00:01, 18.36it/s]2025-08-18 21:33:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 18 (77.8%):  34%|█████████████████████████▏                                                | 17/50 [00:01<00:01, 18.36it/s]2025-08-18 21:33:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:33:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:33:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 19 (73.7%):  36%|██████████████████████████▋                                               | 18/50 [00:01<00:01, 18.36it/s]2025-08-18 21:33:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 15.00 / 20 (75.0%):  38%|████████████████████████████                                              | 19/50 [00:01<00:01, 18.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 15.00 / 20 (75.0%):  40%|█████████████████████████████▌                                            | 20/50 [00:01<00:02, 13.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 16.00 / 21 (76.2%):  40%|█████████████████████████████▌                                            | 20/50 [00:01<00:02, 13.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 17.00 / 22 (77.3%):  42%|███████████████████████████████                                           | 21/50 [00:01<00:02, 13.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 23 (78.3%):  44%|████████████████████████████████▌                                         | 22/50 [00:01<00:02, 13.81it/s]2025-08-18 21:33:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 24 (79.2%):  46%|██████████████████████████████████                                        | 23/50 [00:01<00:01, 13.81it/s]2025-08-18 21:33:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 25 (80.0%):  48%|███████████████████████████████████▌                                      | 24/50 [00:02<00:01, 13.81it/s]2025-08-18 21:33:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 20.00 / 25 (80.0%):  50%|█████████████████████████████████████                                     | 25/50 [00:02<00:01, 12.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 26 (80.8%):  50%|█████████████████████████████████████                                     | 25/50 [00:02<00:01, 12.84it/s]2025-08-18 21:33:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 27 (77.8%):  52%|██████████████████████████████████████▍                                   | 26/50 [00:02<00:01, 12.84it/s]2025-08-18 21:33:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 28 (78.6%):  54%|███████████████████████████████████████▉                                  | 27/50 [00:02<00:01, 12.84it/s]2025-08-18 21:33:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 22.00 / 29 (75.9%):  56%|█████████████████████████████████████████▍                                | 28/50 [00:02<00:01, 12.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 30 (76.7%):  58%|██████████████████████████████████████████▉                               | 29/50 [00:02<00:01, 12.84it/s]2025-08-18 21:33:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 31 (77.4%):  60%|████████████████████████████████████████████▍                             | 30/50 [00:02<00:01, 12.84it/s]2025-08-18 21:33:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 24.00 / 31 (77.4%):  62%|█████████████████████████████████████████████▉                            | 31/50 [00:02<00:01, 17.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 32 (75.0%):  62%|█████████████████████████████████████████████▉                            | 31/50 [00:02<00:01, 17.86it/s]2025-08-18 21:33:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 25.00 / 33 (75.8%):  64%|███████████████████████████████████████████████▎                          | 32/50 [00:02<00:01, 17.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.00 / 34 (73.5%):  66%|████████████████████████████████████████████████▊                         | 33/50 [00:02<00:00, 17.86it/s]2025-08-18 21:33:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 25.00 / 34 (73.5%):  68%|██████████████████████████████████████████████████▎                       | 34/50 [00:02<00:01, 12.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 26.00 / 35 (74.3%):  68%|██████████████████████████████████████████████████▎                       | 34/50 [00:02<00:01, 12.57it/s]2025-08-18 21:33:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27.00 / 36 (75.0%):  70%|███████████████████████████████████████████████████▊                      | 35/50 [00:02<00:01, 12.57it/s]2025-08-18 21:33:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 28.00 / 37 (75.7%):  72%|█████████████████████████████████████████████████████▎                    | 36/50 [00:02<00:01, 12.57it/s]2025-08-18 21:33:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 29.00 / 38 (76.3%):  74%|██████████████████████████████████████████████████████▊                   | 37/50 [00:02<00:01, 12.57it/s]2025-08-18 21:33:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 30.00 / 39 (76.9%):  76%|████████████████████████████████████████████████████████▏                 | 38/50 [00:02<00:00, 12.57it/s]2025-08-18 21:33:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 31.00 / 40 (77.5%):  78%|█████████████████████████████████████████████████████████▋                | 39/50 [00:02<00:00, 12.57it/s]2025-08-18 21:33:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 32.00 / 41 (78.0%):  82%|████████████████████████████████████████████████████████████▋             | 41/50 [00:03<00:00, 13.83it/s]2025-08-18 21:33:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 32.00 / 42 (76.2%):  82%|████████████████████████████████████████████████████████████▋             | 41/50 [00:03<00:00, 13.83it/s]2025-08-18 21:33:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 32.00 / 43 (74.4%):  84%|██████████████████████████████████████████████████████████████▏           | 42/50 [00:03<00:00, 13.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 33.00 / 44 (75.0%):  88%|█████████████████████████████████████████████████████████████████         | 44/50 [00:03<00:00, 14.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 34.00 / 45 (75.6%):  88%|█████████████████████████████████████████████████████████████████         | 44/50 [00:03<00:00, 14.30it/s]2025-08-18 21:33:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 34.00 / 46 (73.9%):  90%|██████████████████████████████████████████████████████████████████▌       | 45/50 [00:03<00:00, 14.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 35.00 / 47 (74.5%):  94%|█████████████████████████████████████████████████████████████████████▌    | 47/50 [00:03<00:00, 16.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 35.00 / 48 (72.9%):  94%|█████████████████████████████████████████████████████████████████████▌    | 47/50 [00:03<00:00, 16.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 36.00 / 49 (73.5%):  96%|███████████████████████████████████████████████████████████████████████   | 48/50 [00:03<00:00, 16.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 36.00 / 50 (72.0%): 100%|██████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 13.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/18 21:33:55 INFO dspy.evaluate.evaluate: Average Metric: 36 / 50 (72.0%)\n",
      "2025/08/18 21:33:55 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 72.0 with parameters ['Predictor 0: Instruction 3', 'Predictor 0: Few-Shot Set 7'].\n",
      "2025/08/18 21:33:55 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [74.0, 72.0, 70.0, 58.0, 62.0, 62.0, 72.0, 74.0, 58.0, 76.0, 78.0, 78.0, 74.0, 70.0, 74.0, 62.0, 72.0, 72.0]\n",
      "2025/08/18 21:33:55 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 78.0\n",
      "2025/08/18 21:33:55 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/08/18 21:33:55 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 19 / 18 =====\n",
      "\u001b[92m21:33:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-08-18 21:33:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:33:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                       | 0/50 [00:00<?, ?it/s]2025-08-18 21:33:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:33:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:33:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:33:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 1 (100.0%):   0%|                                                                                    | 0/50 [00:00<?, ?it/s]2025-08-18 21:33:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 1.00 / 1 (100.0%):   2%|█▌                                                                          | 1/50 [00:00<00:22,  2.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 2 (50.0%):   2%|█▌                                                                           | 1/50 [00:00<00:22,  2.18it/s]2025-08-18 21:33:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 3 (66.7%):   4%|███                                                                          | 2/50 [00:00<00:22,  2.18it/s]2025-08-18 21:33:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 3.00 / 4 (75.0%):   6%|████▌                                                                        | 3/50 [00:00<00:21,  2.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 3.00 / 5 (60.0%):   8%|██████▏                                                                      | 4/50 [00:00<00:21,  2.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 6 (66.7%):  10%|███████▋                                                                     | 5/50 [00:00<00:20,  2.18it/s]2025-08-18 21:33:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 7 (71.4%):  12%|█████████▏                                                                   | 6/50 [00:00<00:20,  2.18it/s]2025-08-18 21:33:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 8 (62.5%):  14%|██████████▊                                                                  | 7/50 [00:00<00:19,  2.18it/s]2025-08-18 21:33:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 5.00 / 8 (62.5%):  16%|████████████▎                                                                | 8/50 [00:00<00:02, 18.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 9 (66.7%):  16%|████████████▎                                                                | 8/50 [00:00<00:02, 18.10it/s]2025-08-18 21:33:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 10 (70.0%):  18%|█████████████▋                                                              | 9/50 [00:00<00:02, 18.10it/s]2025-08-18 21:33:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 8.00 / 11 (72.7%):  20%|███████████████                                                            | 10/50 [00:01<00:02, 18.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 9.00 / 12 (75.0%):  22%|████████████████▌                                                          | 11/50 [00:01<00:02, 18.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 13 (76.9%):  24%|█████████████████▊                                                        | 12/50 [00:01<00:02, 18.10it/s]2025-08-18 21:33:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 13 (76.9%):  26%|███████████████████▏                                                      | 13/50 [00:01<00:02, 13.74it/s]2025-08-18 21:33:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 14 (78.6%):  26%|███████████████████▏                                                      | 13/50 [00:01<00:02, 13.74it/s]2025-08-18 21:33:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 12.00 / 15 (80.0%):  28%|████████████████████▋                                                     | 14/50 [00:01<00:02, 13.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 16 (81.2%):  30%|██████████████████████▏                                                   | 15/50 [00:01<00:02, 13.74it/s]2025-08-18 21:33:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 14.00 / 17 (82.4%):  32%|███████████████████████▋                                                  | 16/50 [00:01<00:02, 13.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 14.00 / 17 (82.4%):  34%|█████████████████████████▏                                                | 17/50 [00:01<00:02, 11.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 18 (83.3%):  34%|█████████████████████████▏                                                | 17/50 [00:01<00:02, 11.61it/s]2025-08-18 21:33:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 16.00 / 19 (84.2%):  36%|██████████████████████████▋                                               | 18/50 [00:01<00:02, 11.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 20 (80.0%):  38%|████████████████████████████                                              | 19/50 [00:01<00:02, 11.61it/s]2025-08-18 21:33:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 21 (81.0%):  40%|█████████████████████████████▌                                            | 20/50 [00:01<00:02, 11.61it/s]2025-08-18 21:33:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 18.00 / 22 (81.8%):  42%|███████████████████████████████                                           | 21/50 [00:01<00:02, 11.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 23 (82.6%):  44%|████████████████████████████████▌                                         | 22/50 [00:01<00:02, 11.61it/s]2025-08-18 21:33:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 19.00 / 23 (82.6%):  46%|██████████████████████████████████                                        | 23/50 [00:01<00:01, 17.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 24 (83.3%):  46%|██████████████████████████████████                                        | 23/50 [00:01<00:01, 17.66it/s]2025-08-18 21:33:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 25 (84.0%):  48%|███████████████████████████████████▌                                      | 24/50 [00:01<00:01, 17.66it/s]2025-08-18 21:33:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 21.00 / 26 (80.8%):  50%|█████████████████████████████████████                                     | 25/50 [00:01<00:01, 17.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 27 (81.5%):  52%|██████████████████████████████████████▍                                   | 26/50 [00:02<00:01, 17.66it/s]2025-08-18 21:33:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 22.00 / 27 (81.5%):  54%|███████████████████████████████████████▉                                  | 27/50 [00:02<00:01, 13.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 28 (82.1%):  54%|███████████████████████████████████████▉                                  | 27/50 [00:02<00:01, 13.90it/s]2025-08-18 21:33:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 29 (79.3%):  56%|█████████████████████████████████████████▍                                | 28/50 [00:02<00:01, 13.90it/s]2025-08-18 21:33:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 30 (76.7%):  58%|██████████████████████████████████████████▉                               | 29/50 [00:02<00:01, 13.90it/s]2025-08-18 21:33:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 31 (77.4%):  60%|████████████████████████████████████████████▍                             | 30/50 [00:02<00:01, 13.90it/s]2025-08-18 21:33:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 32 (75.0%):  62%|█████████████████████████████████████████████▉                            | 31/50 [00:02<00:01, 13.90it/s]2025-08-18 21:33:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.00 / 33 (75.8%):  66%|████████████████████████████████████████████████▊                         | 33/50 [00:02<00:01, 13.96it/s]2025-08-18 21:33:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 26.00 / 34 (76.5%):  66%|████████████████████████████████████████████████▊                         | 33/50 [00:02<00:01, 13.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 26.00 / 35 (74.3%):  68%|██████████████████████████████████████████████████▎                       | 34/50 [00:02<00:01, 13.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 27.00 / 36 (75.0%):  70%|███████████████████████████████████████████████████▊                      | 35/50 [00:02<00:01, 13.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 28.00 / 37 (75.7%):  72%|█████████████████████████████████████████████████████▎                    | 36/50 [00:02<00:01, 13.96it/s]2025-08-18 21:33:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 29.00 / 38 (76.3%):  74%|██████████████████████████████████████████████████████▊                   | 37/50 [00:02<00:00, 13.96it/s]2025-08-18 21:33:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 29.00 / 39 (74.4%):  76%|████████████████████████████████████████████████████████▏                 | 38/50 [00:02<00:00, 13.96it/s]2025-08-18 21:33:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 29.00 / 39 (74.4%):  78%|█████████████████████████████████████████████████████████▋                | 39/50 [00:02<00:00, 18.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 30.00 / 40 (75.0%):  78%|█████████████████████████████████████████████████████████▋                | 39/50 [00:02<00:00, 18.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:58 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 31.00 / 41 (75.6%):  80%|███████████████████████████████████████████████████████████▏              | 40/50 [00:02<00:00, 18.65it/s]2025-08-18 21:33:58 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:58 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 31.00 / 42 (73.8%):  82%|████████████████████████████████████████████████████████████▋             | 41/50 [00:02<00:00, 18.65it/s]2025-08-18 21:33:58 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 31.00 / 42 (73.8%):  84%|██████████████████████████████████████████████████████████████▏           | 42/50 [00:02<00:00, 14.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 31.00 / 43 (72.1%):  84%|██████████████████████████████████████████████████████████████▏           | 42/50 [00:02<00:00, 14.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 32.00 / 44 (72.7%):  86%|███████████████████████████████████████████████████████████████▋          | 43/50 [00:02<00:00, 14.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 33.00 / 45 (73.3%):  88%|█████████████████████████████████████████████████████████████████         | 44/50 [00:03<00:00, 14.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 34.00 / 46 (73.9%):  90%|██████████████████████████████████████████████████████████████████▌       | 45/50 [00:03<00:00, 14.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 34.00 / 46 (73.9%):  92%|████████████████████████████████████████████████████████████████████      | 46/50 [00:03<00:00, 17.15it/s]2025-08-18 21:33:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 35.00 / 48 (72.9%):  94%|█████████████████████████████████████████████████████████████████████▌    | 47/50 [00:03<00:00, 17.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 36.00 / 49 (73.5%):  98%|████████████████████████████████████████████████████████████████████████▌ | 49/50 [00:03<00:00, 14.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:33:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:33:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 37.00 / 50 (74.0%): 100%|██████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 14.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/18 21:33:58 INFO dspy.evaluate.evaluate: Average Metric: 37 / 50 (74.0%)\n",
      "2025/08/18 21:33:58 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 74.0 with parameters ['Predictor 0: Instruction 4', 'Predictor 0: Few-Shot Set 7'].\n",
      "2025/08/18 21:33:58 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [74.0, 72.0, 70.0, 58.0, 62.0, 62.0, 72.0, 74.0, 58.0, 76.0, 78.0, 78.0, 74.0, 70.0, 74.0, 62.0, 72.0, 72.0, 74.0]\n",
      "2025/08/18 21:33:58 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 78.0\n",
      "2025/08/18 21:33:58 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/08/18 21:33:58 INFO dspy.teleprompt.mipro_optimizer_v2: Returning best identified program with score 78.0!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "judge_model = dspy.LM(\n",
    "    \"gemini/gemini-1.5-flash\",\n",
    "    api_key=secrets[\"GEMINI_API_KEY\"],\n",
    "    cache=False,\n",
    "    temperature=0\n",
    ")\n",
    "dspy.configure(lm=judge_model,track_usage=True,adapter=dspy.JSONAdapter())\n",
    "generate_judge_reasoning = dspy.ChainOfThought(SupportTranscriptJudge)\n",
    "\n",
    "optimizer = dspy.MIPROv2(\n",
    "    metric=match_judge_metric,\n",
    "    auto=\"medium\",\n",
    "    init_temperature=1.0,\n",
    "    seed=101\n",
    ")\n",
    "\n",
    "generate_judge_reasoning_optimized = optimizer.compile(\n",
    "    generate_judge_reasoning,\n",
    "    trainset=training_set,\n",
    "    valset=validation_set,\n",
    "    requires_permission_to_run=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d768118-19eb-4fb0-9d78-09cba468ecae",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "  0%|                                                                                                                      | 0/160 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 1.00 / 1 (100.0%):   0%|                                                                                   | 0/160 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 1.00 / 1 (100.0%):   1%|▍                                                                          | 1/160 [00:00<01:24,  1.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 2 (100.0%):   1%|▍                                                                          | 1/160 [00:00<01:24,  1.88it/s]2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 3 (100.0%):   1%|▉                                                                          | 2/160 [00:00<01:24,  1.88it/s]2025-08-18 21:35:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 4.00 / 4 (100.0%):   2%|█▍                                                                         | 3/160 [00:00<01:23,  1.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 5.00 / 5 (100.0%):   2%|█▉                                                                         | 4/160 [00:00<01:22,  1.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 6 (83.3%):   3%|██▍                                                                         | 5/160 [00:00<01:22,  1.88it/s]2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 6.00 / 7 (85.7%):   4%|██▊                                                                         | 6/160 [00:00<01:21,  1.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 8 (87.5%):   4%|███▎                                                                        | 7/160 [00:00<01:21,  1.88it/s]2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 9 (88.9%):   5%|███▊                                                                        | 8/160 [00:00<01:20,  1.88it/s]2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 9.00 / 10 (90.0%):   6%|████▏                                                                      | 9/160 [00:00<01:20,  1.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 11 (81.8%):   6%|████▋                                                                     | 10/160 [00:00<01:19,  1.88it/s]2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 12 (83.3%):   7%|█████                                                                    | 11/160 [00:00<01:19,  1.88it/s]2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 13 (76.9%):   8%|█████▍                                                                   | 12/160 [00:00<01:18,  1.88it/s]2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 14 (71.4%):   8%|█████▉                                                                   | 13/160 [00:00<01:18,  1.88it/s]2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 15 (73.3%):   9%|██████▍                                                                  | 14/160 [00:00<01:17,  1.88it/s]2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 16 (75.0%):   9%|██████▊                                                                  | 15/160 [00:00<01:17,  1.88it/s]2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 17 (70.6%):  10%|███████▎                                                                 | 16/160 [00:00<01:16,  1.88it/s]2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 18 (66.7%):  11%|███████▊                                                                 | 17/160 [00:00<01:16,  1.88it/s]2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 19 (68.4%):  11%|████████▏                                                                | 18/160 [00:00<01:15,  1.88it/s]2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 13.00 / 20 (65.0%):  12%|████████▋                                                                | 19/160 [00:00<01:14,  1.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 21 (66.7%):  12%|█████████▏                                                               | 20/160 [00:00<01:14,  1.88it/s]2025-08-18 21:35:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 22 (68.2%):  13%|█████████▌                                                               | 21/160 [00:00<01:13,  1.88it/s]2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 23 (65.2%):  14%|██████████                                                               | 22/160 [00:00<01:13,  1.88it/s]2025-08-18 21:35:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 15.00 / 23 (65.2%):  14%|██████████▍                                                              | 23/160 [00:00<00:02, 47.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 24 (62.5%):  14%|██████████▍                                                              | 23/160 [00:00<00:02, 47.44it/s]2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 25 (64.0%):  15%|██████████▉                                                              | 24/160 [00:01<00:02, 47.44it/s]2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 26 (65.4%):  16%|███████████▍                                                             | 25/160 [00:01<00:02, 47.44it/s]2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 18.00 / 27 (66.7%):  16%|███████████▊                                                             | 26/160 [00:01<00:02, 47.44it/s]2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 19.00 / 28 (67.9%):  17%|████████████▎                                                            | 27/160 [00:01<00:02, 47.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 20.00 / 29 (69.0%):  18%|████████████▊                                                            | 28/160 [00:01<00:02, 47.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 21.00 / 30 (70.0%):  18%|█████████████▏                                                           | 29/160 [00:01<00:02, 47.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 21.00 / 31 (67.7%):  19%|█████████████▋                                                           | 30/160 [00:01<00:02, 47.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 21.00 / 32 (65.6%):  19%|██████████████▏                                                          | 31/160 [00:01<00:02, 47.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 22.00 / 33 (66.7%):  20%|██████████████▌                                                          | 32/160 [00:01<00:02, 47.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 34 (67.6%):  21%|███████████████                                                          | 33/160 [00:01<00:02, 47.44it/s]2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 35 (65.7%):  21%|███████████████▌                                                         | 34/160 [00:01<00:02, 47.44it/s]2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 23.00 / 36 (63.9%):  22%|███████████████▉                                                         | 35/160 [00:01<00:02, 47.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 36 (63.9%):  22%|████████████████▍                                                        | 36/160 [00:01<00:03, 36.90it/s]2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 37 (64.9%):  22%|████████████████▍                                                        | 36/160 [00:01<00:03, 36.90it/s]2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 25.00 / 38 (65.8%):  23%|████████████████▉                                                        | 37/160 [00:01<00:03, 36.90it/s]2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 26.00 / 39 (66.7%):  24%|█████████████████▎                                                       | 38/160 [00:01<00:03, 36.90it/s]2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 26.00 / 40 (65.0%):  24%|█████████████████▊                                                       | 39/160 [00:01<00:03, 36.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27.00 / 41 (65.9%):  25%|██████████████████▎                                                      | 40/160 [00:01<00:03, 36.90it/s]2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 27.00 / 42 (64.3%):  26%|██████████████████▋                                                      | 41/160 [00:01<00:03, 36.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 28.00 / 43 (65.1%):  26%|███████████████████▏                                                     | 42/160 [00:01<00:03, 36.90it/s]2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 29.00 / 44 (65.9%):  27%|███████████████████▌                                                     | 43/160 [00:01<00:03, 36.90it/s]2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 30.00 / 45 (66.7%):  28%|████████████████████                                                     | 44/160 [00:01<00:03, 36.90it/s]2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 30.00 / 46 (65.2%):  28%|████████████████████▌                                                    | 45/160 [00:01<00:03, 36.90it/s]2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 31.00 / 47 (66.0%):  29%|████████████████████▉                                                    | 46/160 [00:01<00:03, 36.90it/s]2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 31.00 / 47 (66.0%):  29%|█████████████████████▍                                                   | 47/160 [00:01<00:02, 41.29it/s]2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 31.00 / 48 (64.6%):  29%|█████████████████████▍                                                   | 47/160 [00:01<00:02, 41.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 31.00 / 49 (63.3%):  30%|█████████████████████▉                                                   | 48/160 [00:01<00:02, 41.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 32.00 / 50 (64.0%):  31%|██████████████████████▎                                                  | 49/160 [00:01<00:02, 41.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 33.00 / 51 (64.7%):  31%|██████████████████████▊                                                  | 50/160 [00:01<00:02, 41.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 34.00 / 52 (65.4%):  32%|███████████████████████▎                                                 | 51/160 [00:01<00:02, 41.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 35.00 / 53 (66.0%):  32%|███████████████████████▋                                                 | 52/160 [00:01<00:02, 41.29it/s]2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 36.00 / 54 (66.7%):  33%|████████████████████████▏                                                | 53/160 [00:01<00:02, 41.29it/s]2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 36.00 / 54 (66.7%):  34%|████████████████████████▋                                                | 54/160 [00:01<00:02, 37.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 37.00 / 55 (67.3%):  34%|████████████████████████▋                                                | 54/160 [00:01<00:02, 37.66it/s]2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 38.00 / 56 (67.9%):  34%|█████████████████████████                                                | 55/160 [00:01<00:02, 37.66it/s]2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 39.00 / 57 (68.4%):  35%|█████████████████████████▌                                               | 56/160 [00:01<00:02, 37.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 39.00 / 58 (67.2%):  36%|██████████████████████████                                               | 57/160 [00:01<00:02, 37.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 39.00 / 59 (66.1%):  36%|██████████████████████████▍                                              | 58/160 [00:01<00:02, 37.66it/s]2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 40.00 / 60 (66.7%):  37%|██████████████████████████▉                                              | 59/160 [00:01<00:02, 37.66it/s]2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 40.00 / 61 (65.6%):  38%|███████████████████████████▍                                             | 60/160 [00:01<00:02, 37.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 40.00 / 62 (64.5%):  38%|███████████████████████████▊                                             | 61/160 [00:01<00:02, 37.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 41.00 / 63 (65.1%):  39%|████████████████████████████▎                                            | 62/160 [00:01<00:02, 37.66it/s]2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 41.00 / 64 (64.1%):  39%|████████████████████████████▋                                            | 63/160 [00:01<00:02, 37.66it/s]2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 42.00 / 65 (64.6%):  40%|█████████████████████████████▏                                           | 64/160 [00:01<00:02, 37.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 43.00 / 66 (65.2%):  41%|█████████████████████████████▋                                           | 65/160 [00:01<00:02, 37.66it/s]2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 43.00 / 67 (64.2%):  41%|██████████████████████████████                                           | 66/160 [00:01<00:02, 37.66it/s]2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 43.00 / 68 (63.2%):  42%|██████████████████████████████▌                                          | 67/160 [00:01<00:02, 37.66it/s]2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 44.00 / 69 (63.8%):  42%|███████████████████████████████                                          | 68/160 [00:01<00:02, 37.66it/s]2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 44.00 / 70 (62.9%):  43%|███████████████████████████████▍                                         | 69/160 [00:01<00:02, 37.66it/s]2025-08-18 21:35:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 44.00 / 70 (62.9%):  44%|███████████████████████████████▉                                         | 70/160 [00:01<00:01, 56.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 45.00 / 71 (63.4%):  44%|███████████████████████████████▉                                         | 70/160 [00:01<00:01, 56.70it/s]2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 45.00 / 72 (62.5%):  44%|████████████████████████████████▍                                        | 71/160 [00:01<00:01, 56.70it/s]2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 46.00 / 73 (63.0%):  45%|████████████████████████████████▊                                        | 72/160 [00:01<00:01, 56.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 47.00 / 74 (63.5%):  46%|█████████████████████████████████▎                                       | 73/160 [00:01<00:01, 56.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 48.00 / 75 (64.0%):  46%|█████████████████████████████████▊                                       | 74/160 [00:01<00:01, 56.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 49.00 / 76 (64.5%):  47%|██████████████████████████████████▏                                      | 75/160 [00:01<00:01, 56.70it/s]2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 50.00 / 77 (64.9%):  48%|██████████████████████████████████▋                                      | 76/160 [00:02<00:01, 56.70it/s]2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 51.00 / 78 (65.4%):  48%|███████████████████████████████████▏                                     | 77/160 [00:02<00:01, 56.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 52.00 / 79 (65.8%):  49%|███████████████████████████████████▌                                     | 78/160 [00:02<00:01, 56.70it/s]2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 52.00 / 79 (65.8%):  49%|████████████████████████████████████                                     | 79/160 [00:02<00:01, 41.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 53.00 / 80 (66.2%):  49%|████████████████████████████████████                                     | 79/160 [00:02<00:01, 41.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 54.00 / 81 (66.7%):  50%|████████████████████████████████████▌                                    | 80/160 [00:02<00:01, 41.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 55.00 / 82 (67.1%):  51%|████████████████████████████████████▉                                    | 81/160 [00:02<00:01, 41.45it/s]2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 56.00 / 83 (67.5%):  51%|█████████████████████████████████████▍                                   | 82/160 [00:02<00:01, 41.45it/s]2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 56.00 / 84 (66.7%):  52%|█████████████████████████████████████▊                                   | 83/160 [00:02<00:01, 41.45it/s]2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 57.00 / 85 (67.1%):  52%|██████████████████████████████████████▎                                  | 84/160 [00:02<00:01, 41.45it/s]2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 58.00 / 86 (67.4%):  53%|██████████████████████████████████████▊                                  | 85/160 [00:02<00:01, 41.45it/s]2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 59.00 / 87 (67.8%):  54%|███████████████████████████████████████▏                                 | 86/160 [00:02<00:01, 41.45it/s]2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 60.00 / 88 (68.2%):  54%|███████████████████████████████████████▋                                 | 87/160 [00:02<00:01, 41.45it/s]2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 60.00 / 89 (67.4%):  55%|████████████████████████████████████████▏                                | 88/160 [00:02<00:01, 41.45it/s]2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 61.00 / 90 (67.8%):  56%|████████████████████████████████████████▌                                | 89/160 [00:02<00:01, 41.45it/s]2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 62.00 / 91 (68.1%):  56%|█████████████████████████████████████████                                | 90/160 [00:02<00:01, 41.45it/s]2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 63.00 / 92 (68.5%):  57%|█████████████████████████████████████████▌                               | 91/160 [00:02<00:01, 41.45it/s]2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 63.00 / 92 (68.5%):  57%|█████████████████████████████████████████▉                               | 92/160 [00:02<00:01, 53.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 64.00 / 93 (68.8%):  57%|█████████████████████████████████████████▉                               | 92/160 [00:02<00:01, 53.31it/s]2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 65.00 / 94 (69.1%):  58%|██████████████████████████████████████████▍                              | 93/160 [00:02<00:01, 53.31it/s]2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 65.00 / 95 (68.4%):  59%|██████████████████████████████████████████▉                              | 94/160 [00:02<00:01, 53.31it/s]2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 66.00 / 96 (68.8%):  59%|███████████████████████████████████████████▎                             | 95/160 [00:02<00:01, 53.31it/s]2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 67.00 / 97 (69.1%):  60%|███████████████████████████████████████████▊                             | 96/160 [00:02<00:01, 53.31it/s]2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 68.00 / 98 (69.4%):  61%|████████████████████████████████████████████▎                            | 97/160 [00:02<00:01, 53.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 69.00 / 99 (69.7%):  61%|████████████████████████████████████████████▋                            | 98/160 [00:02<00:01, 53.31it/s]2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 69.00 / 100 (69.0%):  62%|████████████████████████████████████████████▌                           | 99/160 [00:02<00:01, 53.31it/s]2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 70.00 / 101 (69.3%):  62%|████████████████████████████████████████████▍                          | 100/160 [00:02<00:01, 53.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 70.00 / 101 (69.3%):  63%|████████████████████████████████████████████▊                          | 101/160 [00:02<00:01, 41.13it/s]2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 70.00 / 102 (68.6%):  63%|████████████████████████████████████████████▊                          | 101/160 [00:02<00:01, 41.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 71.00 / 103 (68.9%):  64%|█████████████████████████████████████████████▎                         | 102/160 [00:02<00:01, 41.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 72.00 / 104 (69.2%):  64%|█████████████████████████████████████████████▋                         | 103/160 [00:02<00:01, 41.13it/s]2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 73.00 / 105 (69.5%):  65%|██████████████████████████████████████████████▏                        | 104/160 [00:02<00:01, 41.13it/s]2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 74.00 / 106 (69.8%):  66%|██████████████████████████████████████████████▌                        | 105/160 [00:02<00:01, 41.13it/s]2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 74.00 / 107 (69.2%):  66%|███████████████████████████████████████████████                        | 106/160 [00:02<00:01, 41.13it/s]2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 75.00 / 108 (69.4%):  67%|███████████████████████████████████████████████▍                       | 107/160 [00:02<00:01, 41.13it/s]2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 76.00 / 109 (69.7%):  68%|███████████████████████████████████████████████▉                       | 108/160 [00:02<00:01, 41.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 77.00 / 110 (70.0%):  68%|████████████████████████████████████████████████▎                      | 109/160 [00:02<00:01, 41.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 78.00 / 111 (70.3%):  69%|████████████████████████████████████████████████▊                      | 110/160 [00:02<00:01, 41.13it/s]2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 79.00 / 112 (70.5%):  69%|█████████████████████████████████████████████████▎                     | 111/160 [00:02<00:01, 41.13it/s]2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 80.00 / 113 (70.8%):  70%|█████████████████████████████████████████████████▋                     | 112/160 [00:02<00:01, 41.13it/s]2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 81.00 / 114 (71.1%):  71%|██████████████████████████████████████████████████▏                    | 113/160 [00:02<00:01, 41.13it/s]2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 81.00 / 115 (70.4%):  71%|██████████████████████████████████████████████████▌                    | 114/160 [00:02<00:01, 41.13it/s]2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 81.00 / 116 (69.8%):  72%|███████████████████████████████████████████████████                    | 115/160 [00:02<00:01, 41.13it/s]2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 82.00 / 117 (70.1%):  72%|███████████████████████████████████████████████████▍                   | 116/160 [00:02<00:01, 41.13it/s]2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 82.00 / 117 (70.1%):  73%|███████████████████████████████████████████████████▉                   | 117/160 [00:02<00:00, 53.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 82.00 / 118 (69.5%):  73%|███████████████████████████████████████████████████▉                   | 117/160 [00:02<00:00, 53.57it/s]2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 83.00 / 119 (69.7%):  74%|████████████████████████████████████████████████████▎                  | 118/160 [00:02<00:00, 53.57it/s]2025-08-18 21:35:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 84.00 / 120 (70.0%):  74%|████████████████████████████████████████████████████▊                  | 119/160 [00:02<00:00, 53.57it/s]2025-08-18 21:35:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 85.00 / 121 (70.2%):  75%|█████████████████████████████████████████████████████▎                 | 120/160 [00:02<00:00, 53.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 86.00 / 122 (70.5%):  76%|█████████████████████████████████████████████████████▋                 | 121/160 [00:02<00:00, 53.57it/s]2025-08-18 21:35:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 87.00 / 123 (70.7%):  76%|██████████████████████████████████████████████████████▏                | 122/160 [00:02<00:00, 53.57it/s]2025-08-18 21:35:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-18 21:35:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 88.00 / 124 (71.0%):  77%|██████████████████████████████████████████████████████▌                | 123/160 [00:02<00:00, 53.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 89.00 / 125 (71.2%):  78%|███████████████████████████████████████████████████████                | 124/160 [00:02<00:00, 53.57it/s]2025-08-18 21:35:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 89.00 / 125 (71.2%):  78%|███████████████████████████████████████████████████████▍               | 125/160 [00:02<00:00, 43.38it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 89.00 / 126 (70.6%):  78%|███████████████████████████████████████████████████████▍               | 125/160 [00:02<00:00, 43.38it/s]2025-08-18 21:35:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 90.00 / 127 (70.9%):  79%|███████████████████████████████████████████████████████▉               | 126/160 [00:02<00:00, 43.38it/s]2025-08-18 21:35:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 90.00 / 128 (70.3%):  79%|████████████████████████████████████████████████████████▎              | 127/160 [00:02<00:00, 43.38it/s]2025-08-18 21:35:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 91.00 / 129 (70.5%):  80%|████████████████████████████████████████████████████████▊              | 128/160 [00:02<00:00, 43.38it/s]2025-08-18 21:35:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 92.00 / 130 (70.8%):  81%|█████████████████████████████████████████████████████████▏             | 129/160 [00:03<00:00, 43.38it/s]2025-08-18 21:35:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 93.00 / 131 (71.0%):  81%|█████████████████████████████████████████████████████████▋             | 130/160 [00:03<00:00, 43.38it/s]2025-08-18 21:35:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 94.00 / 132 (71.2%):  82%|██████████████████████████████████████████████████████████▏            | 131/160 [00:03<00:00, 43.38it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 95.00 / 133 (71.4%):  82%|██████████████████████████████████████████████████████████▌            | 132/160 [00:03<00:00, 43.38it/s]2025-08-18 21:35:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 96.00 / 134 (71.6%):  83%|███████████████████████████████████████████████████████████            | 133/160 [00:03<00:00, 43.38it/s]2025-08-18 21:35:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 96.00 / 135 (71.1%):  84%|███████████████████████████████████████████████████████████▍           | 134/160 [00:03<00:00, 43.38it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 97.00 / 136 (71.3%):  84%|███████████████████████████████████████████████████████████▉           | 135/160 [00:03<00:00, 43.38it/s]2025-08-18 21:35:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 97.00 / 136 (71.3%):  85%|████████████████████████████████████████████████████████████▎          | 136/160 [00:03<00:00, 52.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 98.00 / 137 (71.5%):  85%|████████████████████████████████████████████████████████████▎          | 136/160 [00:03<00:00, 52.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 99.00 / 138 (71.7%):  86%|████████████████████████████████████████████████████████████▊          | 137/160 [00:03<00:00, 52.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 100.00 / 139 (71.9%):  86%|████████████████████████████████████████████████████████████▍         | 138/160 [00:03<00:00, 52.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 100.00 / 140 (71.4%):  87%|████████████████████████████████████████████████████████████▊         | 139/160 [00:03<00:00, 52.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 101.00 / 141 (71.6%):  88%|█████████████████████████████████████████████████████████████▎        | 140/160 [00:03<00:00, 52.34it/s]2025-08-18 21:35:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 102.00 / 142 (71.8%):  88%|█████████████████████████████████████████████████████████████▋        | 141/160 [00:03<00:00, 52.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 103.00 / 143 (72.0%):  89%|██████████████████████████████████████████████████████████████▏       | 142/160 [00:03<00:00, 52.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 103.00 / 144 (71.5%):  90%|███████████████████████████████████████████████████████████████       | 144/160 [00:03<00:00, 46.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 104.00 / 145 (71.7%):  90%|███████████████████████████████████████████████████████████████       | 144/160 [00:03<00:00, 46.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 104.00 / 146 (71.2%):  91%|███████████████████████████████████████████████████████████████▍      | 145/160 [00:03<00:00, 46.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 105.00 / 147 (71.4%):  91%|███████████████████████████████████████████████████████████████▉      | 146/160 [00:03<00:00, 46.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 106.00 / 148 (71.6%):  92%|████████████████████████████████████████████████████████████████▎     | 147/160 [00:03<00:00, 46.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 107.00 / 149 (71.8%):  92%|████████████████████████████████████████████████████████████████▊     | 148/160 [00:03<00:00, 46.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 107.00 / 150 (71.3%):  93%|█████████████████████████████████████████████████████████████████▏    | 149/160 [00:03<00:00, 46.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 108.00 / 151 (71.5%):  94%|██████████████████████████████████████████████████████████████████    | 151/160 [00:03<00:00, 45.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 109.00 / 152 (71.7%):  94%|██████████████████████████████████████████████████████████████████    | 151/160 [00:03<00:00, 45.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 110.00 / 153 (71.9%):  95%|██████████████████████████████████████████████████████████████████▌   | 152/160 [00:03<00:00, 45.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 111.00 / 154 (72.1%):  96%|██████████████████████████████████████████████████████████████████▉   | 153/160 [00:03<00:00, 45.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 112.00 / 155 (72.3%):  96%|███████████████████████████████████████████████████████████████████▍  | 154/160 [00:03<00:00, 45.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 113.00 / 156 (72.4%):  97%|███████████████████████████████████████████████████████████████████▊  | 155/160 [00:03<00:00, 45.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 113.00 / 157 (72.0%):  98%|████████████████████████████████████████████████████████████████████▋ | 157/160 [00:03<00:00, 47.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 114.00 / 158 (72.2%):  98%|████████████████████████████████████████████████████████████████████▋ | 157/160 [00:03<00:00, 47.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 115.00 / 159 (72.3%):  99%|█████████████████████████████████████████████████████████████████████▏| 158/160 [00:03<00:00, 47.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 115.00 / 160 (71.9%): 100%|██████████████████████████████████████████████████████████████████████| 160/160 [00:03<00:00, 44.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/18 21:35:05 INFO dspy.evaluate.evaluate: Average Metric: 115 / 160 (71.9%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>example_satisfied</th>\n",
       "      <th>_id</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>pred_satisfied</th>\n",
       "      <th>match_judge_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Company: comcastcares Transcript so far: Customer: why can’t I wat...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_0</td>\n",
       "      <td>Agent apologizes and attempts to troubleshoot the issue by request...</td>\n",
       "      <td>True</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Company: AppleSupport Transcript so far: Customer: my phone just s...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_1</td>\n",
       "      <td>Agent offers a basic troubleshooting step and acknowledges the issue.</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Company: AskLyft Transcript so far: Customer: This guy hops into m...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_2</td>\n",
       "      <td>Agent acknowledges the issue and requests more information to help.</td>\n",
       "      <td>True</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Company: SpotifyCares Transcript so far: Customer: will spotify re...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_3</td>\n",
       "      <td>The agent politely acknowledges the request and promises to forwar...</td>\n",
       "      <td>True</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Company: VirginTrains Transcript so far: Customer: ...would then @...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_4</td>\n",
       "      <td>The agent's response is polite and helpful, offering assistance an...</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Company: comcastcares Transcript so far: Customer: Hey @comcastcar...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_155</td>\n",
       "      <td>The agent's response is inadequate; it doesn't address the core co...</td>\n",
       "      <td>False</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Company: O2 Transcript so far: Customer: why you closing Tu Go? Wo...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_156</td>\n",
       "      <td>The agent's response is polite but doesn't fully address the custo...</td>\n",
       "      <td>False</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Company: AirAsiaSupport Transcript so far: Customer: Dear @AirAsia...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_157</td>\n",
       "      <td>Agent politely requests necessary information to help.</td>\n",
       "      <td>True</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Company: TacoBellTeam Transcript so far: Customer: I just had a te...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_158</td>\n",
       "      <td>The agent apologizes, acknowledges the unacceptable behavior, and ...</td>\n",
       "      <td>True</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Company: comcastcares Transcript so far: Customer: Yo connection i...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_159</td>\n",
       "      <td>Agent is polite and offers a solution; however, more troubleshooti...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                transcript  \\\n",
       "0    Company: comcastcares Transcript so far: Customer: why can’t I wat...   \n",
       "1    Company: AppleSupport Transcript so far: Customer: my phone just s...   \n",
       "2    Company: AskLyft Transcript so far: Customer: This guy hops into m...   \n",
       "3    Company: SpotifyCares Transcript so far: Customer: will spotify re...   \n",
       "4    Company: VirginTrains Transcript so far: Customer: ...would then @...   \n",
       "..                                                                     ...   \n",
       "155  Company: comcastcares Transcript so far: Customer: Hey @comcastcar...   \n",
       "156  Company: O2 Transcript so far: Customer: why you closing Tu Go? Wo...   \n",
       "157  Company: AirAsiaSupport Transcript so far: Customer: Dear @AirAsia...   \n",
       "158  Company: TacoBellTeam Transcript so far: Customer: I just had a te...   \n",
       "159  Company: comcastcares Transcript so far: Customer: Yo connection i...   \n",
       "\n",
       "     example_satisfied          _id  \\\n",
       "0                 True    example_0   \n",
       "1                 True    example_1   \n",
       "2                 True    example_2   \n",
       "3                 True    example_3   \n",
       "4                False    example_4   \n",
       "..                 ...          ...   \n",
       "155              False  example_155   \n",
       "156              False  example_156   \n",
       "157               True  example_157   \n",
       "158               True  example_158   \n",
       "159               True  example_159   \n",
       "\n",
       "                                                                 reasoning  \\\n",
       "0    Agent apologizes and attempts to troubleshoot the issue by request...   \n",
       "1    Agent offers a basic troubleshooting step and acknowledges the issue.   \n",
       "2      Agent acknowledges the issue and requests more information to help.   \n",
       "3    The agent politely acknowledges the request and promises to forwar...   \n",
       "4    The agent's response is polite and helpful, offering assistance an...   \n",
       "..                                                                     ...   \n",
       "155  The agent's response is inadequate; it doesn't address the core co...   \n",
       "156  The agent's response is polite but doesn't fully address the custo...   \n",
       "157                 Agent politely requests necessary information to help.   \n",
       "158  The agent apologizes, acknowledges the unacceptable behavior, and ...   \n",
       "159  Agent is polite and offers a solution; however, more troubleshooti...   \n",
       "\n",
       "    pred_satisfied match_judge_metric  \n",
       "0             True             ✔️ [1]  \n",
       "1            False                     \n",
       "2             True             ✔️ [1]  \n",
       "3             True             ✔️ [1]  \n",
       "4             True                     \n",
       "..             ...                ...  \n",
       "155          False             ✔️ [1]  \n",
       "156          False             ✔️ [1]  \n",
       "157           True             ✔️ [1]  \n",
       "158           True             ✔️ [1]  \n",
       "159          False                     \n",
       "\n",
       "[160 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimized_score = evaluator(generate_judge_reasoning_optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21b813ff-2cff-440a-b3fd-04882123fbd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.88"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c64ab9c-df28-45bc-bc38-bd9dc87d628b",
   "metadata": {},
   "source": [
    "## Check against validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c5e0063-0dd7-4d99-bba5-615437dbad8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_valid = dspy.Evaluate(\n",
    "    metric=match_judge_metric,\n",
    "    devset=validation_set,\n",
    "    display_table=True,\n",
    "    display_progress=True,\n",
    "    num_threads=24,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f656449-3042-4ba5-b666-c1d0f16f0dde",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:35:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:35:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "  0%|                                                                                                                       | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m21:35:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-18 21:35:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 1 (100.0%):   0%|                                                                                    | 0/50 [00:00<?, ?it/s]2025-08-18 21:35:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 1.00 / 1 (100.0%):   2%|█▌                                                                          | 1/50 [00:00<00:20,  2.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 2 (100.0%):   2%|█▌                                                                          | 1/50 [00:00<00:20,  2.35it/s]2025-08-18 21:35:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 3 (66.7%):   4%|███                                                                          | 2/50 [00:00<00:20,  2.35it/s]2025-08-18 21:35:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 3.00 / 4 (75.0%):   6%|████▌                                                                        | 3/50 [00:00<00:20,  2.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 5 (80.0%):   8%|██████▏                                                                      | 4/50 [00:00<00:19,  2.35it/s]2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 6 (83.3%):  10%|███████▋                                                                     | 5/50 [00:00<00:19,  2.35it/s]2025-08-18 21:35:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 6.00 / 7 (85.7%):  12%|█████████▏                                                                   | 6/50 [00:00<00:18,  2.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 8 (87.5%):  14%|██████████▊                                                                  | 7/50 [00:00<00:18,  2.35it/s]2025-08-18 21:35:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 8 (87.5%):  16%|████████████▎                                                                | 8/50 [00:00<00:02, 19.13it/s]2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 9 (77.8%):  16%|████████████▎                                                                | 8/50 [00:00<00:02, 19.13it/s]2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 8.00 / 10 (80.0%):  18%|█████████████▋                                                              | 9/50 [00:00<00:02, 19.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 9.00 / 11 (81.8%):  20%|███████████████                                                            | 10/50 [00:00<00:02, 19.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 12 (83.3%):  22%|████████████████▎                                                         | 11/50 [00:00<00:02, 19.13it/s]2025-08-18 21:35:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 13 (84.6%):  24%|█████████████████▊                                                        | 12/50 [00:00<00:01, 19.13it/s]2025-08-18 21:35:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 14 (85.7%):  26%|███████████████████▏                                                      | 13/50 [00:00<00:01, 19.13it/s]2025-08-18 21:35:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 15 (86.7%):  28%|████████████████████▋                                                     | 14/50 [00:00<00:01, 19.13it/s]2025-08-18 21:35:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 16 (87.5%):  30%|██████████████████████▏                                                   | 15/50 [00:00<00:01, 19.13it/s]2025-08-18 21:35:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 17 (88.2%):  32%|███████████████████████▋                                                  | 16/50 [00:00<00:01, 19.13it/s]2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 15.00 / 18 (83.3%):  34%|█████████████████████████▏                                                | 17/50 [00:00<00:01, 19.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 19 (78.9%):  36%|██████████████████████████▋                                               | 18/50 [00:00<00:01, 19.13it/s]2025-08-18 21:35:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 20 (75.0%):  38%|████████████████████████████                                              | 19/50 [00:00<00:01, 19.13it/s]2025-08-18 21:35:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 21 (76.2%):  40%|█████████████████████████████▌                                            | 20/50 [00:00<00:01, 19.13it/s]2025-08-18 21:35:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 22 (77.3%):  42%|███████████████████████████████                                           | 21/50 [00:00<00:01, 19.13it/s]2025-08-18 21:35:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 23 (78.3%):  44%|████████████████████████████████▌                                         | 22/50 [00:00<00:01, 19.13it/s]2025-08-18 21:35:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 24 (79.2%):  46%|██████████████████████████████████                                        | 23/50 [00:00<00:01, 19.13it/s]2025-08-18 21:35:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 19.00 / 24 (79.2%):  48%|███████████████████████████████████▌                                      | 24/50 [00:00<00:00, 51.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 25 (80.0%):  48%|███████████████████████████████████▌                                      | 24/50 [00:00<00:00, 51.39it/s]2025-08-18 21:35:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 26 (76.9%):  50%|█████████████████████████████████████                                     | 25/50 [00:00<00:00, 51.39it/s]2025-08-18 21:35:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 21.00 / 27 (77.8%):  52%|██████████████████████████████████████▍                                   | 26/50 [00:00<00:00, 51.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 22.00 / 28 (78.6%):  54%|███████████████████████████████████████▉                                  | 27/50 [00:01<00:00, 51.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 23.00 / 29 (79.3%):  56%|█████████████████████████████████████████▍                                | 28/50 [00:01<00:00, 51.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 24.00 / 30 (80.0%):  58%|██████████████████████████████████████████▉                               | 29/50 [00:01<00:00, 51.39it/s]2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 25.00 / 31 (80.6%):  60%|████████████████████████████████████████████▍                             | 30/50 [00:01<00:00, 51.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 26.00 / 32 (81.2%):  62%|█████████████████████████████████████████████▉                            | 31/50 [00:01<00:00, 51.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 26.00 / 32 (81.2%):  64%|███████████████████████████████████████████████▎                          | 32/50 [00:01<00:00, 34.80it/s]2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 27.00 / 33 (81.8%):  64%|███████████████████████████████████████████████▎                          | 32/50 [00:01<00:00, 34.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27.00 / 34 (79.4%):  66%|████████████████████████████████████████████████▊                         | 33/50 [00:01<00:00, 34.80it/s]2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 28.00 / 35 (80.0%):  68%|██████████████████████████████████████████████████▎                       | 34/50 [00:01<00:00, 34.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 28.00 / 36 (77.8%):  70%|███████████████████████████████████████████████████▊                      | 35/50 [00:01<00:00, 34.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 29.00 / 37 (78.4%):  72%|█████████████████████████████████████████████████████▎                    | 36/50 [00:01<00:00, 34.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 29.00 / 38 (76.3%):  74%|██████████████████████████████████████████████████████▊                   | 37/50 [00:01<00:00, 34.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 30.00 / 39 (76.9%):  76%|████████████████████████████████████████████████████████▏                 | 38/50 [00:01<00:00, 34.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 31.00 / 40 (77.5%):  78%|█████████████████████████████████████████████████████████▋                | 39/50 [00:01<00:00, 34.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 32.00 / 41 (78.0%):  80%|███████████████████████████████████████████████████████████▏              | 40/50 [00:01<00:00, 34.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 33.00 / 42 (78.6%):  82%|████████████████████████████████████████████████████████████▋             | 41/50 [00:01<00:00, 34.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 34.00 / 43 (79.1%):  84%|██████████████████████████████████████████████████████████████▏           | 42/50 [00:01<00:00, 34.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 34.00 / 44 (77.3%):  86%|███████████████████████████████████████████████████████████████▋          | 43/50 [00:01<00:00, 34.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 35.00 / 45 (77.8%):  88%|█████████████████████████████████████████████████████████████████         | 44/50 [00:01<00:00, 34.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 36.00 / 46 (78.3%):  92%|████████████████████████████████████████████████████████████████████      | 46/50 [00:01<00:00, 50.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 37.00 / 47 (78.7%):  92%|████████████████████████████████████████████████████████████████████      | 46/50 [00:01<00:00, 50.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 37.00 / 48 (77.1%):  94%|█████████████████████████████████████████████████████████████████████▌    | 47/50 [00:01<00:00, 50.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 38.00 / 49 (77.6%):  96%|███████████████████████████████████████████████████████████████████████   | 48/50 [00:01<00:00, 50.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:35:19 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 21:35:19 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 38.00 / 50 (76.0%): 100%|██████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 35.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/18 21:35:19 INFO dspy.evaluate.evaluate: Average Metric: 38 / 50 (76.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>example_satisfied</th>\n",
       "      <th>_id</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>pred_satisfied</th>\n",
       "      <th>match_judge_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Company: AppleSupport Transcript so far: Customer: im trying to do...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_110</td>\n",
       "      <td>Agent is polite and asks clarifying questions to diagnose the prob...</td>\n",
       "      <td>True</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Company: hulu_support Transcript so far: Customer: why do you emai...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_111</td>\n",
       "      <td>The agent apologizes and offers a solution by escalating the issue...</td>\n",
       "      <td>True</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Company: Ask_Spectrum Transcript so far: Customer: why can’t I get...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_112</td>\n",
       "      <td>The agent apologizes and offers alternative contact methods.</td>\n",
       "      <td>True</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Company: UPSHelp Transcript so far: Customer: I found a package in...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_113</td>\n",
       "      <td>The response is adequate but lacks specific instructions or a phon...</td>\n",
       "      <td>False</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Company: AppleSupport Transcript so far: Customer: please fix your...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_114</td>\n",
       "      <td>Agent acknowledges the problem and offers a basic troubleshooting ...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Company: AmericanAir Transcript so far: Customer: I want to say a ...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_115</td>\n",
       "      <td>The agent expresses gratitude and acknowledges the positive experi...</td>\n",
       "      <td>True</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Company: XboxSupport Transcript so far: Customer: Hi @XboxSupport,...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_116</td>\n",
       "      <td>The agent is polite and provides clear instructions on how to rece...</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Company: Tesco Transcript so far: Customer: So I bought your ripe ...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_117</td>\n",
       "      <td>The response is polite, offers a clear solution, and apologizes fo...</td>\n",
       "      <td>True</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Company: hulu_support Transcript so far: Customer: Anyone screwed ...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_118</td>\n",
       "      <td>The agent is polite and asks clarifying questions to help the cust...</td>\n",
       "      <td>True</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Company: VirginTrains Transcript so far: Customer: what’s off peak...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_119</td>\n",
       "      <td>Agent provides a helpful answer and offers further assistance.</td>\n",
       "      <td>True</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Company: British_Airways Transcript so far: Customer: I am almost ...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_120</td>\n",
       "      <td>The response is polite but lacks specific instructions on how to c...</td>\n",
       "      <td>False</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Company: O2 Transcript so far: Customer: So.. Can't preorder today...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_121</td>\n",
       "      <td>The agent provided a clear and concise answer to the customer's qu...</td>\n",
       "      <td>True</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Company: AmazonHelp Transcript so far: Customer: How can @115821 s...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_122</td>\n",
       "      <td>Agent apologizes, offers a timeframe, and expresses appreciation f...</td>\n",
       "      <td>True</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Company: VMUcare Transcript so far: Customer: Random call supposed...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_123</td>\n",
       "      <td>Agent acknowledges customer concern and offers a safe solution.</td>\n",
       "      <td>True</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Company: ChipotleTweets Transcript so far: Customer: why didn’t cu...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_124</td>\n",
       "      <td>The response is polite but doesn't address the core issue of why c...</td>\n",
       "      <td>False</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Company: AmericanAir Transcript so far: Customer: Fuck @AmericanAi...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_125</td>\n",
       "      <td>The agent attempts to help but doesn't address the root cause of t...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Company: Ask_Spectrum Transcript so far: Customer: @20517 I just w...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_126</td>\n",
       "      <td>The agent's response is polite but lacks context and doesn't addre...</td>\n",
       "      <td>False</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Company: comcastcares Transcript so far: Customer: #WTF Another ou...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_127</td>\n",
       "      <td>Agent apologizes and offers help, but needs more information.</td>\n",
       "      <td>False</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Company: TacoBellTeam Transcript so far: Customer: Charged by @118...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_128</td>\n",
       "      <td>Agent shows empathy and offers a solution; requests necessary info...</td>\n",
       "      <td>True</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Company: Uber_Support Transcript so far: Customer: really shameful...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_129</td>\n",
       "      <td>The agent apologizes and offers help, but needs more information.</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Company: AppleSupport Transcript so far: Customer: Draining, Drain...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_130</td>\n",
       "      <td>The agent is polite but doesn't directly address the battery issue...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Company: British_Airways Transcript so far: Customer: guys, please...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_131</td>\n",
       "      <td>Agent apologizes, offers troubleshooting, but can't directly book....</td>\n",
       "      <td>False</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Company: AskPlayStation Transcript so far: Customer: Please answer...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_132</td>\n",
       "      <td>The agent accurately and concisely answers the customer's question.</td>\n",
       "      <td>True</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Company: AppleSupport Transcript so far: Customer: how can I cance...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_133</td>\n",
       "      <td>The response is adequate but lacks specific instructions.</td>\n",
       "      <td>False</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Company: AppleSupport Transcript so far: Customer: can you fix my ...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_134</td>\n",
       "      <td>Agent attempts troubleshooting, adapting to the customer's situation.</td>\n",
       "      <td>True</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Company: AmazonHelp Transcript so far: Customer: You have got to b...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_135</td>\n",
       "      <td>Agent apologizes, offers a solution, and acknowledges the customer...</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Company: ChipotleTweets Transcript so far: Customer: was excited t...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_136</td>\n",
       "      <td>The agent apologizes and requests more information to help resolve...</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Company: ATVIAssist Transcript so far: Customer: decide to finally...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_137</td>\n",
       "      <td>Agent apologizes, acknowledges the issue, and escalates it to the ...</td>\n",
       "      <td>True</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Company: AmericanAir Transcript so far: Customer: Remind me to NEV...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_138</td>\n",
       "      <td>Agent acknowledges customer's frustration, clarifies the baggage p...</td>\n",
       "      <td>True</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Company: Ask_Spectrum Transcript so far: Customer: Internet cut ou...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_139</td>\n",
       "      <td>Agent acknowledges the issue but doesn't offer a solution or show ...</td>\n",
       "      <td>False</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Company: idea_cares Transcript so far: Customer: @116331 @122869 i...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_140</td>\n",
       "      <td>The agent's responses are inconsistent and unhelpful, causing furt...</td>\n",
       "      <td>False</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Company: AmazonHelp Transcript so far: Customer: Was ist bei euch ...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_141</td>\n",
       "      <td>The agent acknowledges the problem and offers help in the customer...</td>\n",
       "      <td>True</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Company: marksandspencer Transcript so far: Customer: Disappointed...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_142</td>\n",
       "      <td>The agent apologizes, explains the policy, and offers further assi...</td>\n",
       "      <td>True</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Company: GWRHelp Transcript so far: Customer: I'm on two-thirds of...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_143</td>\n",
       "      <td>Agent is polite and requests more information to help.</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Company: AmericanAir Transcript so far: Customer: I fear we’ll get...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_144</td>\n",
       "      <td>The agent apologizes and offers to check the flight status, addres...</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Company: SouthwestAir Transcript so far: Customer: = so far ahead ...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_145</td>\n",
       "      <td>The agent expresses gratitude and seeks further detail to improve ...</td>\n",
       "      <td>True</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Company: Tesco Transcript so far: Customer: check this total weapo...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_146</td>\n",
       "      <td>The agent responded professionally and offered to address the cust...</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Company: AmazonHelp Transcript so far: Customer: Uhm...if I paid e...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_147</td>\n",
       "      <td>Agent is polite, apologetic, and requests information to help.</td>\n",
       "      <td>True</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Company: AskAmex Transcript so far: Customer: yo I need help with ...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_148</td>\n",
       "      <td>The agent's response to the gift card issue is unhelpful; they don...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Company: AppleSupport Transcript so far: Customer: STILL iPhone 7 ...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_149</td>\n",
       "      <td>Agent acknowledges the issue and attempts to troubleshoot.</td>\n",
       "      <td>True</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Company: AmazonHelp Transcript so far: Customer: Hi @115850 , why ...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_150</td>\n",
       "      <td>The agent is polite, acknowledges the limitation, and offers alter...</td>\n",
       "      <td>True</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Company: hulu_support Transcript so far: Customer: What should I d...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_151</td>\n",
       "      <td>The agent's response is polite but doesn't directly address the cu...</td>\n",
       "      <td>False</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Company: AppleSupport Transcript so far: Customer: why does my mus...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_152</td>\n",
       "      <td>The response is polite, acknowledges the problem, and offers basic...</td>\n",
       "      <td>True</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Company: AppleSupport Transcript so far: Customer: ,solves the pro...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_153</td>\n",
       "      <td>Agent expresses empathy and offers assistance, showing a willingne...</td>\n",
       "      <td>True</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Company: HPSupport Transcript so far: Customer: EXTREMELY BAD CUST...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_154</td>\n",
       "      <td>Agent is polite and offers a solution, but the initial response is...</td>\n",
       "      <td>False</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Company: comcastcares Transcript so far: Customer: Hey @comcastcar...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_155</td>\n",
       "      <td>The agent's response is inadequate; it doesn't address the core co...</td>\n",
       "      <td>False</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Company: O2 Transcript so far: Customer: why you closing Tu Go? Wo...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_156</td>\n",
       "      <td>The agent's response is polite but doesn't fully address the custo...</td>\n",
       "      <td>False</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Company: AirAsiaSupport Transcript so far: Customer: Dear @AirAsia...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_157</td>\n",
       "      <td>Agent politely requests necessary information to help.</td>\n",
       "      <td>True</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Company: TacoBellTeam Transcript so far: Customer: I just had a te...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_158</td>\n",
       "      <td>The agent apologizes, acknowledges the unacceptable behavior, and ...</td>\n",
       "      <td>True</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Company: comcastcares Transcript so far: Customer: Yo connection i...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_159</td>\n",
       "      <td>Agent is polite and offers a solution; however, more troubleshooti...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               transcript  \\\n",
       "0   Company: AppleSupport Transcript so far: Customer: im trying to do...   \n",
       "1   Company: hulu_support Transcript so far: Customer: why do you emai...   \n",
       "2   Company: Ask_Spectrum Transcript so far: Customer: why can’t I get...   \n",
       "3   Company: UPSHelp Transcript so far: Customer: I found a package in...   \n",
       "4   Company: AppleSupport Transcript so far: Customer: please fix your...   \n",
       "5   Company: AmericanAir Transcript so far: Customer: I want to say a ...   \n",
       "6   Company: XboxSupport Transcript so far: Customer: Hi @XboxSupport,...   \n",
       "7   Company: Tesco Transcript so far: Customer: So I bought your ripe ...   \n",
       "8   Company: hulu_support Transcript so far: Customer: Anyone screwed ...   \n",
       "9   Company: VirginTrains Transcript so far: Customer: what’s off peak...   \n",
       "10  Company: British_Airways Transcript so far: Customer: I am almost ...   \n",
       "11  Company: O2 Transcript so far: Customer: So.. Can't preorder today...   \n",
       "12  Company: AmazonHelp Transcript so far: Customer: How can @115821 s...   \n",
       "13  Company: VMUcare Transcript so far: Customer: Random call supposed...   \n",
       "14  Company: ChipotleTweets Transcript so far: Customer: why didn’t cu...   \n",
       "15  Company: AmericanAir Transcript so far: Customer: Fuck @AmericanAi...   \n",
       "16  Company: Ask_Spectrum Transcript so far: Customer: @20517 I just w...   \n",
       "17  Company: comcastcares Transcript so far: Customer: #WTF Another ou...   \n",
       "18  Company: TacoBellTeam Transcript so far: Customer: Charged by @118...   \n",
       "19  Company: Uber_Support Transcript so far: Customer: really shameful...   \n",
       "20  Company: AppleSupport Transcript so far: Customer: Draining, Drain...   \n",
       "21  Company: British_Airways Transcript so far: Customer: guys, please...   \n",
       "22  Company: AskPlayStation Transcript so far: Customer: Please answer...   \n",
       "23  Company: AppleSupport Transcript so far: Customer: how can I cance...   \n",
       "24  Company: AppleSupport Transcript so far: Customer: can you fix my ...   \n",
       "25  Company: AmazonHelp Transcript so far: Customer: You have got to b...   \n",
       "26  Company: ChipotleTweets Transcript so far: Customer: was excited t...   \n",
       "27  Company: ATVIAssist Transcript so far: Customer: decide to finally...   \n",
       "28  Company: AmericanAir Transcript so far: Customer: Remind me to NEV...   \n",
       "29  Company: Ask_Spectrum Transcript so far: Customer: Internet cut ou...   \n",
       "30  Company: idea_cares Transcript so far: Customer: @116331 @122869 i...   \n",
       "31  Company: AmazonHelp Transcript so far: Customer: Was ist bei euch ...   \n",
       "32  Company: marksandspencer Transcript so far: Customer: Disappointed...   \n",
       "33  Company: GWRHelp Transcript so far: Customer: I'm on two-thirds of...   \n",
       "34  Company: AmericanAir Transcript so far: Customer: I fear we’ll get...   \n",
       "35  Company: SouthwestAir Transcript so far: Customer: = so far ahead ...   \n",
       "36  Company: Tesco Transcript so far: Customer: check this total weapo...   \n",
       "37  Company: AmazonHelp Transcript so far: Customer: Uhm...if I paid e...   \n",
       "38  Company: AskAmex Transcript so far: Customer: yo I need help with ...   \n",
       "39  Company: AppleSupport Transcript so far: Customer: STILL iPhone 7 ...   \n",
       "40  Company: AmazonHelp Transcript so far: Customer: Hi @115850 , why ...   \n",
       "41  Company: hulu_support Transcript so far: Customer: What should I d...   \n",
       "42  Company: AppleSupport Transcript so far: Customer: why does my mus...   \n",
       "43  Company: AppleSupport Transcript so far: Customer: ,solves the pro...   \n",
       "44  Company: HPSupport Transcript so far: Customer: EXTREMELY BAD CUST...   \n",
       "45  Company: comcastcares Transcript so far: Customer: Hey @comcastcar...   \n",
       "46  Company: O2 Transcript so far: Customer: why you closing Tu Go? Wo...   \n",
       "47  Company: AirAsiaSupport Transcript so far: Customer: Dear @AirAsia...   \n",
       "48  Company: TacoBellTeam Transcript so far: Customer: I just had a te...   \n",
       "49  Company: comcastcares Transcript so far: Customer: Yo connection i...   \n",
       "\n",
       "    example_satisfied          _id  \\\n",
       "0                True  example_110   \n",
       "1                True  example_111   \n",
       "2                True  example_112   \n",
       "3               False  example_113   \n",
       "4                True  example_114   \n",
       "5                True  example_115   \n",
       "6               False  example_116   \n",
       "7                True  example_117   \n",
       "8                True  example_118   \n",
       "9                True  example_119   \n",
       "10              False  example_120   \n",
       "11               True  example_121   \n",
       "12               True  example_122   \n",
       "13               True  example_123   \n",
       "14              False  example_124   \n",
       "15               True  example_125   \n",
       "16              False  example_126   \n",
       "17              False  example_127   \n",
       "18               True  example_128   \n",
       "19               True  example_129   \n",
       "20               True  example_130   \n",
       "21              False  example_131   \n",
       "22               True  example_132   \n",
       "23              False  example_133   \n",
       "24               True  example_134   \n",
       "25              False  example_135   \n",
       "26              False  example_136   \n",
       "27               True  example_137   \n",
       "28               True  example_138   \n",
       "29              False  example_139   \n",
       "30              False  example_140   \n",
       "31               True  example_141   \n",
       "32               True  example_142   \n",
       "33              False  example_143   \n",
       "34              False  example_144   \n",
       "35               True  example_145   \n",
       "36              False  example_146   \n",
       "37               True  example_147   \n",
       "38               True  example_148   \n",
       "39               True  example_149   \n",
       "40               True  example_150   \n",
       "41              False  example_151   \n",
       "42               True  example_152   \n",
       "43               True  example_153   \n",
       "44              False  example_154   \n",
       "45              False  example_155   \n",
       "46              False  example_156   \n",
       "47               True  example_157   \n",
       "48               True  example_158   \n",
       "49               True  example_159   \n",
       "\n",
       "                                                                reasoning  \\\n",
       "0   Agent is polite and asks clarifying questions to diagnose the prob...   \n",
       "1   The agent apologizes and offers a solution by escalating the issue...   \n",
       "2            The agent apologizes and offers alternative contact methods.   \n",
       "3   The response is adequate but lacks specific instructions or a phon...   \n",
       "4   Agent acknowledges the problem and offers a basic troubleshooting ...   \n",
       "5   The agent expresses gratitude and acknowledges the positive experi...   \n",
       "6   The agent is polite and provides clear instructions on how to rece...   \n",
       "7   The response is polite, offers a clear solution, and apologizes fo...   \n",
       "8   The agent is polite and asks clarifying questions to help the cust...   \n",
       "9          Agent provides a helpful answer and offers further assistance.   \n",
       "10  The response is polite but lacks specific instructions on how to c...   \n",
       "11  The agent provided a clear and concise answer to the customer's qu...   \n",
       "12  Agent apologizes, offers a timeframe, and expresses appreciation f...   \n",
       "13        Agent acknowledges customer concern and offers a safe solution.   \n",
       "14  The response is polite but doesn't address the core issue of why c...   \n",
       "15  The agent attempts to help but doesn't address the root cause of t...   \n",
       "16  The agent's response is polite but lacks context and doesn't addre...   \n",
       "17          Agent apologizes and offers help, but needs more information.   \n",
       "18  Agent shows empathy and offers a solution; requests necessary info...   \n",
       "19     The agent apologizes and offers help, but needs more information.    \n",
       "20  The agent is polite but doesn't directly address the battery issue...   \n",
       "21  Agent apologizes, offers troubleshooting, but can't directly book....   \n",
       "22    The agent accurately and concisely answers the customer's question.   \n",
       "23             The response is adequate but lacks specific instructions.    \n",
       "24  Agent attempts troubleshooting, adapting to the customer's situation.   \n",
       "25  Agent apologizes, offers a solution, and acknowledges the customer...   \n",
       "26  The agent apologizes and requests more information to help resolve...   \n",
       "27  Agent apologizes, acknowledges the issue, and escalates it to the ...   \n",
       "28  Agent acknowledges customer's frustration, clarifies the baggage p...   \n",
       "29  Agent acknowledges the issue but doesn't offer a solution or show ...   \n",
       "30  The agent's responses are inconsistent and unhelpful, causing furt...   \n",
       "31  The agent acknowledges the problem and offers help in the customer...   \n",
       "32  The agent apologizes, explains the policy, and offers further assi...   \n",
       "33                 Agent is polite and requests more information to help.   \n",
       "34  The agent apologizes and offers to check the flight status, addres...   \n",
       "35  The agent expresses gratitude and seeks further detail to improve ...   \n",
       "36  The agent responded professionally and offered to address the cust...   \n",
       "37         Agent is polite, apologetic, and requests information to help.   \n",
       "38  The agent's response to the gift card issue is unhelpful; they don...   \n",
       "39             Agent acknowledges the issue and attempts to troubleshoot.   \n",
       "40  The agent is polite, acknowledges the limitation, and offers alter...   \n",
       "41  The agent's response is polite but doesn't directly address the cu...   \n",
       "42  The response is polite, acknowledges the problem, and offers basic...   \n",
       "43  Agent expresses empathy and offers assistance, showing a willingne...   \n",
       "44  Agent is polite and offers a solution, but the initial response is...   \n",
       "45  The agent's response is inadequate; it doesn't address the core co...   \n",
       "46  The agent's response is polite but doesn't fully address the custo...   \n",
       "47                 Agent politely requests necessary information to help.   \n",
       "48  The agent apologizes, acknowledges the unacceptable behavior, and ...   \n",
       "49  Agent is polite and offers a solution; however, more troubleshooti...   \n",
       "\n",
       "   pred_satisfied match_judge_metric  \n",
       "0            True             ✔️ [1]  \n",
       "1            True             ✔️ [1]  \n",
       "2            True             ✔️ [1]  \n",
       "3           False             ✔️ [1]  \n",
       "4           False                     \n",
       "5            True             ✔️ [1]  \n",
       "6            True                     \n",
       "7            True             ✔️ [1]  \n",
       "8            True             ✔️ [1]  \n",
       "9            True             ✔️ [1]  \n",
       "10          False             ✔️ [1]  \n",
       "11           True             ✔️ [1]  \n",
       "12           True             ✔️ [1]  \n",
       "13           True             ✔️ [1]  \n",
       "14          False             ✔️ [1]  \n",
       "15          False                     \n",
       "16          False             ✔️ [1]  \n",
       "17          False             ✔️ [1]  \n",
       "18           True             ✔️ [1]  \n",
       "19          False                     \n",
       "20          False                     \n",
       "21          False             ✔️ [1]  \n",
       "22           True             ✔️ [1]  \n",
       "23          False             ✔️ [1]  \n",
       "24           True             ✔️ [1]  \n",
       "25           True                     \n",
       "26           True                     \n",
       "27           True             ✔️ [1]  \n",
       "28           True             ✔️ [1]  \n",
       "29          False             ✔️ [1]  \n",
       "30          False             ✔️ [1]  \n",
       "31           True             ✔️ [1]  \n",
       "32           True             ✔️ [1]  \n",
       "33           True                     \n",
       "34           True                     \n",
       "35           True             ✔️ [1]  \n",
       "36           True                     \n",
       "37           True             ✔️ [1]  \n",
       "38          False                     \n",
       "39           True             ✔️ [1]  \n",
       "40           True             ✔️ [1]  \n",
       "41          False             ✔️ [1]  \n",
       "42           True             ✔️ [1]  \n",
       "43           True             ✔️ [1]  \n",
       "44          False             ✔️ [1]  \n",
       "45          False             ✔️ [1]  \n",
       "46          False             ✔️ [1]  \n",
       "47           True             ✔️ [1]  \n",
       "48           True             ✔️ [1]  \n",
       "49          False                     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimized_valid_score = evaluator_valid(generate_judge_reasoning_optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2fac1b31-0856-414e-a738-2f2990cabaa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_valid_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17b3d13-3fa0-4cd9-91bd-d0418eae6211",
   "metadata": {},
   "source": [
    "## Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d6bf633d-9e1b-4ba7-a38f-6ccf0c25b16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_judge_reasoning.save(\"dspy_modules/baseline_llm_judge\",save_program=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1e4747c-892e-40bf-9383-e952fb674050",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_judge_reasoning_optimized.save(\"dspy_modules/optimized_llm_judge\",save_program=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3a1237-6316-4016-a6e7-1af04c0c562a",
   "metadata": {},
   "source": [
    "## Use this to see the resulting system prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "131e2410-1c1a-467d-8a05-12c3595b5d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate_judge_reasoning_optimized.inspect_history(n=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
