{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9559ccd0-996b-491f-96a6-569e3e6005cd",
   "metadata": {},
   "source": [
    "## Optimization of judge using gold standard labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ada2a8d4-7501-42ec-91aa-79a7258016dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d85d9ce5-2fc0-4491-9f68-1df83ff7d1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rmartinshort/Documents/DS_projects/dspy_judge/judgemodel/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dspy_judge.llm_caller.utils import load_secrets\n",
    "from dspy_judge.data_loader.dataset_loader import CustomerSupportDatasetLoader\n",
    "from dspy_judge.processor.parallel_processor import ParallelProcessor\n",
    "from dspy_judge.prompts.dspy_signatures import SupportTranscriptJudge\n",
    "from dspy_judge.processor.utils import convert_dataset_to_dspy_examples, extract_llm_response_fields_dspy\n",
    "from dspy_judge.processor.parallel_processor import ParallelProcessor\n",
    "from dspy_judge.metrics import match_judge_metric\n",
    "from dspy_judge.plotting import plot_judge_results\n",
    "import numpy as np\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71ea396b-0268-49a8-8241-06636e3ea490",
   "metadata": {},
   "outputs": [],
   "source": [
    "secrets = load_secrets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0274486f-ebc5-4e1a-9051-20e370de4d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = CustomerSupportDatasetLoader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2577fc-8e6a-4599-a044-7ccb346c339a",
   "metadata": {},
   "source": [
    "## Set up judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9526922-17e4-45a9-a506-bef536f98693",
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_model = dspy.LM(\n",
    "    \"gemini/gemini-1.5-flash\",\n",
    "    api_key=secrets[\"GEMINI_API_KEY\"],\n",
    "    cache=False,\n",
    "    temperature=0\n",
    ")\n",
    "dspy.configure(lm=judge_model,track_usage=True,adapter=dspy.JSONAdapter())\n",
    "generate_judge_reasoning = dspy.ChainOfThought(SupportTranscriptJudge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b532f042-07ec-45cb-8b62-80119ad624e2",
   "metadata": {},
   "source": [
    "## Load the gold standard judge dataset (AKA SME labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "416d2082-8b0b-4129-a494-487a9e9c1be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:35:51 - dspy_judge.data_loader.dataset_loader - INFO - Local dataset loaded from datasets/gold_standard_judge_result. Size: 160\n"
     ]
    }
   ],
   "source": [
    "dspy_gold_standard_judge_results = data_loader.load_local_dataset(\"datasets/gold_standard_judge_result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4d4095b-4718-4a93-b58d-552f381450d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:35:53 - dspy_judge.processor.utils - INFO - Processed 160 training examples\n"
     ]
    }
   ],
   "source": [
    "judge_dataset_examples = convert_dataset_to_dspy_examples(\n",
    "    dspy_gold_standard_judge_results,\n",
    "    field_mapping = {\"transcript\":\"output_transcript\",\"satisfied\":\"satisfied\"},\n",
    "    input_field=\"transcript\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee52c402-3ef7-41af-a20f-5f76daa84d31",
   "metadata": {},
   "source": [
    "## Check that the metric works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "24668fac-9eb2-47d9-8bb4-aa7d85a41bf2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:44:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:44:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                   | 0/160 [00:00<?, ?it/s]2025-08-23 15:44:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:44:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:44:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:44:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:44:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 1.00 / 1 (100.0%):   0%|                                                                                                                | 0/160 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 1 (100.0%):   1%|▋                                                                                                       | 1/160 [00:00<01:10,  2.27it/s]2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 2 (50.0%):   1%|▋                                                                                                        | 1/160 [00:00<01:10,  2.27it/s]2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 3 (33.3%):   1%|█▎                                                                                                       | 2/160 [00:00<01:09,  2.27it/s]2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 2.00 / 4 (50.0%):   2%|█▉                                                                                                       | 3/160 [00:00<01:09,  2.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 3.00 / 5 (60.0%):   2%|██▋                                                                                                      | 4/160 [00:00<01:08,  2.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 3.00 / 6 (50.0%):   3%|███▎                                                                                                     | 5/160 [00:00<01:08,  2.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 7 (57.1%):   4%|███▉                                                                                                     | 6/160 [00:00<01:07,  2.27it/s]2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 8 (62.5%):   4%|████▌                                                                                                    | 7/160 [00:00<01:07,  2.27it/s]2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 9 (66.7%):   5%|█████▎                                                                                                   | 8/160 [00:00<01:07,  2.27it/s]2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 6.00 / 10 (60.0%):   6%|█████▊                                                                                                  | 9/160 [00:00<01:06,  2.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 11 (63.6%):   6%|██████▍                                                                                                | 10/160 [00:00<01:06,  2.27it/s]2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 12 (66.7%):   7%|███████                                                                                                | 11/160 [00:00<01:05,  2.27it/s]2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 8.00 / 13 (61.5%):   8%|███████▋                                                                                               | 12/160 [00:00<01:05,  2.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 14 (64.3%):   8%|████████▎                                                                                              | 13/160 [00:00<01:04,  2.27it/s]2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 15 (60.0%):   9%|█████████                                                                                              | 14/160 [00:00<01:04,  2.27it/s]2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 16 (62.5%):   9%|█████████▌                                                                                            | 15/160 [00:00<01:03,  2.27it/s]2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 17 (64.7%):  10%|██████████▏                                                                                           | 16/160 [00:00<01:03,  2.27it/s]2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 12.00 / 18 (66.7%):  11%|██████████▊                                                                                           | 17/160 [00:00<01:03,  2.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 19 (63.2%):  11%|███████████▍                                                                                          | 18/160 [00:00<01:02,  2.27it/s]2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 13.00 / 20 (65.0%):  12%|████████████                                                                                          | 19/160 [00:00<01:02,  2.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 13.00 / 21 (61.9%):  12%|████████████▊                                                                                         | 20/160 [00:00<01:01,  2.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 14.00 / 22 (63.6%):  13%|█████████████▍                                                                                        | 21/160 [00:00<01:01,  2.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 23 (65.2%):  14%|██████████████                                                                                        | 22/160 [00:00<01:00,  2.27it/s]2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 15.00 / 23 (65.2%):  14%|██████████████▋                                                                                       | 23/160 [00:00<00:02, 54.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 24 (66.7%):  14%|██████████████▋                                                                                       | 23/160 [00:00<00:02, 54.77it/s]2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 25 (68.0%):  15%|███████████████▎                                                                                      | 24/160 [00:00<00:02, 54.77it/s]2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 18.00 / 26 (69.2%):  16%|███████████████▉                                                                                      | 25/160 [00:00<00:02, 54.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 27 (70.4%):  16%|████████████████▌                                                                                     | 26/160 [00:00<00:02, 54.77it/s]2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 28 (71.4%):  17%|█████████████████▏                                                                                    | 27/160 [00:00<00:02, 54.77it/s]2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 29 (69.0%):  18%|█████████████████▊                                                                                    | 28/160 [00:00<00:02, 54.77it/s]2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 20.00 / 30 (66.7%):  18%|██████████████████▍                                                                                   | 29/160 [00:00<00:02, 54.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 31 (67.7%):  19%|███████████████████▏                                                                                  | 30/160 [00:00<00:02, 54.77it/s]2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 32 (68.8%):  19%|███████████████████▊                                                                                  | 31/160 [00:00<00:02, 54.77it/s]2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 33 (69.7%):  20%|████████████████████▍                                                                                 | 32/160 [00:00<00:02, 54.77it/s]2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 24.00 / 34 (70.6%):  21%|█████████████████████                                                                                 | 33/160 [00:00<00:02, 54.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.00 / 35 (71.4%):  21%|█████████████████████▋                                                                                | 34/160 [00:00<00:02, 54.77it/s]2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 26.00 / 36 (72.2%):  22%|██████████████████████▎                                                                               | 35/160 [00:00<00:02, 54.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 26.00 / 36 (72.2%):  22%|██████████████████████▉                                                                               | 36/160 [00:00<00:02, 41.51it/s]2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 26.00 / 37 (70.3%):  22%|██████████████████████▉                                                                               | 36/160 [00:00<00:02, 41.51it/s]2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27.00 / 38 (71.1%):  23%|███████████████████████▌                                                                              | 37/160 [00:00<00:02, 41.51it/s]2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 28.00 / 39 (71.8%):  24%|████████████████████████▏                                                                             | 38/160 [00:00<00:02, 41.51it/s]2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 29.00 / 40 (72.5%):  24%|████████████████████████▊                                                                             | 39/160 [00:00<00:02, 41.51it/s]2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 30.00 / 41 (73.2%):  25%|█████████████████████████▌                                                                            | 40/160 [00:00<00:02, 41.51it/s]2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 31.00 / 42 (73.8%):  26%|██████████████████████████▏                                                                           | 41/160 [00:00<00:02, 41.51it/s]2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 31.00 / 43 (72.1%):  26%|██████████████████████████▊                                                                           | 42/160 [00:00<00:02, 41.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 32.00 / 44 (72.7%):  27%|███████████████████████████▍                                                                          | 43/160 [00:00<00:02, 41.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 32.00 / 45 (71.1%):  28%|████████████████████████████                                                                          | 44/160 [00:00<00:02, 41.51it/s]2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 32.00 / 46 (69.6%):  28%|████████████████████████████▋                                                                         | 45/160 [00:00<00:02, 41.51it/s]2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 33.00 / 47 (70.2%):  29%|█████████████████████████████▎                                                                        | 46/160 [00:01<00:02, 41.51it/s]2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 33.00 / 48 (68.8%):  29%|█████████████████████████████▉                                                                        | 47/160 [00:01<00:02, 41.51it/s]2025-08-23 15:44:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 34.00 / 49 (69.4%):  30%|██████████████████████████████▌                                                                       | 48/160 [00:01<00:02, 41.51it/s]2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 34.00 / 49 (69.4%):  31%|███████████████████████████████▏                                                                      | 49/160 [00:01<00:02, 37.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 35.00 / 50 (70.0%):  31%|███████████████████████████████▏                                                                      | 49/160 [00:01<00:02, 37.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 36.00 / 51 (70.6%):  31%|███████████████████████████████▉                                                                      | 50/160 [00:01<00:02, 37.99it/s]2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 37.00 / 52 (71.2%):  32%|████████████████████████████████▌                                                                     | 51/160 [00:01<00:02, 37.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 37.00 / 53 (69.8%):  32%|█████████████████████████████████▏                                                                    | 52/160 [00:01<00:02, 37.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 38.00 / 54 (70.4%):  33%|█████████████████████████████████▊                                                                    | 53/160 [00:01<00:02, 37.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 39.00 / 55 (70.9%):  34%|██████████████████████████████████▍                                                                   | 54/160 [00:01<00:02, 37.99it/s]2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 39.00 / 56 (69.6%):  34%|███████████████████████████████████                                                                   | 55/160 [00:01<00:02, 37.99it/s]2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 40.00 / 57 (70.2%):  35%|███████████████████████████████████▋                                                                  | 56/160 [00:01<00:02, 37.99it/s]2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 40.00 / 58 (69.0%):  36%|████████████████████████████████████▎                                                                 | 57/160 [00:01<00:02, 37.99it/s]2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 40.00 / 59 (67.8%):  36%|████████████████████████████████████▉                                                                 | 58/160 [00:01<00:02, 37.99it/s]2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 40.00 / 60 (66.7%):  37%|█████████████████████████████████████▌                                                                | 59/160 [00:01<00:02, 37.99it/s]2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 40.00 / 60 (66.7%):  38%|██████████████████████████████████████▎                                                               | 60/160 [00:01<00:02, 48.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 40.00 / 61 (65.6%):  38%|██████████████████████████████████████▎                                                               | 60/160 [00:01<00:02, 48.08it/s]2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 41.00 / 62 (66.1%):  38%|██████████████████████████████████████▉                                                               | 61/160 [00:01<00:02, 48.08it/s]2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 42.00 / 63 (66.7%):  39%|███████████████████████████████████████▌                                                              | 62/160 [00:01<00:02, 48.08it/s]2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 43.00 / 64 (67.2%):  39%|████████████████████████████████████████▏                                                             | 63/160 [00:01<00:02, 48.08it/s]2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 44.00 / 65 (67.7%):  40%|████████████████████████████████████████▊                                                             | 64/160 [00:01<00:01, 48.08it/s]2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 45.00 / 66 (68.2%):  41%|█████████████████████████████████████████▍                                                            | 65/160 [00:01<00:01, 48.08it/s]2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 46.00 / 67 (68.7%):  41%|██████████████████████████████████████████                                                            | 66/160 [00:01<00:01, 48.08it/s]2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 47.00 / 68 (69.1%):  42%|██████████████████████████████████████████▋                                                           | 67/160 [00:01<00:01, 48.08it/s]2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 48.00 / 69 (69.6%):  42%|███████████████████████████████████████████▎                                                          | 68/160 [00:01<00:01, 48.08it/s]2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 48.00 / 70 (68.6%):  43%|███████████████████████████████████████████▉                                                          | 69/160 [00:01<00:01, 48.08it/s]2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 49.00 / 71 (69.0%):  44%|████████████████████████████████████████████▋                                                         | 70/160 [00:01<00:01, 48.08it/s]2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 50.00 / 72 (69.4%):  44%|█████████████████████████████████████████████▎                                                        | 71/160 [00:01<00:01, 48.08it/s]2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 50.00 / 73 (68.5%):  45%|█████████████████████████████████████████████▉                                                        | 72/160 [00:01<00:01, 48.08it/s]2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 50.00 / 73 (68.5%):  46%|██████████████████████████████████████████████▌                                                       | 73/160 [00:01<00:02, 43.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 50.00 / 74 (67.6%):  46%|██████████████████████████████████████████████▌                                                       | 73/160 [00:01<00:02, 43.22it/s]2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 51.00 / 75 (68.0%):  46%|███████████████████████████████████████████████▏                                                      | 74/160 [00:01<00:01, 43.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 52.00 / 76 (68.4%):  47%|███████████████████████████████████████████████▊                                                      | 75/160 [00:01<00:01, 43.22it/s]2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 53.00 / 77 (68.8%):  48%|████████████████████████████████████████████████▍                                                     | 76/160 [00:01<00:01, 43.22it/s]2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 54.00 / 78 (69.2%):  48%|█████████████████████████████████████████████████                                                     | 77/160 [00:01<00:01, 43.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 54.00 / 79 (68.4%):  49%|█████████████████████████████████████████████████▋                                                    | 78/160 [00:01<00:01, 43.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 54.00 / 80 (67.5%):  49%|██████████████████████████████████████████████████▎                                                   | 79/160 [00:01<00:01, 43.22it/s]2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 54.00 / 81 (66.7%):  50%|███████████████████████████████████████████████████                                                   | 80/160 [00:01<00:01, 43.22it/s]2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 54.00 / 81 (66.7%):  51%|███████████████████████████████████████████████████▋                                                  | 81/160 [00:01<00:01, 48.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 54.00 / 82 (65.9%):  51%|███████████████████████████████████████████████████▋                                                  | 81/160 [00:01<00:01, 48.34it/s]2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 55.00 / 83 (66.3%):  51%|████████████████████████████████████████████████████▎                                                 | 82/160 [00:01<00:01, 48.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 55.00 / 84 (65.5%):  52%|████████████████████████████████████████████████████▉                                                 | 83/160 [00:01<00:01, 48.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 56.00 / 85 (65.9%):  52%|█████████████████████████████████████████████████████▌                                                | 84/160 [00:01<00:01, 48.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 57.00 / 86 (66.3%):  53%|██████████████████████████████████████████████████████▏                                               | 85/160 [00:01<00:01, 48.34it/s]2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 58.00 / 87 (66.7%):  54%|██████████████████████████████████████████████████████▊                                               | 86/160 [00:01<00:01, 48.34it/s]2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 59.00 / 88 (67.0%):  54%|███████████████████████████████████████████████████████▍                                              | 87/160 [00:01<00:01, 48.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 59.00 / 89 (66.3%):  55%|████████████████████████████████████████████████████████                                              | 88/160 [00:01<00:01, 48.34it/s]2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 59.00 / 90 (65.6%):  56%|████████████████████████████████████████████████████████▋                                             | 89/160 [00:01<00:01, 48.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 59.00 / 91 (64.8%):  56%|█████████████████████████████████████████████████████████▍                                            | 90/160 [00:01<00:01, 48.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 60.00 / 92 (65.2%):  57%|██████████████████████████████████████████████████████████                                            | 91/160 [00:01<00:01, 48.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 60.00 / 93 (64.5%):  57%|██████████████████████████████████████████████████████████▋                                           | 92/160 [00:01<00:01, 48.34it/s]2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 61.00 / 94 (64.9%):  58%|███████████████████████████████████████████████████████████▎                                          | 93/160 [00:01<00:01, 48.34it/s]2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 62.00 / 95 (65.3%):  59%|███████████████████████████████████████████████████████████▉                                          | 94/160 [00:01<00:01, 48.34it/s]2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 63.00 / 96 (65.6%):  59%|████████████████████████████████████████████████████████████▌                                         | 95/160 [00:01<00:01, 48.34it/s]2025-08-23 15:44:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 64.00 / 97 (66.0%):  60%|█████████████████████████████████████████████████████████████▏                                        | 96/160 [00:02<00:01, 48.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 64.00 / 97 (66.0%):  61%|█████████████████████████████████████████████████████████████▊                                        | 97/160 [00:02<00:01, 49.40it/s]2025-08-23 15:44:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 64.00 / 98 (65.3%):  61%|█████████████████████████████████████████████████████████████▊                                        | 97/160 [00:02<00:01, 49.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 65.00 / 99 (65.7%):  61%|██████████████████████████████████████████████████████████████▍                                       | 98/160 [00:02<00:01, 49.40it/s]2025-08-23 15:44:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 66.00 / 100 (66.0%):  62%|██████████████████████████████████████████████████████████████▍                                      | 99/160 [00:02<00:01, 49.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 67.00 / 101 (66.3%):  62%|██████████████████████████████████████████████████████████████▌                                     | 100/160 [00:02<00:01, 49.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 67.00 / 102 (65.7%):  63%|███████████████████████████████████████████████████████████████▏                                    | 101/160 [00:02<00:01, 49.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 68.00 / 103 (66.0%):  64%|███████████████████████████████████████████████████████████████▋                                    | 102/160 [00:02<00:01, 49.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:44:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 69.00 / 104 (66.3%):  64%|████████████████████████████████████████████████████████████████▍                                   | 103/160 [00:02<00:01, 49.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 69.00 / 104 (66.3%):  65%|█████████████████████████████████████████████████████████████████                                   | 104/160 [00:02<00:01, 48.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 69.00 / 105 (65.7%):  65%|█████████████████████████████████████████████████████████████████                                   | 104/160 [00:02<00:01, 48.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 70.00 / 106 (66.0%):  66%|█████████████████████████████████████████████████████████████████▋                                  | 105/160 [00:02<00:01, 48.08it/s]2025-08-23 15:44:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 70.00 / 107 (65.4%):  66%|██████████████████████████████████████████████████████████████████▎                                 | 106/160 [00:02<00:01, 48.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 71.00 / 108 (65.7%):  67%|██████████████████████████████████████████████████████████████████▉                                 | 107/160 [00:02<00:01, 48.08it/s]2025-08-23 15:44:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 71.00 / 109 (65.1%):  68%|███████████████████████████████████████████████████████████████████▌                                | 108/160 [00:02<00:01, 48.08it/s]2025-08-23 15:44:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 72.00 / 110 (65.5%):  68%|████████████████████████████████████████████████████████████████████▏                               | 109/160 [00:02<00:01, 48.08it/s]2025-08-23 15:44:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 73.00 / 111 (65.8%):  69%|████████████████████████████████████████████████████████████████████▊                               | 110/160 [00:02<00:01, 48.08it/s]2025-08-23 15:44:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 74.00 / 112 (66.1%):  69%|█████████████████████████████████████████████████████████████████████▍                              | 111/160 [00:02<00:01, 48.08it/s]2025-08-23 15:44:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 74.00 / 113 (65.5%):  70%|██████████████████████████████████████████████████████████████████████                              | 112/160 [00:02<00:00, 48.08it/s]2025-08-23 15:44:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 75.00 / 114 (65.8%):  71%|██████████████████████████████████████████████████████████████████████▋                             | 113/160 [00:02<00:00, 48.08it/s]2025-08-23 15:44:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 75.00 / 115 (65.2%):  71%|███████████████████████████████████████████████████████████████████████▎                            | 114/160 [00:02<00:00, 48.08it/s]2025-08-23 15:44:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 75.00 / 116 (64.7%):  72%|███████████████████████████████████████████████████████████████████████▉                            | 115/160 [00:02<00:00, 48.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 76.00 / 117 (65.0%):  72%|████████████████████████████████████████████████████████████████████████▌                           | 116/160 [00:02<00:00, 48.08it/s]2025-08-23 15:44:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 77.00 / 118 (65.3%):  73%|█████████████████████████████████████████████████████████████████████████▏                          | 117/160 [00:02<00:00, 48.08it/s]2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 78.00 / 119 (65.5%):  74%|█████████████████████████████████████████████████████████████████████████▊                          | 118/160 [00:02<00:00, 48.08it/s]2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 78.00 / 120 (65.0%):  74%|██████████████████████████████████████████████████████████████████████████▍                         | 119/160 [00:02<00:00, 48.08it/s]2025-08-23 15:44:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 78.00 / 121 (64.5%):  75%|███████████████████████████████████████████████████████████████████████████                         | 120/160 [00:02<00:00, 48.08it/s]2025-08-23 15:44:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 78.00 / 121 (64.5%):  76%|███████████████████████████████████████████████████████████████████████████▋                        | 121/160 [00:02<00:00, 52.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 79.00 / 122 (64.8%):  76%|███████████████████████████████████████████████████████████████████████████▋                        | 121/160 [00:02<00:00, 52.26it/s]2025-08-23 15:44:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 80.00 / 123 (65.0%):  76%|████████████████████████████████████████████████████████████████████████████▎                       | 122/160 [00:02<00:00, 52.26it/s]2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 81.00 / 124 (65.3%):  77%|████████████████████████████████████████████████████████████████████████████▉                       | 123/160 [00:02<00:00, 52.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 81.00 / 125 (64.8%):  78%|█████████████████████████████████████████████████████████████████████████████▌                      | 124/160 [00:02<00:00, 52.26it/s]2025-08-23 15:44:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 82.00 / 126 (65.1%):  78%|██████████████████████████████████████████████████████████████████████████████▏                     | 125/160 [00:02<00:00, 52.26it/s]2025-08-23 15:44:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 83.00 / 127 (65.4%):  79%|██████████████████████████████████████████████████████████████████████████████▊                     | 126/160 [00:02<00:00, 52.26it/s]2025-08-23 15:44:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 83.00 / 127 (65.4%):  79%|███████████████████████████████████████████████████████████████████████████████▍                    | 127/160 [00:02<00:00, 44.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 84.00 / 128 (65.6%):  79%|███████████████████████████████████████████████████████████████████████████████▍                    | 127/160 [00:03<00:00, 44.91it/s]2025-08-23 15:44:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 84.00 / 129 (65.1%):  80%|████████████████████████████████████████████████████████████████████████████████                    | 128/160 [00:03<00:00, 44.91it/s]2025-08-23 15:44:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 85.00 / 130 (65.4%):  81%|████████████████████████████████████████████████████████████████████████████████▋                   | 129/160 [00:03<00:00, 44.91it/s]2025-08-23 15:44:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 86.00 / 131 (65.6%):  81%|█████████████████████████████████████████████████████████████████████████████████▎                  | 130/160 [00:03<00:00, 44.91it/s]2025-08-23 15:44:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 86.00 / 132 (65.2%):  82%|█████████████████████████████████████████████████████████████████████████████████▉                  | 131/160 [00:03<00:00, 44.91it/s]2025-08-23 15:44:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 86.00 / 132 (65.2%):  82%|██████████████████████████████████████████████████████████████████████████████████▌                 | 132/160 [00:03<00:00, 38.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 87.00 / 133 (65.4%):  82%|██████████████████████████████████████████████████████████████████████████████████▌                 | 132/160 [00:03<00:00, 38.96it/s]2025-08-23 15:44:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 88.00 / 134 (65.7%):  83%|███████████████████████████████████████████████████████████████████████████████████▏                | 133/160 [00:03<00:00, 38.96it/s]2025-08-23 15:44:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 89.00 / 135 (65.9%):  84%|███████████████████████████████████████████████████████████████████████████████████▊                | 134/160 [00:03<00:00, 38.96it/s]2025-08-23 15:44:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 90.00 / 136 (66.2%):  84%|████████████████████████████████████████████████████████████████████████████████████▍               | 135/160 [00:03<00:00, 38.96it/s]2025-08-23 15:44:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 90.00 / 137 (65.7%):  85%|█████████████████████████████████████████████████████████████████████████████████████               | 136/160 [00:03<00:00, 38.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 90.00 / 138 (65.2%):  86%|█████████████████████████████████████████████████████████████████████████████████████▋              | 137/160 [00:03<00:00, 38.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 91.00 / 139 (65.5%):  86%|██████████████████████████████████████████████████████████████████████████████████████▎             | 138/160 [00:03<00:00, 38.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 91.00 / 140 (65.0%):  87%|██████████████████████████████████████████████████████████████████████████████████████▉             | 139/160 [00:03<00:00, 38.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 92.00 / 141 (65.2%):  88%|███████████████████████████████████████████████████████████████████████████████████████▌            | 140/160 [00:03<00:00, 38.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 93.00 / 142 (65.5%):  88%|████████████████████████████████████████████████████████████████████████████████████████▏           | 141/160 [00:03<00:00, 38.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 94.00 / 143 (65.7%):  89%|████████████████████████████████████████████████████████████████████████████████████████▊           | 142/160 [00:03<00:00, 38.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 95.00 / 144 (66.0%):  89%|█████████████████████████████████████████████████████████████████████████████████████████▍          | 143/160 [00:03<00:00, 38.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 96.00 / 145 (66.2%):  90%|██████████████████████████████████████████████████████████████████████████████████████████          | 144/160 [00:03<00:00, 38.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 97.00 / 146 (66.4%):  91%|███████████████████████████████████████████████████████████████████████████████████████████▎        | 146/160 [00:03<00:00, 34.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 97.00 / 147 (66.0%):  91%|███████████████████████████████████████████████████████████████████████████████████████████▎        | 146/160 [00:03<00:00, 34.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 98.00 / 148 (66.2%):  92%|███████████████████████████████████████████████████████████████████████████████████████████▉        | 147/160 [00:03<00:00, 34.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 99.00 / 149 (66.4%):  92%|████████████████████████████████████████████████████████████████████████████████████████████▌       | 148/160 [00:03<00:00, 34.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 100.00 / 150 (66.7%):  93%|████████████████████████████████████████████████████████████████████████████████████████████▏      | 149/160 [00:03<00:00, 34.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 101.00 / 151 (66.9%):  94%|████████████████████████████████████████████████████████████████████████████████████████████▊      | 150/160 [00:03<00:00, 34.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 101.00 / 152 (66.4%):  94%|█████████████████████████████████████████████████████████████████████████████████████████████▍     | 151/160 [00:03<00:00, 34.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 101.00 / 153 (66.0%):  95%|██████████████████████████████████████████████████████████████████████████████████████████████     | 152/160 [00:03<00:00, 34.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 101.00 / 154 (65.6%):  96%|██████████████████████████████████████████████████████████████████████████████████████████████▋    | 153/160 [00:03<00:00, 34.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 101.00 / 155 (65.2%):  96%|███████████████████████████████████████████████████████████████████████████████████████████████▎   | 154/160 [00:03<00:00, 34.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 102.00 / 156 (65.4%):  97%|███████████████████████████████████████████████████████████████████████████████████████████████▉   | 155/160 [00:03<00:00, 34.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 102.00 / 157 (65.0%):  98%|████████████████████████████████████████████████████████████████████████████████████████████████▌  | 156/160 [00:03<00:00, 34.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 102.00 / 158 (64.6%):  98%|█████████████████████████████████████████████████████████████████████████████████████████████████▏ | 157/160 [00:03<00:00, 34.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 102.00 / 159 (64.2%):  99%|█████████████████████████████████████████████████████████████████████████████████████████████████▊ | 158/160 [00:03<00:00, 34.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:44:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 102.00 / 160 (63.8%): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 160/160 [00:03<00:00, 44.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/23 15:44:58 INFO dspy.evaluate.evaluate: Average Metric: 102 / 160 (63.8%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>example_satisfied</th>\n",
       "      <th>_id</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>pred_satisfied</th>\n",
       "      <th>match_judge_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: I need thi...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_0</td>\n",
       "      <td>Agent is polite and helpful, offering alternative solutions.</td>\n",
       "      <td>True</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: traveling ...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_1</td>\n",
       "      <td>Agent's response is polite but unhelpful; doesn't offer any soluti...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: Looks like...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_2</td>\n",
       "      <td>The response is polite and acknowledges the customer's concern, bu...</td>\n",
       "      <td>False</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: I am bring...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_3</td>\n",
       "      <td>The response is polite, helpful, and provides all necessary inform...</td>\n",
       "      <td>True</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: I printed ...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_4</td>\n",
       "      <td>Agent was polite and answered the question clearly and concisely.</td>\n",
       "      <td>True</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Company: American Airlines Conversation Transcript so far: Custome...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_155</td>\n",
       "      <td>The agent is polite and helpful, redirecting the customer appropri...</td>\n",
       "      <td>True</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: In email, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_156</td>\n",
       "      <td>Good response, polite and acknowledges the problem.</td>\n",
       "      <td>True</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: I am looki...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_157</td>\n",
       "      <td>The agent is polite and helpful, offering to find the cheapest tic...</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Company: Delta Air Lines Transcript so far: Customer: I fly from B...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_158</td>\n",
       "      <td>The response is polite and helpful, offering a solution and reassu...</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: What happe...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_159</td>\n",
       "      <td>The agent's response is unhelpful and doesn't address the customer...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                transcript  \\\n",
       "0    Company: American Airlines Transcript so far: Customer: I need thi...   \n",
       "1    Company: American Airlines Transcript so far: Customer: traveling ...   \n",
       "2    Company: American Airlines Transcript so far: Customer: Looks like...   \n",
       "3    Company: American Airlines Transcript so far: Customer: I am bring...   \n",
       "4    Company: American Airlines Transcript so far: Customer: I printed ...   \n",
       "..                                                                     ...   \n",
       "155  Company: American Airlines Conversation Transcript so far: Custome...   \n",
       "156  Company: American Airlines Transcript so far: Customer: In email, ...   \n",
       "157  Company: American Airlines Transcript so far: Customer: I am looki...   \n",
       "158  Company: Delta Air Lines Transcript so far: Customer: I fly from B...   \n",
       "159  Company: American Airlines Transcript so far: Customer: What happe...   \n",
       "\n",
       "    example_satisfied          _id  \\\n",
       "0                True    example_0   \n",
       "1                True    example_1   \n",
       "2               False    example_2   \n",
       "3                True    example_3   \n",
       "4                True    example_4   \n",
       "..                ...          ...   \n",
       "155              True  example_155   \n",
       "156              True  example_156   \n",
       "157             False  example_157   \n",
       "158             False  example_158   \n",
       "159              True  example_159   \n",
       "\n",
       "                                                                 reasoning  \\\n",
       "0             Agent is polite and helpful, offering alternative solutions.   \n",
       "1    Agent's response is polite but unhelpful; doesn't offer any soluti...   \n",
       "2    The response is polite and acknowledges the customer's concern, bu...   \n",
       "3    The response is polite, helpful, and provides all necessary inform...   \n",
       "4        Agent was polite and answered the question clearly and concisely.   \n",
       "..                                                                     ...   \n",
       "155  The agent is polite and helpful, redirecting the customer appropri...   \n",
       "156                    Good response, polite and acknowledges the problem.   \n",
       "157  The agent is polite and helpful, offering to find the cheapest tic...   \n",
       "158  The response is polite and helpful, offering a solution and reassu...   \n",
       "159  The agent's response is unhelpful and doesn't address the customer...   \n",
       "\n",
       "    pred_satisfied match_judge_metric  \n",
       "0             True             ✔️ [1]  \n",
       "1            False                     \n",
       "2            False             ✔️ [1]  \n",
       "3             True             ✔️ [1]  \n",
       "4             True             ✔️ [1]  \n",
       "..             ...                ...  \n",
       "155           True             ✔️ [1]  \n",
       "156           True             ✔️ [1]  \n",
       "157           True                     \n",
       "158           True                     \n",
       "159          False                     \n",
       "\n",
       "[160 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluator = dspy.Evaluate(\n",
    "    metric=match_judge_metric,\n",
    "    devset=judge_dataset_examples,\n",
    "    display_table=True,\n",
    "    display_progress=True,\n",
    "    num_threads=24,\n",
    ")\n",
    "original_score = evaluator(generate_judge_reasoning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ee0f2cb9-d115-4c27-b989-69551057bc9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.75"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b9575c-d4f5-4521-8ec8-a9b3540cfe48",
   "metadata": {},
   "source": [
    "## Check that we can get the same result using the parallel processor\n",
    "\n",
    "Why do we do this? We need to confirm that when we run the judge on the generator development dataset, we can reproduce the same behavior that we saw in judge development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e7e5148-fa0a-4103-b98d-52b5595cd02d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:02 - dspy_judge.processor.parallel_processor - INFO - Initialized ParallelProcessor with max_workers=4\n",
      "2025-08-23 15:38:02 - dspy_judge.processor.parallel_processor - INFO - Processing 160 examples with 4 workers using DSPy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing with DSPy:   0%|                                                                                                                             | 0/160 [00:00<?, ?it/s]\u001b[92m15:38:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:06 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:06 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:06 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:06 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:06 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:06 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:06 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Processing with DSPy:   1%|▋                                                                                                                    | 1/160 [00:03<09:23,  3.54s/it]\u001b[92m15:38:06 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:06 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:06 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:06 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:06 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:06 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:06 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:06 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:06 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:06 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:06 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:06 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:06 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:06 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:06 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:06 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:06 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Processing with DSPy:   3%|███▋                                                                                                                 | 5/160 [00:04<01:38,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:06 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:06 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:06 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:06 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:06 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:06 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:06 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:06 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:07 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:   6%|██████▌                                                                                                              | 9/160 [00:04<00:52,  2.87it/s]\u001b[92m15:38:07 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:07 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:07 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:07 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:07 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:07 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:07 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:07 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:07 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:07 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:07 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:07 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:07 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:07 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:07 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:07 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:   8%|█████████▍                                                                                                          | 13/160 [00:04<00:36,  4.06it/s]\u001b[92m15:38:07 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:07 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:07 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:07 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:07 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:07 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:07 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:07 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:07 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:07 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:07 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:07 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:07 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:07 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:07 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  11%|████████████▎                                                                                                       | 17/160 [00:05<00:27,  5.24it/s]\u001b[92m15:38:08 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:08 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:08 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:08 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:08 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:08 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:08 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:08 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  13%|███████████████▏                                                                                                    | 21/160 [00:05<00:22,  6.22it/s]\u001b[92m15:38:08 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:08 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:08 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:08 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:08 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:08 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  15%|█████████████████▍                                                                                                  | 24/160 [00:06<00:18,  7.37it/s]\u001b[92m15:38:08 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:08 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:09 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:09 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  16%|██████████████████▊                                                                                                 | 26/160 [00:06<00:17,  7.49it/s]\u001b[92m15:38:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:09 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:09 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:09 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:09 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:09 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  18%|████████████████████▎                                                                                               | 28/160 [00:06<00:17,  7.38it/s]\u001b[92m15:38:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:09 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  18%|█████████████████████                                                                                               | 29/160 [00:06<00:17,  7.42it/s]\u001b[92m15:38:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:09 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:09 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:09 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:09 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:09 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  19%|██████████████████████▍                                                                                             | 31/160 [00:06<00:14,  8.72it/s]\u001b[92m15:38:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:09 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:09 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:09 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  21%|███████████████████████▉                                                                                            | 33/160 [00:07<00:15,  8.32it/s]\u001b[92m15:38:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  21%|████████████████████████▋                                                                                           | 34/160 [00:07<00:15,  8.33it/s]\u001b[92m15:38:10 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:09 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:09 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:10 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:10 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:10 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:10 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  22%|██████████████████████████                                                                                          | 36/160 [00:07<00:16,  7.58it/s]\u001b[92m15:38:10 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  24%|███████████████████████████▌                                                                                        | 38/160 [00:07<00:13,  8.86it/s]\u001b[92m15:38:10 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:10 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:10 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:10 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:10 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:10 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  25%|█████████████████████████████                                                                                       | 40/160 [00:08<00:16,  7.24it/s]\u001b[92m15:38:10 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:10 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:10 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  26%|██████████████████████████████▍                                                                                     | 42/160 [00:08<00:13,  8.94it/s]\u001b[92m15:38:10 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:10 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:10 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:10 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:10 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:11 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:11 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:11 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:11 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Processing with DSPy:  28%|███████████████████████████████▉                                                                                    | 44/160 [00:08<00:18,  6.40it/s]\u001b[92m15:38:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:11 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:11 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:11 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:11 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:11 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:11 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  30%|██████████████████████████████████▊                                                                                 | 48/160 [00:09<00:14,  7.50it/s]\u001b[92m15:38:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:11 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:11 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:11 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:11 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:11 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:11 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:12 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:12 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:12 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:12 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:12 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:12 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:12 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  32%|█████████████████████████████████████▋                                                                              | 52/160 [00:09<00:15,  7.16it/s]\u001b[92m15:38:12 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:12 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:12 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:12 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:12 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:12 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:12 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:12 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:12 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:12 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:12 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:12 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:12 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Processing with DSPy:  35%|████████████████████████████████████████▌                                                                           | 56/160 [00:10<00:14,  7.37it/s]\u001b[92m15:38:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:12 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:12 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:12 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:12 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:13 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:13 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:13 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:13 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  38%|███████████████████████████████████████████▌                                                                        | 60/160 [00:10<00:13,  7.52it/s]\u001b[92m15:38:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:13 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:13 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:13 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:13 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:14 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:14 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:14 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:14 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  40%|██████████████████████████████████████████████▍                                                                     | 64/160 [00:11<00:12,  7.61it/s]\u001b[92m15:38:14 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:14 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:14 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:14 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:14 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:14 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:14 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:14 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:14 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:14 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:14 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:14 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:14 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:14 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:14 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  42%|█████████████████████████████████████████████████▎                                                                  | 68/160 [00:11<00:11,  8.15it/s]\u001b[92m15:38:14 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:14 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:14 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:14 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:14 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:14 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:14 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:14 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:14 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:14 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:14 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:14 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:14 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:14 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:14 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:14 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:14 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:14 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:14 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:14 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:14 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Processing with DSPy:  45%|████████████████████████████████████████████████████▏                                                               | 72/160 [00:12<00:10,  8.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:14 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:14 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:14 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:14 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:14 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:14 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:14 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:14 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:15 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:15 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:15 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:15 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:15 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:15 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:15 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Processing with DSPy:  48%|███████████████████████████████████████████████████████                                                             | 76/160 [00:12<00:11,  7.53it/s]\u001b[92m15:38:15 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:15 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:15 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:15 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:15 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:15 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:15 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:15 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:15 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:16 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:16 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  50%|██████████████████████████████████████████████████████████                                                          | 80/160 [00:13<00:10,  7.63it/s]\u001b[92m15:38:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:16 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:16 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:16 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:16 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:16 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:16 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:16 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:16 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  52%|████████████████████████████████████████████████████████████▉                                                       | 84/160 [00:13<00:09,  8.07it/s]\u001b[92m15:38:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:16 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:16 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:16 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:16 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:16 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:16 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:16 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  55%|███████████████████████████████████████████████████████████████▊                                                    | 88/160 [00:14<00:08,  8.51it/s]\u001b[92m15:38:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:16 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:16 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  56%|█████████████████████████████████████████████████████████████████▎                                                  | 90/160 [00:14<00:07,  9.47it/s]\u001b[92m15:38:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:16 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:16 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:16 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  57%|██████████████████████████████████████████████████████████████████▋                                                 | 92/160 [00:14<00:08,  8.10it/s]\u001b[92m15:38:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  60%|█████████████████████████████████████████████████████████████████████▌                                              | 96/160 [00:15<00:07,  8.58it/s]\u001b[92m15:38:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  62%|███████████████████████████████████████████████████████████████████████▊                                            | 99/160 [00:15<00:05, 10.26it/s]\u001b[92m15:38:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Processing with DSPy:  63%|████████████████████████████████████████████████████████████████████████▌                                          | 101/160 [00:15<00:07,  7.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  65%|██████████████████████████████████████████████████████████████████████████▊                                        | 104/160 [00:15<00:06,  8.56it/s]\u001b[92m15:38:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  66%|████████████████████████████████████████████████████████████████████████████▏                                      | 106/160 [00:16<00:05,  9.82it/s]\u001b[92m15:38:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:19 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:19 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:19 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  68%|█████████████████████████████████████████████████████████████████████████████▋                                     | 108/160 [00:16<00:06,  7.89it/s]\u001b[92m15:38:19 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:19 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:19 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:19 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:19 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:19 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:19 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:19 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:19 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:19 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  69%|███████████████████████████████████████████████████████████████████████████████▊                                   | 111/160 [00:16<00:04,  9.94it/s]\u001b[92m15:38:19 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:19 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:19 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:19 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:19 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:19 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  71%|█████████████████████████████████████████████████████████████████████████████████▏                                 | 113/160 [00:16<00:05,  9.14it/s]\u001b[92m15:38:19 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:19 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:19 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:19 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  72%|██████████████████████████████████████████████████████████████████████████████████▋                                | 115/160 [00:17<00:04,  9.99it/s]\u001b[92m15:38:19 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:19 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:19 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:19 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:19 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:19 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:19 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:19 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:19 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:20 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:20 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:20 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  73%|████████████████████████████████████████████████████████████████████████████████████                               | 117/160 [00:17<00:05,  8.57it/s]\u001b[92m15:38:20 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:20 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:20 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:20 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:20 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:20 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:20 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:20 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:20 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:20 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:20 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:20 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:20 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:20 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:20 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:20 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:20 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:20 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:20 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Processing with DSPy:  75%|██████████████████████████████████████████████████████████████████████████████████████▎                            | 120/160 [00:17<00:05,  7.13it/s]\u001b[92m15:38:20 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:20 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:20 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:20 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:20 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:20 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:20 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:20 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:20 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:20 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:21 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:21 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:21 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:21 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:21 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Processing with DSPy:  78%|█████████████████████████████████████████████████████████████████████████████████████████▏                         | 124/160 [00:18<00:04,  7.72it/s]\u001b[92m15:38:21 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:21 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:21 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:21 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:21 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:21 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:21 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:21 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:21 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:21 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:21 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:21 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  80%|████████████████████████████████████████████████████████████████████████████████████████████                       | 128/160 [00:18<00:03,  8.48it/s]\u001b[92m15:38:21 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:21 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:21 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:21 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:21 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Processing with DSPy:  81%|████████████████████████████████████████████████████████████████████████████████████████████▋                      | 129/160 [00:18<00:03,  8.61it/s]\u001b[92m15:38:21 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:21 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:21 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:21 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:21 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:21 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:21 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:21 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:21 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:21 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:21 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  82%|██████████████████████████████████████████████████████████████████████████████████████████████▉                    | 132/160 [00:19<00:03,  8.72it/s]\u001b[92m15:38:21 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:22 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:22 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  83%|███████████████████████████████████████████████████████████████████████████████████████████████▌                   | 133/160 [00:19<00:03,  8.67it/s]\u001b[92m15:38:22 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:21 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:21 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:22 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:22 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:22 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  85%|█████████████████████████████████████████████████████████████████████████████████████████████████▊                 | 136/160 [00:19<00:02,  8.86it/s]\u001b[92m15:38:22 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:22 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  86%|███████████████████████████████████████████████████████████████████████████████████████████████████▏               | 138/160 [00:19<00:02, 10.16it/s]\u001b[92m15:38:22 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:22 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:22 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:22 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:22 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:22 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  88%|████████████████████████████████████████████████████████████████████████████████████████████████████▋              | 140/160 [00:20<00:02,  8.77it/s]\u001b[92m15:38:22 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:22 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  89%|██████████████████████████████████████████████████████████████████████████████████████████████████████             | 142/160 [00:20<00:01,  9.93it/s]\u001b[92m15:38:22 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:22 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:22 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:22 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:23 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:23 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:23 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  90%|███████████████████████████████████████████████████████████████████████████████████████████████████████▌           | 144/160 [00:20<00:01,  8.57it/s]\u001b[92m15:38:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:23 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:23 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  91%|████████████████████████████████████████████████████████████████████████████████████████████████████████▉          | 146/160 [00:20<00:01,  9.26it/s]\u001b[92m15:38:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:23 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:23 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:23 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:23 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:23 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▍        | 148/160 [00:20<00:01,  8.60it/s]\u001b[92m15:38:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:23 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:23 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:23 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:23 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  94%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▊       | 150/160 [00:21<00:01,  9.17it/s]\u001b[92m15:38:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:24 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:23 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:23 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:24 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▎     | 152/160 [00:21<00:01,  7.91it/s]\u001b[92m15:38:24 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:24 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:24 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▍   | 155/160 [00:21<00:00, 10.19it/s]\u001b[92m15:38:24 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:24 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:24 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:24 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:24 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:24 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:38:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊  | 157/160 [00:21<00:00,  8.96it/s]\u001b[92m15:38:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:24 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:38:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:38:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy:  99%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎| 159/160 [00:22<00:00,  9.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:38:25 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "Processing with DSPy: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 160/160 [00:22<00:00,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:38:25 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dspy_judge_config = {\n",
    "  \"model_name\":\"gemini/gemini-1.5-flash\",\n",
    "  \"api_key\":secrets[\"GEMINI_API_KEY\"],\n",
    "  \"temperature\": 0\n",
    "}\n",
    "\n",
    "dspy_judge_processor = ParallelProcessor()\n",
    "\n",
    "dspy_judge_results = dspy_judge_processor.process_dataset_with_dspy(\n",
    "  dspy_gold_standard_judge_results.select_columns(\n",
    "    [\"conversation_id\",\"output_transcript\"]\n",
    "  ),\n",
    "  input_field=\"output_transcript\",\n",
    "  dspy_module=generate_judge_reasoning,\n",
    "  dspy_config=dspy_judge_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58f666b2-733d-4c36-967a-1d5ac0035d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 160/160 [00:00<00:00, 20541.43 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dspy_judge_results = dspy_judge_results.map(\n",
    "    extract_llm_response_fields_dspy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "18ab029b-7209-4f90-8517-2402fae62d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.625\n"
     ]
    }
   ],
   "source": [
    "# this results\n",
    "baseline_result = dspy_judge_results.to_pandas()[[\"conversation_id\",\"satisfied\"]].rename(\n",
    "    columns={\n",
    "        \"satisfied\":\"prediction\"\n",
    "    }\n",
    ")\n",
    "# gold standard result\n",
    "gold_standard_result = dspy_gold_standard_judge_results.to_pandas()[[\"conversation_id\",\"satisfied\"]].rename(\n",
    "    columns={\n",
    "        \"satisfied\":\"gold_standard\"\n",
    "    }\n",
    ")\n",
    "full_result = baseline_result.merge(\n",
    "    gold_standard_result,on=[\"conversation_id\"]\n",
    ")\n",
    "# full_result[\"prediction\"] = full_result[\"prediction\"].astype(bool).astype(int)\n",
    "# full_result[\"gold_standard\"] = full_result[\"gold_standard\"].astype(bool).astype(int)\n",
    "\n",
    "print(\n",
    "    np.mean(full_result[\"prediction\"] == full_result[\"gold_standard\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ecffb5-4099-42b3-acb5-b63af1242217",
   "metadata": {},
   "source": [
    "## Crude test train split for judge training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "93ef21db-067e-4591-b7f9-bb4a9544f948",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = judge_dataset_examples[:110]\n",
    "validation_set = judge_dataset_examples[110:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8582cdd3-5760-4d90-918a-70c57e2f3377",
   "metadata": {},
   "source": [
    "## Run the optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dae7cb33-ec87-4508-9c68-0e9eecddc2a6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/23 15:48:52 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "RUNNING WITH THE FOLLOWING MEDIUM AUTO RUN SETTINGS:\n",
      "num_trials: 18\n",
      "minibatch: False\n",
      "num_fewshot_candidates: 12\n",
      "num_instruct_candidates: 6\n",
      "valset size: 50\n",
      "\n",
      "2025/08/23 15:48:52 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n",
      "2025/08/23 15:48:52 INFO dspy.teleprompt.mipro_optimizer_v2: These will be used as few-shot example candidates for our program and for creating instructions.\n",
      "\n",
      "2025/08/23 15:48:52 INFO dspy.teleprompt.mipro_optimizer_v2: Bootstrapping N=12 sets of demonstrations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping set 1/12\n",
      "Bootstrapping set 2/12\n",
      "Bootstrapping set 3/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                   | 0/110 [00:00<?, ?it/s]\u001b[92m15:48:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:48:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:48:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:48:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▎                                                                                                                                         | 1/110 [00:00<00:58,  1.88it/s]\u001b[92m15:48:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:48:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:48:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:48:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██▌                                                                                                                                        | 2/110 [00:01<00:57,  1.88it/s]\u001b[92m15:48:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:48:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:48:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:48:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███▊                                                                                                                                       | 3/110 [00:01<00:54,  1.95it/s]\u001b[92m15:48:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:48:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:48:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:48:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█████                                                                                                                                      | 4/110 [00:02<00:52,  2.03it/s]\u001b[92m15:48:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:48:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:48:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:48:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██████▎                                                                                                                                    | 5/110 [00:02<00:54,  1.92it/s]\u001b[92m15:48:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:48:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:48:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:48:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███████▌                                                                                                                                   | 6/110 [00:03<00:53,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 6 examples for up to 1 rounds, amounting to 6 attempts.\n",
      "Bootstrapping set 4/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                   | 0/110 [00:00<?, ?it/s]\u001b[92m15:48:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:48:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:48:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:48:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▎                                                                                                                                         | 1/110 [00:00<00:53,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Bootstrapping set 5/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                   | 0/110 [00:00<?, ?it/s]\u001b[92m15:48:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:48:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:48:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:48:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▎                                                                                                                                         | 1/110 [00:00<01:17,  1.40it/s]\u001b[92m15:48:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:48:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:48:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:48:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██▌                                                                                                                                        | 2/110 [00:01<01:05,  1.66it/s]\u001b[92m15:48:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:48:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:48:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:48:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███▊                                                                                                                                       | 3/110 [00:01<01:00,  1.77it/s]\u001b[92m15:48:58 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:48:58 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:48:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:48:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█████                                                                                                                                      | 4/110 [00:02<00:58,  1.80it/s]\u001b[92m15:48:58 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:48:58 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:48:59 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:48:59 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██████▎                                                                                                                                    | 5/110 [00:02<00:58,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 5 examples for up to 1 rounds, amounting to 5 attempts.\n",
      "Bootstrapping set 6/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                   | 0/110 [00:00<?, ?it/s]\u001b[92m15:48:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:48:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:48:59 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:48:59 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▎                                                                                                                                         | 1/110 [00:00<00:51,  2.12it/s]\u001b[92m15:48:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:48:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██▌                                                                                                                                        | 2/110 [00:00<00:50,  2.13it/s]\u001b[92m15:49:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███▊                                                                                                                                       | 3/110 [00:01<00:50,  2.12it/s]\u001b[92m15:49:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█████                                                                                                                                      | 4/110 [00:01<00:49,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 4 examples for up to 1 rounds, amounting to 4 attempts.\n",
      "Bootstrapping set 7/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                   | 0/110 [00:00<?, ?it/s]\u001b[92m15:49:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▎                                                                                                                                         | 1/110 [00:00<00:59,  1.82it/s]\u001b[92m15:49:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██▌                                                                                                                                        | 2/110 [00:01<00:54,  1.98it/s]\u001b[92m15:49:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███▊                                                                                                                                       | 3/110 [00:01<00:52,  2.03it/s]\u001b[92m15:49:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█████                                                                                                                                      | 4/110 [00:02<00:53,  1.98it/s]\u001b[92m15:49:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██████▎                                                                                                                                    | 5/110 [00:02<00:51,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 5 examples for up to 1 rounds, amounting to 5 attempts.\n",
      "Bootstrapping set 8/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                   | 0/110 [00:00<?, ?it/s]\u001b[92m15:49:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▎                                                                                                                                         | 1/110 [00:00<00:58,  1.85it/s]\u001b[92m15:49:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██▌                                                                                                                                        | 2/110 [00:00<00:51,  2.11it/s]\u001b[92m15:49:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███▊                                                                                                                                       | 3/110 [00:01<00:56,  1.89it/s]\u001b[92m15:49:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█████                                                                                                                                      | 4/110 [00:01<00:51,  2.04it/s]\u001b[92m15:49:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██████▎                                                                                                                                    | 5/110 [00:02<00:51,  2.05it/s]\u001b[92m15:49:06 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:06 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:06 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:06 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███████▌                                                                                                                                   | 6/110 [00:02<00:50,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 6 examples for up to 1 rounds, amounting to 6 attempts.\n",
      "Bootstrapping set 9/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                   | 0/110 [00:00<?, ?it/s]\u001b[92m15:49:06 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:06 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:06 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:06 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▎                                                                                                                                         | 1/110 [00:00<00:51,  2.13it/s]\u001b[92m15:49:06 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:06 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:07 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:07 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██▌                                                                                                                                        | 2/110 [00:00<00:51,  2.09it/s]\u001b[92m15:49:07 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:07 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:07 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:07 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███▊                                                                                                                                       | 3/110 [00:01<00:51,  2.10it/s]\u001b[92m15:49:07 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:07 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█████                                                                                                                                      | 4/110 [00:01<00:49,  2.13it/s]\u001b[92m15:49:08 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:08 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:09 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:09 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██████▎                                                                                                                                    | 5/110 [00:02<01:00,  1.72it/s]\u001b[92m15:49:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:09 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:09 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███████▌                                                                                                                                   | 6/110 [00:03<00:58,  1.79it/s]\u001b[92m15:49:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████████▊                                                                                                                                  | 7/110 [00:03<00:59,  1.73it/s]\u001b[92m15:49:10 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:10 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████████                                                                                                                                 | 8/110 [00:04<00:54,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 8 examples for up to 1 rounds, amounting to 8 attempts.\n",
      "Bootstrapping set 10/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                   | 0/110 [00:00<?, ?it/s]\u001b[92m15:49:10 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:10 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:11 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:11 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▎                                                                                                                                         | 1/110 [00:00<00:55,  1.98it/s]\u001b[92m15:49:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:11 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:11 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██▌                                                                                                                                        | 2/110 [00:01<00:55,  1.96it/s]\u001b[92m15:49:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:12 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:12 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███▊                                                                                                                                       | 3/110 [00:01<00:54,  1.96it/s]\u001b[92m15:49:12 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:12 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:12 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:12 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█████                                                                                                                                      | 4/110 [00:02<00:54,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 4 examples for up to 1 rounds, amounting to 4 attempts.\n",
      "Bootstrapping set 11/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                   | 0/110 [00:00<?, ?it/s]\u001b[92m15:49:12 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:12 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:13 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:13 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▎                                                                                                                                         | 1/110 [00:00<00:54,  1.99it/s]\u001b[92m15:49:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:13 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:13 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██▌                                                                                                                                        | 2/110 [00:01<00:54,  1.97it/s]\u001b[92m15:49:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:14 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:14 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███▊                                                                                                                                       | 3/110 [00:01<00:54,  1.96it/s]\u001b[92m15:49:14 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:14 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:14 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:14 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█████                                                                                                                                      | 4/110 [00:01<00:52,  2.02it/s]\u001b[92m15:49:14 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:14 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:15 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:15 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██████▎                                                                                                                                    | 5/110 [00:02<00:53,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 5 examples for up to 1 rounds, amounting to 5 attempts.\n",
      "Bootstrapping set 12/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                   | 0/110 [00:00<?, ?it/s]\u001b[92m15:49:15 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:15 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:15 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:15 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▎                                                                                                                                         | 1/110 [00:00<00:52,  2.06it/s]\u001b[92m15:49:15 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:15 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:16 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:16 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██▌                                                                                                                                        | 2/110 [00:01<00:54,  1.98it/s]\u001b[92m15:49:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:16 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:16 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███▊                                                                                                                                       | 3/110 [00:01<00:53,  2.01it/s]\u001b[92m15:49:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█████                                                                                                                                      | 4/110 [00:02<00:54,  1.95it/s]\n",
      "2025/08/23 15:49:17 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 2: PROPOSE INSTRUCTION CANDIDATES <==\n",
      "2025/08/23 15:49:17 INFO dspy.teleprompt.mipro_optimizer_v2: We will use the few-shot examples from the previous step, a generated dataset summary, a summary of the program code, and a randomly selected prompting tip to propose instructions.\n",
      "\u001b[92m15:49:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 4 examples for up to 1 rounds, amounting to 4 attempts.\n",
      "2025-08-23 15:49:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:20 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:20 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:20 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:20 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:22 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:22 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:22 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:22 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:22 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:22 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:23 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:23 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:23 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:23 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:24 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:24 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/23 15:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "Proposing N=6 instructions...\n",
      "\n",
      "\u001b[92m15:49:24 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:24 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:25 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:25 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:26 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:26 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:26 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:26 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:29 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:29 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:29 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:29 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:30 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:30 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:30 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:30 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:34 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:34 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:35 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:35 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:39 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:39 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:39 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:39 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:40 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:40 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:40 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:40 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:41 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:41 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:41 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:41 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:42 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:42 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:42 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:42 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:43 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:43 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:43 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:43 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:44 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:44 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:44 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:44 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:45 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:45 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:45 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:45 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:46 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:46 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/23 15:49:46 INFO dspy.teleprompt.mipro_optimizer_v2: Proposed Instructions for Predictor 0:\n",
      "\n",
      "2025/08/23 15:49:46 INFO dspy.teleprompt.mipro_optimizer_v2: 0: You are a very experienced customer service agent who has worked in multiple industries and understands how to address\n",
      "a very large range of issues. Your task is to help train more junior customer service agents by looking at how they responded \n",
      "to real queries and judging whether or not the interaction was successful. \n",
      "A successful interaction is somewhat subjective and you will lean on your expertise when making the judgment. In general, the\n",
      "responses from the agent being judged should:\n",
      "1. Provide a solid answer to the question if one is asked. If the agent doesn't know the answer, or there is no clear answer, that's OK, \n",
      "but the agent should clearly explain that they don't know and offer suggestions for where to find more information. \n",
      "2. The agent's response should always be polite and understanding, even if the customer is angry.\n",
      "3. Sometimes customers make comments that can't really be acted upon. In these situations, the agent's response should be appropriate, expressing\n",
      "thanks for the feedback, apologizing for any failures, and being supportive of any issues.\n",
      "4. The responses should be concise. Complicated issues should be sufficiently explained without excessive verbosity.\n",
      "Put yourself in the customer's shoes when reading the agent's responses. How would they react to what they read? Would they have had a \n",
      "positive or negative experience? \n",
      "When reading, pay most attention to the agent's most recent response since this is the one that the customer will be reading right now.\n",
      "Use the other parts of the conversation as useful context. You'll also be told the company that the agent works for, which may help you\n",
      "understand the types of issues that they deal with.\n",
      "You must provide an indication of whether or not you are satisfied with the agent's response, and a short explanation for your\n",
      "reasoning. Your indication can only be True or False, and your explanation should be fewer than 20 words.\n",
      "\n",
      "2025/08/23 15:49:46 INFO dspy.teleprompt.mipro_optimizer_v2: 1: You are an expert in customer service, specializing in evaluating airline customer support interactions. Your task is to assess the quality of a customer service agent's response based on a provided transcript.  Consider the following criteria:\n",
      "\n",
      "* **Helpfulness:** Did the agent provide a clear and accurate answer to the customer's question or concern? If the answer is unknown, did the agent explain this and offer alternative resources?\n",
      "* **Politeness:** Was the agent's response polite and understanding, regardless of the customer's tone?\n",
      "* **Conciseness:** Was the response clear and concise, avoiding unnecessary verbosity?\n",
      "* **Effectiveness:** Did the agent effectively address the customer's needs and concerns?\n",
      "* **Professionalism:** Did the agent maintain a professional demeanor throughout the interaction?\n",
      "\n",
      "Based on your evaluation, provide:\n",
      "\n",
      "1. **Satisfied:** A boolean value (True/False) indicating whether the customer was likely satisfied with the agent's response.\n",
      "2. **Reasoning:** A concise explanation (under 20 words) justifying your satisfaction rating.  Focus on the most recent agent response, using prior conversation for context.\n",
      "\n",
      "**Input Format:**\n",
      "\n",
      "* **Company:** The name of the airline company.\n",
      "* **Transcript:** The complete conversation transcript between the customer and the agent.\n",
      "\n",
      "**Example:**\n",
      "\n",
      "Company: American Airlines\n",
      "Transcript: Customer: My flight was delayed...\n",
      "Agent: I apologize for the inconvenience.  ...\n",
      "\n",
      "Satisfied: True\n",
      "Reasoning: Agent empathetic and provided helpful information.\n",
      "\n",
      "2025/08/23 15:49:46 INFO dspy.teleprompt.mipro_optimizer_v2: 2: You are a seasoned customer service expert, responsible for evaluating the performance of junior agents at American Airlines.  Your evaluation directly impacts their bonuses and potential promotions, so your judgment must be fair but firm. Analyze the following customer service transcripts.  Each transcript shows a conversation between a customer and a junior agent. Your job is to determine if the agent's response successfully addressed the customer's issue and created a positive experience. Consider these key factors:  Did the agent provide accurate, helpful information? Was their response polite, empathetic, and concise?  Did they handle unactionable comments appropriately? Your evaluation must be expressed as 'True' for a successful interaction or 'False' for an unsuccessful one, followed by a concise explanation (under 20 words) of your reasoning.  Remember, a single negative evaluation can significantly affect an agent's performance and future prospects. American Airlines reputation is at stake, so make sure your assessment is accurate and insightful.\n",
      "\n",
      "2025/08/23 15:49:46 INFO dspy.teleprompt.mipro_optimizer_v2: 3: You are an expert in customer service, specializing in airline interactions.  Your job is to evaluate the quality of customer service interactions based on provided transcripts.  Analyze each interaction, considering factors like politeness, accuracy, helpfulness, and efficiency.  Focus especially on the agent's final response to determine customer satisfaction.  Indicate 'True' if satisfied and 'False' otherwise, along with a concise explanation (under 20 words). Consider the context of the conversation, the airline company involved, and the customer's perspective.  The transcripts will include the company name and the full conversation history.\n",
      "\n",
      "2025/08/23 15:49:46 INFO dspy.teleprompt.mipro_optimizer_v2: 4: You are an expert customer service evaluator. Assess the following airline customer service interaction transcript.  Consider clarity, politeness, helpfulness, and conciseness.  Indicate whether the agent's response was satisfactory (True/False) and provide a concise (under 20 words) explanation.  Transcript: {transcript} Company: {company}\n",
      "\n",
      "2025/08/23 15:49:46 INFO dspy.teleprompt.mipro_optimizer_v2: 5: You are an expert in customer service, evaluating interactions between customers and agents. Analyze the following conversation transcript, considering the agent's response in context.  Assess whether the agent's response was satisfactory, focusing on whether it was helpful, accurate, polite, concise, and understanding.  Consider the customer's perspective.  Respond with \"Satisfied: True\" or \"Satisfied: False\", followed by a concise explanation (under 20 words) justifying your assessment.\n",
      "\n",
      "2025/08/23 15:49:46 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/08/23 15:49:46 INFO dspy.teleprompt.mipro_optimizer_v2: ==> STEP 3: FINDING OPTIMAL PROMPT PARAMETERS <==\n",
      "2025/08/23 15:49:46 INFO dspy.teleprompt.mipro_optimizer_v2: We will evaluate the program over a series of trials with different combinations of instructions and few-shot examples to find the optimal combination using Bayesian Optimization.\n",
      "\n",
      "2025/08/23 15:49:46 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 1 / 18 - Full Evaluation of Default Program ==\n",
      "\u001b[92m15:49:46 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:49:46 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:46 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:49:46 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "  0%|                                                                                                                                                    | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:46 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:46 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:46 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:46 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:46 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:46 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:46 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:46 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:46 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:46 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:46 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:46 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:47 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:47 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:47 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 1 (0.0%):   0%|                                                                                                                   | 0/50 [00:00<?, ?it/s]2025-08-23 15:49:47 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:47 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 1 (0.0%):   2%|██▏                                                                                                        | 1/50 [00:00<00:28,  1.71it/s]2025-08-23 15:49:47 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 0.00 / 2 (0.0%):   2%|██▏                                                                                                        | 1/50 [00:00<00:28,  1.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:47 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:49:47 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:47 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:47 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:47 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 1.00 / 3 (33.3%):   4%|████▏                                                                                                     | 2/50 [00:00<00:28,  1.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:47 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:47 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 2.00 / 4 (50.0%):   6%|██████▎                                                                                                   | 3/50 [00:00<00:27,  1.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:47 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:49:47 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:47 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:49:47 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 2.00 / 5 (40.0%):   8%|████████▍                                                                                                 | 4/50 [00:00<00:26,  1.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:47 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:47 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 3.00 / 6 (50.0%):  10%|██████████▌                                                                                               | 5/50 [00:00<00:26,  1.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:47 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:49:47 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:47 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:47 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:47 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 3.00 / 7 (42.9%):  12%|████████████▋                                                                                             | 6/50 [00:00<00:25,  1.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:47 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:47 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:49:47 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:49:47 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:47 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:47 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:47 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 8 (50.0%):  16%|████████████████▉                                                                                         | 8/50 [00:00<00:03, 12.88it/s]2025-08-23 15:49:47 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:47 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:47 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:47 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 9 (44.4%):  16%|████████████████▉                                                                                         | 8/50 [00:01<00:03, 12.88it/s]2025-08-23 15:49:47 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:47 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:47 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:47 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 10 (50.0%):  18%|██████████████████▉                                                                                      | 9/50 [00:01<00:03, 12.88it/s]2025-08-23 15:49:47 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:47 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:47 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:47 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 11 (45.5%):  20%|████████████████████▊                                                                                   | 10/50 [00:01<00:03, 12.88it/s]2025-08-23 15:49:47 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 5.00 / 11 (45.5%):  22%|██████████████████████▉                                                                                 | 11/50 [00:01<00:03, 11.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:47 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:47 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:47 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 12 (50.0%):  22%|██████████████████████▉                                                                                 | 11/50 [00:01<00:03, 11.21it/s]2025-08-23 15:49:47 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:47 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:47 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:47 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 13 (53.8%):  24%|████████████████████████▉                                                                               | 12/50 [00:01<00:03, 11.21it/s]2025-08-23 15:49:47 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:47 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:47 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:47 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 14 (57.1%):  26%|███████████████████████████                                                                             | 13/50 [00:01<00:03, 11.21it/s]2025-08-23 15:49:47 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:47 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:47 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:47 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 15 (53.3%):  28%|█████████████████████████████                                                                           | 14/50 [00:01<00:03, 11.21it/s]2025-08-23 15:49:47 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:47 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:47 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 9.00 / 16 (56.2%):  30%|███████████████████████████████▏                                                                        | 15/50 [00:01<00:03, 11.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:47 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 16 (56.2%):  32%|█████████████████████████████████▎                                                                      | 16/50 [00:01<00:02, 13.43it/s]2025-08-23 15:49:47 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 17 (58.8%):  32%|████████████████████████████████▉                                                                      | 16/50 [00:01<00:02, 13.43it/s]2025-08-23 15:49:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:49:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:49:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 10.00 / 18 (55.6%):  34%|███████████████████████████████████                                                                    | 17/50 [00:01<00:02, 13.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 18 (55.6%):  36%|█████████████████████████████████████                                                                  | 18/50 [00:01<00:02, 13.41it/s]2025-08-23 15:49:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 19 (57.9%):  36%|█████████████████████████████████████                                                                  | 18/50 [00:01<00:02, 13.41it/s]2025-08-23 15:49:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 20 (60.0%):  38%|███████████████████████████████████████▏                                                               | 19/50 [00:01<00:02, 13.41it/s]2025-08-23 15:49:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 21 (61.9%):  40%|█████████████████████████████████████████▏                                                             | 20/50 [00:01<00:02, 13.41it/s]2025-08-23 15:49:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 22 (63.6%):  42%|███████████████████████████████████████████▎                                                           | 21/50 [00:01<00:02, 13.41it/s]2025-08-23 15:49:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 23 (60.9%):  44%|█████████████████████████████████████████████▎                                                         | 22/50 [00:01<00:02, 13.41it/s]2025-08-23 15:49:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 24 (58.3%):  46%|███████████████████████████████████████████████▍                                                       | 23/50 [00:01<00:02, 13.41it/s]2025-08-23 15:49:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 14.00 / 24 (58.3%):  48%|█████████████████████████████████████████████████▍                                                     | 24/50 [00:01<00:01, 14.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 25 (60.0%):  48%|█████████████████████████████████████████████████▍                                                     | 24/50 [00:02<00:01, 14.67it/s]2025-08-23 15:49:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:49:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:49:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 15.00 / 26 (57.7%):  50%|███████████████████████████████████████████████████▌                                                   | 25/50 [00:02<00:01, 14.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 15.00 / 26 (57.7%):  52%|█████████████████████████████████████████████████████▌                                                 | 26/50 [00:02<00:01, 15.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 16.00 / 27 (59.3%):  52%|█████████████████████████████████████████████████████▌                                                 | 26/50 [00:02<00:01, 15.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 17.00 / 28 (60.7%):  54%|███████████████████████████████████████████████████████▌                                               | 27/50 [00:02<00:01, 15.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 17.00 / 29 (58.6%):  56%|█████████████████████████████████████████████████████████▋                                             | 28/50 [00:02<00:01, 15.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 30 (60.0%):  58%|███████████████████████████████████████████████████████████▋                                           | 29/50 [00:02<00:01, 15.00it/s]2025-08-23 15:49:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 31 (58.1%):  60%|█████████████████████████████████████████████████████████████▊                                         | 30/50 [00:02<00:01, 15.00it/s]2025-08-23 15:49:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 32 (59.4%):  62%|███████████████████████████████████████████████████████████████▊                                       | 31/50 [00:02<00:01, 15.00it/s]2025-08-23 15:49:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 19.00 / 32 (59.4%):  64%|█████████████████████████████████████████████████████████████████▉                                     | 32/50 [00:02<00:01, 15.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 20.00 / 33 (60.6%):  64%|█████████████████████████████████████████████████████████████████▉                                     | 32/50 [00:02<00:01, 15.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 21.00 / 34 (61.8%):  66%|███████████████████████████████████████████████████████████████████▉                                   | 33/50 [00:02<00:01, 15.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 35 (60.0%):  68%|██████████████████████████████████████████████████████████████████████                                 | 34/50 [00:02<00:01, 15.14it/s]2025-08-23 15:49:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 36 (61.1%):  70%|████████████████████████████████████████████████████████████████████████                               | 35/50 [00:02<00:00, 15.14it/s]2025-08-23 15:49:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 37 (59.5%):  72%|██████████████████████████████████████████████████████████████████████████▏                            | 36/50 [00:02<00:00, 15.14it/s]2025-08-23 15:49:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 38 (60.5%):  74%|████████████████████████████████████████████████████████████████████████████▏                          | 37/50 [00:02<00:00, 15.14it/s]2025-08-23 15:49:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 39 (61.5%):  76%|██████████████████████████████████████████████████████████████████████████████▎                        | 38/50 [00:02<00:00, 15.14it/s]2025-08-23 15:49:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 24.00 / 39 (61.5%):  78%|████████████████████████████████████████████████████████████████████████████████▎                      | 39/50 [00:02<00:00, 21.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:49:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 26.00 / 41 (63.4%):  80%|██████████████████████████████████████████████████████████████████████████████████▍                    | 40/50 [00:02<00:00, 21.27it/s]2025-08-23 15:49:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27.00 / 42 (64.3%):  82%|████████████████████████████████████████████████████████████████████████████████████▍                  | 41/50 [00:02<00:00, 21.27it/s]2025-08-23 15:49:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 27.00 / 42 (64.3%):  84%|██████████████████████████████████████████████████████████████████████████████████████▌                | 42/50 [00:02<00:00, 15.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 27.00 / 43 (62.8%):  84%|██████████████████████████████████████████████████████████████████████████████████████▌                | 42/50 [00:02<00:00, 15.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 28.00 / 44 (63.6%):  86%|████████████████████████████████████████████████████████████████████████████████████████▌              | 43/50 [00:02<00:00, 15.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 29.00 / 45 (64.4%):  88%|██████████████████████████████████████████████████████████████████████████████████████████▋            | 44/50 [00:02<00:00, 15.74it/s]2025-08-23 15:49:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 30.00 / 46 (65.2%):  90%|████████████████████████████████████████████████████████████████████████████████████████████▋          | 45/50 [00:02<00:00, 15.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 31.00 / 47 (66.0%):  92%|██████████████████████████████████████████████████████████████████████████████████████████████▊        | 46/50 [00:02<00:00, 15.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 31.00 / 48 (64.6%):  94%|████████████████████████████████████████████████████████████████████████████████████████████████▊      | 47/50 [00:03<00:00, 15.74it/s]2025-08-23 15:49:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 31.00 / 48 (64.6%):  96%|██████████████████████████████████████████████████████████████████████████████████████████████████▉    | 48/50 [00:03<00:00, 14.15it/s]2025-08-23 15:49:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 33.00 / 50 (66.0%): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 14.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/23 15:49:49 INFO dspy.evaluate.evaluate: Average Metric: 33 / 50 (66.0%)\n",
      "2025/08/23 15:49:49 INFO dspy.teleprompt.mipro_optimizer_v2: Default program score: 66.0\n",
      "\n",
      "/Users/rmartinshort/Documents/DS_projects/dspy_judge/judgemodel/lib/python3.12/site-packages/optuna/_experimental.py:32: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "2025/08/23 15:49:49 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 2 / 18 =====\n",
      "\u001b[92m15:49:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-08-23 15:49:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:49:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:49:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                    | 0/50 [00:00<?, ?it/s]2025-08-23 15:49:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:50 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:50 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:50 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 1 (0.0%):   0%|                                                                                                                   | 0/50 [00:00<?, ?it/s]2025-08-23 15:49:50 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 0.00 / 1 (0.0%):   2%|██▏                                                                                                        | 1/50 [00:00<00:27,  1.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:50 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:49:50 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:50 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 0.00 / 2 (0.0%):   2%|██▏                                                                                                        | 1/50 [00:00<00:27,  1.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:50 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:50 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:49:50 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 0.00 / 3 (0.0%):   4%|████▎                                                                                                      | 2/50 [00:00<00:26,  1.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:50 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:50 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:50 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:50 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 0.00 / 4 (0.0%):   6%|██████▍                                                                                                    | 3/50 [00:00<00:26,  1.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:50 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:50 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:50 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:50 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 1.00 / 5 (20.0%):   8%|████████▍                                                                                                 | 4/50 [00:00<00:25,  1.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:50 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 6 (16.7%):  10%|██████████▌                                                                                               | 5/50 [00:00<00:25,  1.80it/s]2025-08-23 15:49:50 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:50 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:50 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:50 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:50 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 2.00 / 7 (28.6%):  12%|████████████▋                                                                                             | 6/50 [00:00<00:24,  1.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:50 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:50 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:50 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:50 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:50 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:50 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:50 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 8 (37.5%):  14%|██████████████▊                                                                                           | 7/50 [00:00<00:23,  1.80it/s]2025-08-23 15:49:50 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:51 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:51 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:51 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:51 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 3.00 / 9 (33.3%):  16%|████████████████▉                                                                                         | 8/50 [00:01<00:23,  1.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:51 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:51 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 3.00 / 9 (33.3%):  18%|███████████████████                                                                                       | 9/50 [00:01<00:04,  9.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:51 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:51 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 4.00 / 10 (40.0%):  18%|██████████████████▉                                                                                      | 9/50 [00:01<00:04,  9.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:51 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:51 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 5.00 / 11 (45.5%):  20%|████████████████████▊                                                                                   | 10/50 [00:01<00:04,  9.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:51 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:51 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 5.00 / 12 (41.7%):  22%|██████████████████████▉                                                                                 | 11/50 [00:01<00:04,  9.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:51 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:49:51 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:51 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:51 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:51 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 6.00 / 13 (46.2%):  24%|████████████████████████▉                                                                               | 12/50 [00:01<00:04,  9.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:51 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:51 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:51 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:51 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 6.00 / 14 (42.9%):  26%|███████████████████████████                                                                             | 13/50 [00:01<00:03,  9.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:51 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:51 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:49:51 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 7.00 / 15 (46.7%):  28%|█████████████████████████████                                                                           | 14/50 [00:01<00:03,  9.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:51 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:51 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:51 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 16 (50.0%):  30%|███████████████████████████████▏                                                                        | 15/50 [00:01<00:03,  9.48it/s]2025-08-23 15:49:51 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:51 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:51 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:51 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:51 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:51 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:51 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:51 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:51 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 9.00 / 17 (52.9%):  32%|█████████████████████████████████▎                                                                      | 16/50 [00:01<00:03,  9.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:51 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:49:51 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:51 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 9.00 / 17 (52.9%):  34%|███████████████████████████████████▎                                                                    | 17/50 [00:01<00:02, 11.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:51 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:51 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 11.00 / 19 (57.9%):  36%|█████████████████████████████████████                                                                  | 18/50 [00:01<00:02, 11.21it/s]2025-08-23 15:49:51 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:51 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:49:51 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:51 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 11.00 / 20 (55.0%):  38%|███████████████████████████████████████▏                                                               | 19/50 [00:01<00:02, 11.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:51 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:51 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:51 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:51 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:49:51 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 11.00 / 21 (52.4%):  40%|█████████████████████████████████████████▏                                                             | 20/50 [00:01<00:02, 11.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:51 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:51 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 12.00 / 22 (54.5%):  42%|███████████████████████████████████████████▎                                                           | 21/50 [00:01<00:02, 11.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:51 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:51 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:51 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 23 (56.5%):  44%|█████████████████████████████████████████████▎                                                         | 22/50 [00:01<00:02, 11.21it/s]2025-08-23 15:49:51 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:51 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:51 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 14.00 / 24 (58.3%):  46%|███████████████████████████████████████████████▍                                                       | 23/50 [00:01<00:02, 11.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:51 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:51 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:51 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:51 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:51 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:51 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 15.00 / 25 (60.0%):  48%|█████████████████████████████████████████████████▍                                                     | 24/50 [00:02<00:02, 11.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 15.00 / 25 (60.0%):  50%|███████████████████████████████████████████████████▌                                                   | 25/50 [00:02<00:01, 13.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 15.00 / 26 (57.7%):  50%|███████████████████████████████████████████████████▌                                                   | 25/50 [00:02<00:01, 13.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 27 (59.3%):  52%|█████████████████████████████████████████████████████▌                                                 | 26/50 [00:02<00:01, 13.16it/s]2025-08-23 15:49:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 28 (60.7%):  54%|███████████████████████████████████████████████████████▌                                               | 27/50 [00:02<00:01, 13.16it/s]2025-08-23 15:49:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 29 (62.1%):  56%|█████████████████████████████████████████████████████████▋                                             | 28/50 [00:02<00:01, 13.16it/s]2025-08-23 15:49:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 18.00 / 29 (62.1%):  58%|███████████████████████████████████████████████████████████▋                                           | 29/50 [00:02<00:01, 15.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 30 (63.3%):  58%|███████████████████████████████████████████████████████████▋                                           | 29/50 [00:02<00:01, 15.58it/s]2025-08-23 15:49:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 31 (61.3%):  60%|█████████████████████████████████████████████████████████████▊                                         | 30/50 [00:02<00:01, 15.58it/s]2025-08-23 15:49:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 19.00 / 32 (59.4%):  62%|███████████████████████████████████████████████████████████████▊                                       | 31/50 [00:02<00:01, 15.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 20.00 / 33 (60.6%):  64%|█████████████████████████████████████████████████████████████████▉                                     | 32/50 [00:02<00:01, 15.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 33 (60.6%):  66%|███████████████████████████████████████████████████████████████████▉                                   | 33/50 [00:02<00:01, 13.30it/s]2025-08-23 15:49:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 20.00 / 34 (58.8%):  66%|███████████████████████████████████████████████████████████████████▉                                   | 33/50 [00:02<00:01, 13.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 35 (60.0%):  68%|██████████████████████████████████████████████████████████████████████                                 | 34/50 [00:02<00:01, 13.30it/s]2025-08-23 15:49:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 36 (61.1%):  70%|████████████████████████████████████████████████████████████████████████                               | 35/50 [00:02<00:01, 13.30it/s]2025-08-23 15:49:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 37 (62.2%):  72%|██████████████████████████████████████████████████████████████████████████▏                            | 36/50 [00:02<00:01, 13.30it/s]2025-08-23 15:49:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 38 (63.2%):  74%|████████████████████████████████████████████████████████████████████████████▏                          | 37/50 [00:02<00:00, 13.30it/s]2025-08-23 15:49:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.00 / 39 (64.1%):  76%|██████████████████████████████████████████████████████████████████████████████▎                        | 38/50 [00:02<00:00, 13.30it/s]2025-08-23 15:49:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 26.00 / 40 (65.0%):  78%|████████████████████████████████████████████████████████████████████████████████▎                      | 39/50 [00:02<00:00, 13.30it/s]2025-08-23 15:49:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 26.00 / 40 (65.0%):  80%|██████████████████████████████████████████████████████████████████████████████████▍                    | 40/50 [00:02<00:00, 18.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27.00 / 41 (65.9%):  80%|██████████████████████████████████████████████████████████████████████████████████▍                    | 40/50 [00:03<00:00, 18.89it/s]2025-08-23 15:49:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 28.00 / 42 (66.7%):  82%|████████████████████████████████████████████████████████████████████████████████████▍                  | 41/50 [00:03<00:00, 18.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 29.00 / 44 (65.9%):  86%|████████████████████████████████████████████████████████████████████████████████████████▌              | 43/50 [00:03<00:00, 14.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 30.00 / 45 (66.7%):  88%|██████████████████████████████████████████████████████████████████████████████████████████▋            | 44/50 [00:03<00:00, 14.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 31.00 / 46 (67.4%):  90%|████████████████████████████████████████████████████████████████████████████████████████████▋          | 45/50 [00:03<00:00, 14.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 32.00 / 47 (68.1%):  92%|██████████████████████████████████████████████████████████████████████████████████████████████▊        | 46/50 [00:03<00:00, 14.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 33.00 / 48 (68.8%):  94%|████████████████████████████████████████████████████████████████████████████████████████████████▊      | 47/50 [00:03<00:00, 14.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 33.00 / 49 (67.3%):  96%|██████████████████████████████████████████████████████████████████████████████████████████████████▉    | 48/50 [00:03<00:00, 14.64it/s]2025-08-23 15:49:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 34.00 / 50 (68.0%): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 13.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/23 15:49:53 INFO dspy.evaluate.evaluate: Average Metric: 34 / 50 (68.0%)\n",
      "2025/08/23 15:49:53 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mBest full score so far!\u001b[0m Score: 68.0\n",
      "2025/08/23 15:49:53 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 68.0 with parameters ['Predictor 0: Instruction 5', 'Predictor 0: Few-Shot Set 8'].\n",
      "2025/08/23 15:49:53 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [66.0, 68.0]\n",
      "2025/08/23 15:49:53 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 68.0\n",
      "2025/08/23 15:49:53 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/08/23 15:49:53 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 3 / 18 =====\n",
      "\u001b[92m15:49:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-08-23 15:49:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:49:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:49:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                    | 0/50 [00:00<?, ?it/s]2025-08-23 15:49:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 1 (0.0%):   0%|                                                                                                                   | 0/50 [00:00<?, ?it/s]2025-08-23 15:49:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 0.00 / 1 (0.0%):   2%|██▏                                                                                                        | 1/50 [00:00<00:27,  1.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 1.00 / 2 (50.0%):   2%|██                                                                                                        | 1/50 [00:00<00:27,  1.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 1.00 / 3 (33.3%):   4%|████▏                                                                                                     | 2/50 [00:00<00:27,  1.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:49:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 2.00 / 4 (50.0%):   6%|██████▎                                                                                                   | 3/50 [00:00<00:26,  1.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:49:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 2.00 / 5 (40.0%):   8%|████████▍                                                                                                 | 4/50 [00:00<00:26,  1.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 2.00 / 6 (33.3%):  10%|██████████▌                                                                                               | 5/50 [00:00<00:25,  1.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 3.00 / 7 (42.9%):  12%|████████████▋                                                                                             | 6/50 [00:00<00:25,  1.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 4.00 / 8 (50.0%):  14%|██████████████▊                                                                                           | 7/50 [00:00<00:24,  1.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 5.00 / 9 (55.6%):  16%|████████████████▉                                                                                         | 8/50 [00:01<00:23,  1.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 5.00 / 9 (55.6%):  18%|███████████████████                                                                                       | 9/50 [00:01<00:04,  9.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 10 (50.0%):  18%|██████████████████▉                                                                                      | 9/50 [00:01<00:04,  9.56it/s]2025-08-23 15:49:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 11 (54.5%):  20%|████████████████████▊                                                                                   | 10/50 [00:01<00:04,  9.56it/s]2025-08-23 15:49:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:49:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 12 (50.0%):  22%|██████████████████████▉                                                                                 | 11/50 [00:01<00:04,  9.56it/s]2025-08-23 15:49:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 7.00 / 13 (53.8%):  24%|████████████████████████▉                                                                               | 12/50 [00:01<00:03,  9.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:49:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 7.00 / 14 (50.0%):  26%|███████████████████████████                                                                             | 13/50 [00:01<00:03,  9.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 15 (46.7%):  28%|█████████████████████████████                                                                           | 14/50 [00:01<00:03,  9.56it/s]2025-08-23 15:49:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 16 (50.0%):  30%|███████████████████████████████▏                                                                        | 15/50 [00:01<00:03,  9.56it/s]2025-08-23 15:49:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 17 (52.9%):  32%|█████████████████████████████████▎                                                                      | 16/50 [00:01<00:03,  9.56it/s]2025-08-23 15:49:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 17 (52.9%):  34%|███████████████████████████████████▎                                                                    | 17/50 [00:01<00:02, 12.25it/s]2025-08-23 15:49:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:49:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 18 (50.0%):  34%|███████████████████████████████████▎                                                                    | 17/50 [00:01<00:02, 12.25it/s]2025-08-23 15:49:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 10.00 / 19 (52.6%):  36%|█████████████████████████████████████                                                                  | 18/50 [00:01<00:02, 12.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 10.00 / 20 (50.0%):  38%|███████████████████████████████████████▏                                                               | 19/50 [00:01<00:02, 12.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 11.00 / 21 (52.4%):  40%|█████████████████████████████████████████▏                                                             | 20/50 [00:01<00:02, 12.25it/s]2025-08-23 15:49:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 22 (50.0%):  42%|███████████████████████████████████████████▎                                                           | 21/50 [00:01<00:02, 12.25it/s]2025-08-23 15:49:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 23 (47.8%):  44%|█████████████████████████████████████████████▎                                                         | 22/50 [00:01<00:02, 12.25it/s]2025-08-23 15:49:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 24 (50.0%):  46%|███████████████████████████████████████████████▍                                                       | 23/50 [00:01<00:02, 12.25it/s]2025-08-23 15:49:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 12.00 / 24 (50.0%):  48%|█████████████████████████████████████████████████▍                                                     | 24/50 [00:01<00:01, 16.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 13.00 / 25 (52.0%):  48%|█████████████████████████████████████████████████▍                                                     | 24/50 [00:02<00:01, 16.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 14.00 / 26 (53.8%):  50%|███████████████████████████████████████████████████▌                                                   | 25/50 [00:02<00:01, 16.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 14.00 / 27 (51.9%):  52%|█████████████████████████████████████████████████████▌                                                 | 26/50 [00:02<00:01, 16.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 27 (51.9%):  54%|███████████████████████████████████████████████████████▌                                               | 27/50 [00:02<00:01, 14.47it/s]2025-08-23 15:49:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 28 (53.6%):  54%|███████████████████████████████████████████████████████▌                                               | 27/50 [00:02<00:01, 14.47it/s]2025-08-23 15:49:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 29 (55.2%):  56%|█████████████████████████████████████████████████████████▋                                             | 28/50 [00:02<00:01, 14.47it/s]2025-08-23 15:49:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 16.00 / 30 (53.3%):  58%|███████████████████████████████████████████████████████████▋                                           | 29/50 [00:02<00:01, 14.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:55 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:55 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 17.00 / 31 (54.8%):  60%|█████████████████████████████████████████████████████████████▊                                         | 30/50 [00:02<00:01, 14.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:55 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:55 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 32 (56.2%):  62%|███████████████████████████████████████████████████████████████▊                                       | 31/50 [00:02<00:01, 14.47it/s]2025-08-23 15:49:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 18.00 / 32 (56.2%):  64%|█████████████████████████████████████████████████████████████████▉                                     | 32/50 [00:02<00:01, 14.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 33 (54.5%):  64%|█████████████████████████████████████████████████████████████████▉                                     | 32/50 [00:02<00:01, 14.84it/s]2025-08-23 15:49:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 34 (55.9%):  66%|███████████████████████████████████████████████████████████████████▉                                   | 33/50 [00:02<00:01, 14.84it/s]2025-08-23 15:49:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 19.00 / 34 (55.9%):  68%|██████████████████████████████████████████████████████████████████████                                 | 34/50 [00:02<00:01, 15.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 20.00 / 35 (57.1%):  68%|██████████████████████████████████████████████████████████████████████                                 | 34/50 [00:02<00:01, 15.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 36 (58.3%):  70%|████████████████████████████████████████████████████████████████████████                               | 35/50 [00:02<00:00, 15.07it/s]2025-08-23 15:49:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:49:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 21.00 / 37 (56.8%):  72%|██████████████████████████████████████████████████████████████████████████▏                            | 36/50 [00:02<00:00, 15.07it/s]2025-08-23 15:49:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 38 (57.9%):  74%|████████████████████████████████████████████████████████████████████████████▏                          | 37/50 [00:02<00:00, 15.07it/s]2025-08-23 15:49:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 39 (56.4%):  76%|██████████████████████████████████████████████████████████████████████████████▎                        | 38/50 [00:02<00:00, 15.07it/s]2025-08-23 15:49:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 40 (57.5%):  78%|████████████████████████████████████████████████████████████████████████████████▎                      | 39/50 [00:02<00:00, 15.07it/s]2025-08-23 15:49:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 23.00 / 40 (57.5%):  80%|██████████████████████████████████████████████████████████████████████████████████▍                    | 40/50 [00:02<00:00, 16.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 24.00 / 41 (58.5%):  80%|██████████████████████████████████████████████████████████████████████████████████▍                    | 40/50 [00:02<00:00, 16.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:56 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.00 / 42 (59.5%):  82%|████████████████████████████████████████████████████████████████████████████████████▍                  | 41/50 [00:03<00:00, 16.53it/s]2025-08-23 15:49:56 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 25.00 / 42 (59.5%):  84%|██████████████████████████████████████████████████████████████████████████████████████▌                | 42/50 [00:03<00:00, 15.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 26.00 / 43 (60.5%):  84%|██████████████████████████████████████████████████████████████████████████████████████▌                | 42/50 [00:03<00:00, 15.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 26.00 / 44 (59.1%):  86%|████████████████████████████████████████████████████████████████████████████████████████▌              | 43/50 [00:03<00:00, 15.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 27.00 / 45 (60.0%):  88%|██████████████████████████████████████████████████████████████████████████████████████████▋            | 44/50 [00:03<00:00, 15.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 27.00 / 46 (58.7%):  92%|██████████████████████████████████████████████████████████████████████████████████████████████▊        | 46/50 [00:03<00:00, 18.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:56 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:56 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 28.00 / 47 (59.6%):  92%|██████████████████████████████████████████████████████████████████████████████████████████████▊        | 46/50 [00:03<00:00, 18.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 29.00 / 48 (60.4%):  96%|██████████████████████████████████████████████████████████████████████████████████████████████████▉    | 48/50 [00:03<00:00, 17.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 30.00 / 49 (61.2%):  96%|██████████████████████████████████████████████████████████████████████████████████████████████████▉    | 48/50 [00:03<00:00, 17.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 31.00 / 50 (62.0%): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 14.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/23 15:49:57 INFO dspy.evaluate.evaluate: Average Metric: 31 / 50 (62.0%)\n",
      "2025/08/23 15:49:57 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 62.0 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 1'].\n",
      "2025/08/23 15:49:57 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [66.0, 68.0, 62.0]\n",
      "2025/08/23 15:49:57 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 68.0\n",
      "2025/08/23 15:49:57 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/08/23 15:49:57 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 4 / 18 =====\n",
      "\u001b[92m15:49:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-08-23 15:49:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                    | 0/50 [00:00<?, ?it/s]2025-08-23 15:49:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:49:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:49:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 0.00 / 1 (0.0%):   0%|                                                                                                                   | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:49:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 0.00 / 1 (0.0%):   2%|██▏                                                                                                        | 1/50 [00:00<00:25,  1.95it/s]2025-08-23 15:49:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 1.00 / 2 (50.0%):   2%|██                                                                                                        | 1/50 [00:00<00:25,  1.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 1.00 / 3 (33.3%):   4%|████▏                                                                                                     | 2/50 [00:00<00:24,  1.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 2.00 / 4 (50.0%):   6%|██████▎                                                                                                   | 3/50 [00:00<00:24,  1.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 2.00 / 5 (40.0%):   8%|████████▍                                                                                                 | 4/50 [00:00<00:23,  1.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 6 (50.0%):  10%|██████████▌                                                                                               | 5/50 [00:00<00:23,  1.95it/s]2025-08-23 15:49:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 7 (42.9%):  12%|████████████▋                                                                                             | 6/50 [00:00<00:22,  1.95it/s]2025-08-23 15:49:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:57 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:57 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:57 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 8 (50.0%):  14%|██████████████▊                                                                                           | 7/50 [00:00<00:22,  1.95it/s]2025-08-23 15:49:57 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 9 (55.6%):  16%|████████████████▉                                                                                         | 8/50 [00:01<00:21,  1.95it/s]2025-08-23 15:49:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:58 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 9 (55.6%):  18%|███████████████████                                                                                       | 9/50 [00:01<00:04,  9.22it/s]2025-08-23 15:49:58 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 10 (50.0%):  18%|██████████████████▉                                                                                      | 9/50 [00:01<00:04,  9.22it/s]2025-08-23 15:49:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 6.00 / 11 (54.5%):  20%|████████████████████▊                                                                                   | 10/50 [00:01<00:04,  9.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:58 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 12 (50.0%):  22%|██████████████████████▉                                                                                 | 11/50 [00:01<00:04,  9.22it/s]2025-08-23 15:49:58 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 13 (53.8%):  24%|████████████████████████▉                                                                               | 12/50 [00:01<00:04,  9.22it/s]2025-08-23 15:49:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:58 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:58 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 8.00 / 14 (57.1%):  26%|███████████████████████████                                                                             | 13/50 [00:01<00:04,  9.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:58 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:58 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:58 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:58 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 8.00 / 15 (53.3%):  28%|█████████████████████████████                                                                           | 14/50 [00:01<00:03,  9.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:58 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:58 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:58 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:58 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:58 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 16 (56.2%):  30%|███████████████████████████████▏                                                                        | 15/50 [00:01<00:03,  9.22it/s]2025-08-23 15:49:58 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:58 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 17 (58.8%):  32%|████████████████████████████████▉                                                                      | 16/50 [00:01<00:03,  9.22it/s]2025-08-23 15:49:58 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 10.00 / 17 (58.8%):  34%|███████████████████████████████████                                                                    | 17/50 [00:01<00:02, 12.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 11.00 / 18 (61.1%):  34%|███████████████████████████████████                                                                    | 17/50 [00:01<00:02, 12.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:58 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:58 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 12.00 / 19 (63.2%):  36%|█████████████████████████████████████                                                                  | 18/50 [00:01<00:02, 12.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:58 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:58 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 12.00 / 20 (60.0%):  38%|███████████████████████████████████████▏                                                               | 19/50 [00:01<00:02, 12.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:58 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 21 (57.1%):  40%|█████████████████████████████████████████▏                                                             | 20/50 [00:01<00:02, 12.20it/s]2025-08-23 15:49:58 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:59 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:59 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 13.00 / 22 (59.1%):  42%|███████████████████████████████████████████▎                                                           | 21/50 [00:01<00:02, 12.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:59 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:59 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 13.00 / 23 (56.5%):  44%|█████████████████████████████████████████████▎                                                         | 22/50 [00:01<00:02, 12.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:59 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:59 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 24 (54.2%):  46%|███████████████████████████████████████████████▍                                                       | 23/50 [00:01<00:02, 12.20it/s]2025-08-23 15:49:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:59 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:59 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:59 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 25 (56.0%):  48%|█████████████████████████████████████████████████▍                                                     | 24/50 [00:02<00:02, 12.20it/s]2025-08-23 15:49:59 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 14.00 / 25 (56.0%):  50%|███████████████████████████████████████████████████▌                                                   | 25/50 [00:02<00:01, 13.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 15.00 / 26 (57.7%):  50%|███████████████████████████████████████████████████▌                                                   | 25/50 [00:02<00:01, 13.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:59 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:59 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 27 (55.6%):  52%|█████████████████████████████████████████████████████▌                                                 | 26/50 [00:02<00:01, 13.46it/s]2025-08-23 15:49:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:59 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:59 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:59 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 28 (57.1%):  54%|███████████████████████████████████████████████████████▌                                               | 27/50 [00:02<00:01, 13.46it/s]2025-08-23 15:49:59 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 29 (58.6%):  56%|█████████████████████████████████████████████████████████▋                                             | 28/50 [00:02<00:01, 13.46it/s]2025-08-23 15:49:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:59 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:59 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 30 (60.0%):  58%|███████████████████████████████████████████████████████████▋                                           | 29/50 [00:02<00:01, 13.46it/s]2025-08-23 15:49:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:59 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:59 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 31 (58.1%):  60%|█████████████████████████████████████████████████████████████▊                                         | 30/50 [00:02<00:01, 13.46it/s]2025-08-23 15:49:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:59 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:59 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 32 (59.4%):  64%|█████████████████████████████████████████████████████████████████▉                                     | 32/50 [00:02<00:01, 16.50it/s]2025-08-23 15:49:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:59 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:59 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:59 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:59 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 20.00 / 33 (60.6%):  64%|█████████████████████████████████████████████████████████████████▉                                     | 32/50 [00:02<00:01, 16.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:49:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 20.00 / 34 (58.8%):  68%|██████████████████████████████████████████████████████████████████████                                 | 34/50 [00:02<00:01, 15.12it/s]2025-08-23 15:49:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:59 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:59 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 35 (57.1%):  68%|██████████████████████████████████████████████████████████████████████                                 | 34/50 [00:02<00:01, 15.12it/s]2025-08-23 15:49:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:59 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:49:59 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:49:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 36 (58.3%):  70%|████████████████████████████████████████████████████████████████████████                               | 35/50 [00:02<00:00, 15.12it/s]2025-08-23 15:49:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 37 (56.8%):  72%|██████████████████████████████████████████████████████████████████████████▏                            | 36/50 [00:02<00:00, 15.12it/s]2025-08-23 15:50:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 21.00 / 37 (56.8%):  74%|████████████████████████████████████████████████████████████████████████████▏                          | 37/50 [00:02<00:00, 16.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 38 (57.9%):  74%|████████████████████████████████████████████████████████████████████████████▏                          | 37/50 [00:02<00:00, 16.58it/s]2025-08-23 15:50:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 39 (59.0%):  76%|██████████████████████████████████████████████████████████████████████████████▎                        | 38/50 [00:02<00:00, 16.58it/s]2025-08-23 15:50:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 23.00 / 39 (59.0%):  78%|████████████████████████████████████████████████████████████████████████████████▎                      | 39/50 [00:02<00:00, 16.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 40 (57.5%):  78%|████████████████████████████████████████████████████████████████████████████████▎                      | 39/50 [00:02<00:00, 16.35it/s]2025-08-23 15:50:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 24.00 / 41 (58.5%):  80%|██████████████████████████████████████████████████████████████████████████████████▍                    | 40/50 [00:03<00:00, 16.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 41 (58.5%):  82%|████████████████████████████████████████████████████████████████████████████████████▍                  | 41/50 [00:03<00:00, 13.66it/s]2025-08-23 15:50:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 25.00 / 42 (59.5%):  82%|████████████████████████████████████████████████████████████████████████████████████▍                  | 41/50 [00:03<00:00, 13.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 26.00 / 43 (60.5%):  84%|██████████████████████████████████████████████████████████████████████████████████████▌                | 42/50 [00:03<00:00, 13.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 27.00 / 44 (61.4%):  86%|████████████████████████████████████████████████████████████████████████████████████████▌              | 43/50 [00:03<00:00, 13.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27.00 / 45 (60.0%):  88%|██████████████████████████████████████████████████████████████████████████████████████████▋            | 44/50 [00:03<00:00, 13.66it/s]2025-08-23 15:50:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 27.00 / 46 (58.7%):  90%|████████████████████████████████████████████████████████████████████████████████████████████▋          | 45/50 [00:03<00:00, 14.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 28.00 / 47 (59.6%):  92%|██████████████████████████████████████████████████████████████████████████████████████████████▊        | 46/50 [00:03<00:00, 14.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 29.00 / 48 (60.4%):  94%|████████████████████████████████████████████████████████████████████████████████████████████████▊      | 47/50 [00:03<00:00, 14.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 30.00 / 49 (61.2%):  98%|████████████████████████████████████████████████████████████████████████████████████████████████████▉  | 49/50 [00:03<00:00, 14.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 31.00 / 50 (62.0%): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 13.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/23 15:50:00 INFO dspy.evaluate.evaluate: Average Metric: 31 / 50 (62.0%)\n",
      "2025/08/23 15:50:00 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 62.0 with parameters ['Predictor 0: Instruction 3', 'Predictor 0: Few-Shot Set 1'].\n",
      "2025/08/23 15:50:00 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [66.0, 68.0, 62.0, 62.0]\n",
      "2025/08/23 15:50:00 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 68.0\n",
      "2025/08/23 15:50:00 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/08/23 15:50:00 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 5 / 18 =====\n",
      "\u001b[92m15:50:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-08-23 15:50:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:50:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:50:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                    | 0/50 [00:00<?, ?it/s]2025-08-23 15:50:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 1 (100.0%):   2%|██                                                                                                       | 1/50 [00:00<00:22,  2.22it/s]2025-08-23 15:50:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 2 (50.0%):   2%|██                                                                                                        | 1/50 [00:00<00:22,  2.22it/s]2025-08-23 15:50:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 2.00 / 3 (66.7%):   4%|████▏                                                                                                     | 2/50 [00:00<00:21,  2.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 4 (75.0%):   6%|██████▎                                                                                                   | 3/50 [00:00<00:21,  2.22it/s]2025-08-23 15:50:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 5 (80.0%):   8%|████████▍                                                                                                 | 4/50 [00:00<00:20,  2.22it/s]2025-08-23 15:50:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 6 (66.7%):  10%|██████████▌                                                                                               | 5/50 [00:00<00:20,  2.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:50:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 7 (57.1%):  12%|████████████▋                                                                                             | 6/50 [00:00<00:19,  2.22it/s]2025-08-23 15:50:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 5.00 / 8 (62.5%):  14%|██████████████▊                                                                                           | 7/50 [00:00<00:19,  2.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 5.00 / 8 (62.5%):  16%|████████████████▉                                                                                         | 8/50 [00:00<00:02, 16.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 9 (66.7%):  16%|████████████████▉                                                                                         | 8/50 [00:00<00:02, 16.45it/s]2025-08-23 15:50:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 10 (70.0%):  18%|██████████████████▉                                                                                      | 9/50 [00:00<00:02, 16.45it/s]2025-08-23 15:50:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 8.00 / 11 (72.7%):  20%|████████████████████▊                                                                                   | 10/50 [00:00<00:02, 16.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 11 (72.7%):  22%|██████████████████████▉                                                                                 | 11/50 [00:00<00:03, 12.41it/s]2025-08-23 15:50:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 12 (66.7%):  22%|██████████████████████▉                                                                                 | 11/50 [00:00<00:03, 12.41it/s]2025-08-23 15:50:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 13 (61.5%):  24%|████████████████████████▉                                                                               | 12/50 [00:00<00:03, 12.41it/s]2025-08-23 15:50:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 14 (64.3%):  26%|███████████████████████████                                                                             | 13/50 [00:00<00:02, 12.41it/s]2025-08-23 15:50:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 10.00 / 15 (66.7%):  28%|████████████████████████████▊                                                                          | 14/50 [00:01<00:02, 12.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 11.00 / 16 (68.8%):  30%|██████████████████████████████▉                                                                        | 15/50 [00:01<00:02, 12.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 11.00 / 17 (64.7%):  32%|████████████████████████████████▉                                                                      | 16/50 [00:01<00:02, 12.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 11.00 / 17 (64.7%):  34%|███████████████████████████████████                                                                    | 17/50 [00:01<00:02, 12.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 18 (66.7%):  34%|███████████████████████████████████                                                                    | 17/50 [00:01<00:02, 12.99it/s]2025-08-23 15:50:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 19 (68.4%):  36%|█████████████████████████████████████                                                                  | 18/50 [00:01<00:02, 12.99it/s]2025-08-23 15:50:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 13.00 / 20 (65.0%):  38%|███████████████████████████████████████▏                                                               | 19/50 [00:01<00:02, 12.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 14.00 / 21 (66.7%):  40%|█████████████████████████████████████████▏                                                             | 20/50 [00:01<00:02, 12.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 15.00 / 22 (68.2%):  42%|███████████████████████████████████████████▎                                                           | 21/50 [00:01<00:02, 12.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 15.00 / 23 (65.2%):  44%|█████████████████████████████████████████████▎                                                         | 22/50 [00:01<00:02, 12.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 24 (66.7%):  46%|███████████████████████████████████████████████▍                                                       | 23/50 [00:01<00:02, 12.99it/s]2025-08-23 15:50:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 25 (64.0%):  48%|█████████████████████████████████████████████████▍                                                     | 24/50 [00:01<00:02, 12.99it/s]2025-08-23 15:50:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 25 (64.0%):  50%|███████████████████████████████████████████████████▌                                                   | 25/50 [00:01<00:01, 14.85it/s]2025-08-23 15:50:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 26 (65.4%):  50%|███████████████████████████████████████████████████▌                                                   | 25/50 [00:01<00:01, 14.85it/s]2025-08-23 15:50:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 27 (66.7%):  52%|█████████████████████████████████████████████████████▌                                                 | 26/50 [00:01<00:01, 14.85it/s]2025-08-23 15:50:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 28 (64.3%):  54%|███████████████████████████████████████████████████████▌                                               | 27/50 [00:01<00:01, 14.85it/s]2025-08-23 15:50:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 29 (62.1%):  56%|█████████████████████████████████████████████████████████▋                                             | 28/50 [00:01<00:01, 14.85it/s]2025-08-23 15:50:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 30 (63.3%):  58%|███████████████████████████████████████████████████████████▋                                           | 29/50 [00:01<00:01, 14.85it/s]2025-08-23 15:50:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 31 (61.3%):  60%|█████████████████████████████████████████████████████████████▊                                         | 30/50 [00:01<00:01, 14.85it/s]2025-08-23 15:50:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 32 (62.5%):  62%|███████████████████████████████████████████████████████████████▊                                       | 31/50 [00:01<00:01, 14.85it/s]2025-08-23 15:50:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 33 (63.6%):  64%|█████████████████████████████████████████████████████████████████▉                                     | 32/50 [00:02<00:01, 14.85it/s]2025-08-23 15:50:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 21.00 / 33 (63.6%):  66%|███████████████████████████████████████████████████████████████████▉                                   | 33/50 [00:02<00:01, 16.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 34 (61.8%):  66%|███████████████████████████████████████████████████████████████████▉                                   | 33/50 [00:02<00:01, 16.19it/s]2025-08-23 15:50:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 22.00 / 35 (62.9%):  68%|██████████████████████████████████████████████████████████████████████                                 | 34/50 [00:02<00:00, 16.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 23.00 / 36 (63.9%):  70%|████████████████████████████████████████████████████████████████████████                               | 35/50 [00:02<00:00, 16.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 23.00 / 37 (62.2%):  72%|██████████████████████████████████████████████████████████████████████████▏                            | 36/50 [00:02<00:00, 16.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 38 (63.2%):  74%|████████████████████████████████████████████████████████████████████████████▏                          | 37/50 [00:02<00:00, 16.19it/s]2025-08-23 15:50:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.00 / 39 (64.1%):  76%|██████████████████████████████████████████████████████████████████████████████▎                        | 38/50 [00:02<00:00, 16.19it/s]2025-08-23 15:50:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 26.00 / 40 (65.0%):  78%|████████████████████████████████████████████████████████████████████████████████▎                      | 39/50 [00:02<00:00, 16.19it/s]2025-08-23 15:50:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 26.00 / 40 (65.0%):  80%|██████████████████████████████████████████████████████████████████████████████████▍                    | 40/50 [00:02<00:00, 21.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27.00 / 41 (65.9%):  80%|██████████████████████████████████████████████████████████████████████████████████▍                    | 40/50 [00:02<00:00, 21.87it/s]2025-08-23 15:50:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 28.00 / 42 (66.7%):  82%|████████████████████████████████████████████████████████████████████████████████████▍                  | 41/50 [00:02<00:00, 21.87it/s]2025-08-23 15:50:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 30.00 / 44 (68.2%):  88%|██████████████████████████████████████████████████████████████████████████████████████████▋            | 44/50 [00:02<00:00, 17.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 31.00 / 46 (67.4%):  90%|████████████████████████████████████████████████████████████████████████████████████████████▋          | 45/50 [00:02<00:00, 17.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 32.00 / 47 (68.1%):  92%|██████████████████████████████████████████████████████████████████████████████████████████████▊        | 46/50 [00:02<00:00, 17.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 33.00 / 48 (68.8%):  94%|████████████████████████████████████████████████████████████████████████████████████████████████▊      | 47/50 [00:02<00:00, 17.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 34.00 / 49 (69.4%):  98%|████████████████████████████████████████████████████████████████████████████████████████████████████▉  | 49/50 [00:03<00:00, 15.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 34.00 / 50 (68.0%): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 15.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/23 15:50:04 INFO dspy.evaluate.evaluate: Average Metric: 34 / 50 (68.0%)\n",
      "2025/08/23 15:50:04 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 68.0 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 2'].\n",
      "2025/08/23 15:50:04 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [66.0, 68.0, 62.0, 62.0, 68.0]\n",
      "2025/08/23 15:50:04 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 68.0\n",
      "2025/08/23 15:50:04 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/08/23 15:50:04 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 6 / 18 =====\n",
      "\u001b[92m15:50:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-08-23 15:50:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:50:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:50:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                    | 0/50 [00:00<?, ?it/s]2025-08-23 15:50:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 1 (0.0%):   0%|                                                                                                                   | 0/50 [00:00<?, ?it/s]2025-08-23 15:50:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 0.00 / 1 (0.0%):   2%|██▏                                                                                                        | 1/50 [00:00<00:22,  2.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 1.00 / 2 (50.0%):   2%|██                                                                                                        | 1/50 [00:00<00:22,  2.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 1.00 / 3 (33.3%):   4%|████▏                                                                                                     | 2/50 [00:00<00:21,  2.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 4 (50.0%):   6%|██████▎                                                                                                   | 3/50 [00:00<00:21,  2.19it/s]2025-08-23 15:50:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 3.00 / 5 (60.0%):   8%|████████▍                                                                                                 | 4/50 [00:00<00:21,  2.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 4.00 / 6 (66.7%):  10%|██████████▌                                                                                               | 5/50 [00:00<00:20,  2.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 7 (57.1%):  12%|████████████▋                                                                                             | 6/50 [00:00<00:20,  2.19it/s]2025-08-23 15:50:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:04 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:04 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:04 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 8 (62.5%):  14%|██████████████▊                                                                                           | 7/50 [00:00<00:19,  2.19it/s]2025-08-23 15:50:04 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 5.00 / 8 (62.5%):  16%|████████████████▉                                                                                         | 8/50 [00:00<00:02, 18.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 9 (66.7%):  16%|████████████████▉                                                                                         | 8/50 [00:00<00:02, 18.30it/s]2025-08-23 15:50:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 6.00 / 10 (60.0%):  18%|██████████████████▉                                                                                      | 9/50 [00:00<00:02, 18.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 6.00 / 11 (54.5%):  20%|████████████████████▊                                                                                   | 10/50 [00:01<00:02, 18.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 12 (50.0%):  22%|██████████████████████▉                                                                                 | 11/50 [00:01<00:02, 18.30it/s]2025-08-23 15:50:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 7.00 / 13 (53.8%):  24%|████████████████████████▉                                                                               | 12/50 [00:01<00:02, 18.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 13 (53.8%):  26%|███████████████████████████                                                                             | 13/50 [00:01<00:02, 13.61it/s]2025-08-23 15:50:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 14 (57.1%):  26%|███████████████████████████                                                                             | 13/50 [00:01<00:02, 13.61it/s]2025-08-23 15:50:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 15 (53.3%):  28%|█████████████████████████████                                                                           | 14/50 [00:01<00:02, 13.61it/s]2025-08-23 15:50:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 16 (56.2%):  30%|███████████████████████████████▏                                                                        | 15/50 [00:01<00:02, 13.61it/s]2025-08-23 15:50:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 10.00 / 17 (58.8%):  32%|████████████████████████████████▉                                                                      | 16/50 [00:01<00:02, 13.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 17 (58.8%):  34%|███████████████████████████████████                                                                    | 17/50 [00:01<00:02, 11.77it/s]2025-08-23 15:50:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 18 (61.1%):  34%|███████████████████████████████████                                                                    | 17/50 [00:01<00:02, 11.77it/s]2025-08-23 15:50:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 19 (63.2%):  36%|█████████████████████████████████████                                                                  | 18/50 [00:01<00:02, 11.77it/s]2025-08-23 15:50:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 20 (60.0%):  38%|███████████████████████████████████████▏                                                               | 19/50 [00:01<00:02, 11.77it/s]2025-08-23 15:50:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 21 (57.1%):  40%|█████████████████████████████████████████▏                                                             | 20/50 [00:01<00:02, 11.77it/s]2025-08-23 15:50:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 21 (57.1%):  42%|███████████████████████████████████████████▎                                                           | 21/50 [00:01<00:01, 14.56it/s]2025-08-23 15:50:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 22 (54.5%):  42%|███████████████████████████████████████████▎                                                           | 21/50 [00:01<00:01, 14.56it/s]2025-08-23 15:50:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:05 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:05 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 13.00 / 23 (56.5%):  44%|█████████████████████████████████████████████▎                                                         | 22/50 [00:01<00:01, 14.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 14.00 / 24 (58.3%):  46%|███████████████████████████████████████████████▍                                                       | 23/50 [00:01<00:01, 14.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:05 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:05 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:06 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:06 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:06 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 25 (60.0%):  48%|█████████████████████████████████████████████████▍                                                     | 24/50 [00:01<00:01, 14.56it/s]2025-08-23 15:50:06 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 15.00 / 25 (60.0%):  50%|███████████████████████████████████████████████████▌                                                   | 25/50 [00:01<00:01, 12.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:06 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:06 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:06 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:06 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 16.00 / 26 (61.5%):  50%|███████████████████████████████████████████████████▌                                                   | 25/50 [00:02<00:01, 12.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:06 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 27 (59.3%):  52%|█████████████████████████████████████████████████████▌                                                 | 26/50 [00:02<00:01, 12.71it/s]2025-08-23 15:50:06 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:06 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:06 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:06 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:06 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:06 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 28 (60.7%):  54%|███████████████████████████████████████████████████████▌                                               | 27/50 [00:02<00:01, 12.71it/s]2025-08-23 15:50:06 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:06 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:06 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:06 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 29 (62.1%):  56%|█████████████████████████████████████████████████████████▋                                             | 28/50 [00:02<00:01, 12.71it/s]2025-08-23 15:50:06 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:06 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:06 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:06 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 30 (63.3%):  58%|███████████████████████████████████████████████████████████▋                                           | 29/50 [00:02<00:01, 12.71it/s]2025-08-23 15:50:06 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:06 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:06 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:06 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 31 (61.3%):  60%|█████████████████████████████████████████████████████████████▊                                         | 30/50 [00:02<00:01, 12.71it/s]2025-08-23 15:50:06 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 19.00 / 31 (61.3%):  62%|███████████████████████████████████████████████████████████████▊                                       | 31/50 [00:02<00:01, 17.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:06 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:06 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:06 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 32 (62.5%):  62%|███████████████████████████████████████████████████████████████▊                                       | 31/50 [00:02<00:01, 17.91it/s]2025-08-23 15:50:06 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:06 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:06 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:06 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 33 (60.6%):  64%|█████████████████████████████████████████████████████████████████▉                                     | 32/50 [00:02<00:01, 17.91it/s]2025-08-23 15:50:06 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:06 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:06 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:06 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 34 (61.8%):  66%|███████████████████████████████████████████████████████████████████▉                                   | 33/50 [00:02<00:00, 17.91it/s]2025-08-23 15:50:06 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 21.00 / 34 (61.8%):  68%|██████████████████████████████████████████████████████████████████████                                 | 34/50 [00:02<00:01, 14.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:06 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:06 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:06 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 35 (60.0%):  68%|██████████████████████████████████████████████████████████████████████                                 | 34/50 [00:02<00:01, 14.43it/s]2025-08-23 15:50:06 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:06 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:06 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:06 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 36 (61.1%):  70%|████████████████████████████████████████████████████████████████████████                               | 35/50 [00:02<00:01, 14.43it/s]2025-08-23 15:50:06 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:06 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:06 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:06 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 37 (62.2%):  72%|██████████████████████████████████████████████████████████████████████████▏                            | 36/50 [00:02<00:00, 14.43it/s]2025-08-23 15:50:06 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:06 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:06 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:06 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 38 (63.2%):  74%|████████████████████████████████████████████████████████████████████████████▏                          | 37/50 [00:02<00:00, 14.43it/s]2025-08-23 15:50:06 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:06 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:06 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:06 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.00 / 39 (64.1%):  76%|██████████████████████████████████████████████████████████████████████████████▎                        | 38/50 [00:02<00:00, 14.43it/s]2025-08-23 15:50:06 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:06 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:06 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:06 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 26.00 / 40 (65.0%):  78%|████████████████████████████████████████████████████████████████████████████████▎                      | 39/50 [00:02<00:00, 14.43it/s]2025-08-23 15:50:06 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 26.00 / 40 (65.0%):  80%|██████████████████████████████████████████████████████████████████████████████████▍                    | 40/50 [00:02<00:00, 18.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:07 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:07 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:07 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:07 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 27.00 / 41 (65.9%):  80%|██████████████████████████████████████████████████████████████████████████████████▍                    | 40/50 [00:03<00:00, 18.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:07 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27.00 / 42 (64.3%):  82%|████████████████████████████████████████████████████████████████████████████████████▍                  | 41/50 [00:03<00:00, 18.41it/s]2025-08-23 15:50:07 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:07 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:07 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:07 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:07 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 28.00 / 43 (65.1%):  84%|██████████████████████████████████████████████████████████████████████████████████████▌                | 42/50 [00:03<00:00, 18.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:07 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:07 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 28.00 / 43 (65.1%):  86%|████████████████████████████████████████████████████████████████████████████████████████▌              | 43/50 [00:03<00:00, 14.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:07 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:07 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 30.00 / 45 (66.7%):  88%|██████████████████████████████████████████████████████████████████████████████████████████▋            | 44/50 [00:03<00:00, 14.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:07 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:07 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 31.00 / 46 (67.4%):  90%|████████████████████████████████████████████████████████████████████████████████████████████▋          | 45/50 [00:03<00:00, 14.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:07 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:07 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:07 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 32.00 / 47 (68.1%):  92%|██████████████████████████████████████████████████████████████████████████████████████████████▊        | 46/50 [00:03<00:00, 14.29it/s]2025-08-23 15:50:07 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 33.00 / 48 (68.8%):  94%|████████████████████████████████████████████████████████████████████████████████████████████████▊      | 47/50 [00:03<00:00, 16.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:07 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:07 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 34.00 / 49 (69.4%):  96%|██████████████████████████████████████████████████████████████████████████████████████████████████▉    | 48/50 [00:03<00:00, 16.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:07 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:07 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 35.00 / 50 (70.0%): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 13.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/23 15:50:07 INFO dspy.evaluate.evaluate: Average Metric: 35 / 50 (70.0%)\n",
      "2025/08/23 15:50:07 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mBest full score so far!\u001b[0m Score: 70.0\n",
      "2025/08/23 15:50:07 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 70.0 with parameters ['Predictor 0: Instruction 4', 'Predictor 0: Few-Shot Set 6'].\n",
      "2025/08/23 15:50:07 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [66.0, 68.0, 62.0, 62.0, 68.0, 70.0]\n",
      "2025/08/23 15:50:07 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 70.0\n",
      "2025/08/23 15:50:07 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/08/23 15:50:07 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 7 / 18 =====\n",
      "\u001b[92m15:50:07 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-08-23 15:50:07 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:07 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:50:07 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:07 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:50:07 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:07 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                    | 0/50 [00:00<?, ?it/s]2025-08-23 15:50:07 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:07 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:07 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:07 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:07 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:07 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:07 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:07 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:07 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 0.00 / 1 (0.0%):   0%|                                                                                                                   | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:08 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:08 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 0.00 / 1 (0.0%):   2%|██▏                                                                                                        | 1/50 [00:00<00:22,  2.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:08 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 2 (0.0%):   2%|██▏                                                                                                        | 1/50 [00:00<00:22,  2.17it/s]2025-08-23 15:50:08 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:08 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 3 (33.3%):   4%|████▏                                                                                                     | 2/50 [00:00<00:22,  2.17it/s]2025-08-23 15:50:08 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:08 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 4 (25.0%):   6%|██████▎                                                                                                   | 3/50 [00:00<00:21,  2.17it/s]2025-08-23 15:50:08 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:08 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 5 (20.0%):   8%|████████▍                                                                                                 | 4/50 [00:00<00:21,  2.17it/s]2025-08-23 15:50:08 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:08 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 6 (33.3%):  10%|██████████▌                                                                                               | 5/50 [00:00<00:20,  2.17it/s]2025-08-23 15:50:08 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:08 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 7 (42.9%):  12%|████████████▋                                                                                             | 6/50 [00:00<00:20,  2.17it/s]2025-08-23 15:50:08 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:08 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 8 (50.0%):  14%|██████████████▊                                                                                           | 7/50 [00:00<00:19,  2.17it/s]2025-08-23 15:50:08 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 9 (44.4%):  16%|████████████████▉                                                                                         | 8/50 [00:00<00:19,  2.17it/s]2025-08-23 15:50:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 9 (44.4%):  18%|███████████████████                                                                                       | 9/50 [00:00<00:03, 10.81it/s]2025-08-23 15:50:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:08 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 10 (50.0%):  18%|██████████████████▉                                                                                      | 9/50 [00:00<00:03, 10.81it/s]2025-08-23 15:50:08 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:08 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 11 (45.5%):  20%|████████████████████▊                                                                                   | 10/50 [00:00<00:03, 10.81it/s]2025-08-23 15:50:08 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:08 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:08 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:08 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 12 (50.0%):  22%|██████████████████████▉                                                                                 | 11/50 [00:00<00:03, 10.81it/s]2025-08-23 15:50:08 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:08 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 13 (53.8%):  24%|████████████████████████▉                                                                               | 12/50 [00:00<00:03, 10.81it/s]2025-08-23 15:50:08 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:08 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 14 (57.1%):  26%|███████████████████████████                                                                             | 13/50 [00:00<00:03, 10.81it/s]2025-08-23 15:50:08 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:08 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 15 (60.0%):  28%|█████████████████████████████                                                                           | 14/50 [00:01<00:03, 10.81it/s]2025-08-23 15:50:08 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:08 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:08 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:08 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 16 (56.2%):  30%|███████████████████████████████▏                                                                        | 15/50 [00:01<00:03, 10.81it/s]2025-08-23 15:50:08 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:09 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:09 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 10.00 / 17 (58.8%):  32%|████████████████████████████████▉                                                                      | 16/50 [00:01<00:03, 10.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 10.00 / 17 (58.8%):  34%|███████████████████████████████████                                                                    | 17/50 [00:01<00:02, 13.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:09 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:09 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 18 (61.1%):  34%|███████████████████████████████████                                                                    | 17/50 [00:01<00:02, 13.77it/s]2025-08-23 15:50:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:09 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:09 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 19 (63.2%):  36%|█████████████████████████████████████                                                                  | 18/50 [00:01<00:02, 13.77it/s]2025-08-23 15:50:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:09 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:09 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 20 (65.0%):  38%|███████████████████████████████████████▏                                                               | 19/50 [00:01<00:02, 13.77it/s]2025-08-23 15:50:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:09 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:09 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 21 (61.9%):  40%|█████████████████████████████████████████▏                                                             | 20/50 [00:01<00:02, 13.77it/s]2025-08-23 15:50:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:09 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:09 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 22 (59.1%):  42%|███████████████████████████████████████████▎                                                           | 21/50 [00:01<00:02, 13.77it/s]2025-08-23 15:50:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:09 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 22 (59.1%):  44%|█████████████████████████████████████████████▎                                                         | 22/50 [00:01<00:01, 17.81it/s]2025-08-23 15:50:09 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 23 (60.9%):  44%|█████████████████████████████████████████████▎                                                         | 22/50 [00:01<00:01, 17.81it/s]2025-08-23 15:50:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:09 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:09 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 24 (62.5%):  46%|███████████████████████████████████████████████▍                                                       | 23/50 [00:01<00:01, 17.81it/s]2025-08-23 15:50:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:09 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:09 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 25 (64.0%):  48%|█████████████████████████████████████████████████▍                                                     | 24/50 [00:01<00:01, 17.81it/s]2025-08-23 15:50:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 16.00 / 25 (64.0%):  50%|███████████████████████████████████████████████████▌                                                   | 25/50 [00:01<00:01, 13.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:09 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:09 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 26 (61.5%):  50%|███████████████████████████████████████████████████▌                                                   | 25/50 [00:01<00:01, 13.63it/s]2025-08-23 15:50:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:09 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:09 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:09 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:09 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 17.00 / 27 (63.0%):  52%|█████████████████████████████████████████████████████▌                                                 | 26/50 [00:01<00:01, 13.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 18.00 / 28 (64.3%):  54%|███████████████████████████████████████████████████████▌                                               | 27/50 [00:01<00:01, 13.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:09 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:09 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 29 (62.1%):  56%|█████████████████████████████████████████████████████████▋                                             | 28/50 [00:01<00:01, 13.63it/s]2025-08-23 15:50:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:09 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:09 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:09 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 30 (63.3%):  58%|███████████████████████████████████████████████████████████▋                                           | 29/50 [00:02<00:01, 13.63it/s]2025-08-23 15:50:09 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 19.00 / 30 (63.3%):  60%|█████████████████████████████████████████████████████████████▊                                         | 30/50 [00:02<00:01, 17.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:10 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 31 (61.3%):  60%|█████████████████████████████████████████████████████████████▊                                         | 30/50 [00:02<00:01, 17.97it/s]2025-08-23 15:50:10 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:10 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 32 (62.5%):  62%|███████████████████████████████████████████████████████████████▊                                       | 31/50 [00:02<00:01, 17.97it/s]2025-08-23 15:50:10 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:10 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 33 (60.6%):  64%|█████████████████████████████████████████████████████████████████▉                                     | 32/50 [00:02<00:01, 17.97it/s]2025-08-23 15:50:10 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 20.00 / 33 (60.6%):  66%|███████████████████████████████████████████████████████████████████▉                                   | 33/50 [00:02<00:01, 14.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 21.00 / 34 (61.8%):  66%|███████████████████████████████████████████████████████████████████▉                                   | 33/50 [00:02<00:01, 14.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:10 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:10 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:10 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 35 (62.9%):  68%|██████████████████████████████████████████████████████████████████████                                 | 34/50 [00:02<00:01, 14.37it/s]2025-08-23 15:50:10 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:10 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 36 (63.9%):  70%|████████████████████████████████████████████████████████████████████████                               | 35/50 [00:02<00:01, 14.37it/s]2025-08-23 15:50:10 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 23.00 / 36 (63.9%):  72%|██████████████████████████████████████████████████████████████████████████▏                            | 36/50 [00:02<00:00, 16.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:10 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 37 (64.9%):  72%|██████████████████████████████████████████████████████████████████████████▏                            | 36/50 [00:02<00:00, 16.39it/s]2025-08-23 15:50:10 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:10 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.00 / 38 (65.8%):  74%|████████████████████████████████████████████████████████████████████████████▏                          | 37/50 [00:02<00:00, 16.39it/s]2025-08-23 15:50:10 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 26.00 / 39 (66.7%):  76%|██████████████████████████████████████████████████████████████████████████████▎                        | 38/50 [00:02<00:00, 16.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:10 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:10 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 26.00 / 39 (66.7%):  78%|████████████████████████████████████████████████████████████████████████████████▎                      | 39/50 [00:02<00:00, 17.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:10 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:10 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 27.00 / 40 (67.5%):  78%|████████████████████████████████████████████████████████████████████████████████▎                      | 39/50 [00:02<00:00, 17.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:10 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 28.00 / 41 (68.3%):  80%|██████████████████████████████████████████████████████████████████████████████████▍                    | 40/50 [00:02<00:00, 17.99it/s]2025-08-23 15:50:10 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:10 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 29.00 / 42 (69.0%):  82%|████████████████████████████████████████████████████████████████████████████████████▍                  | 41/50 [00:02<00:00, 17.99it/s]2025-08-23 15:50:10 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 29.00 / 42 (69.0%):  84%|██████████████████████████████████████████████████████████████████████████████████████▌                | 42/50 [00:02<00:00, 14.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 30.00 / 43 (69.8%):  84%|██████████████████████████████████████████████████████████████████████████████████████▌                | 42/50 [00:02<00:00, 14.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 31.00 / 44 (70.5%):  86%|████████████████████████████████████████████████████████████████████████████████████████▌              | 43/50 [00:02<00:00, 14.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:10 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:10 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 31.00 / 45 (68.9%):  90%|████████████████████████████████████████████████████████████████████████████████████████████▋          | 45/50 [00:03<00:00, 17.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:11 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:11 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 32.00 / 46 (69.6%):  90%|████████████████████████████████████████████████████████████████████████████████████████████▋          | 45/50 [00:03<00:00, 17.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:11 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:11 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 33.00 / 47 (70.2%):  92%|██████████████████████████████████████████████████████████████████████████████████████████████▊        | 46/50 [00:03<00:00, 17.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:11 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:11 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 34.00 / 48 (70.8%):  96%|██████████████████████████████████████████████████████████████████████████████████████████████████▉    | 48/50 [00:03<00:00, 17.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:11 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:11 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 34.00 / 49 (69.4%):  96%|██████████████████████████████████████████████████████████████████████████████████████████████████▉    | 48/50 [00:03<00:00, 17.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:11 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:11 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 35.00 / 50 (70.0%): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 14.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/23 15:50:11 INFO dspy.evaluate.evaluate: Average Metric: 35 / 50 (70.0%)\n",
      "2025/08/23 15:50:11 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 70.0 with parameters ['Predictor 0: Instruction 5', 'Predictor 0: Few-Shot Set 8'].\n",
      "2025/08/23 15:50:11 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [66.0, 68.0, 62.0, 62.0, 68.0, 70.0, 70.0]\n",
      "2025/08/23 15:50:11 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 70.0\n",
      "2025/08/23 15:50:11 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/08/23 15:50:11 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 8 / 18 =====\n",
      "\u001b[92m15:50:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-08-23 15:50:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:50:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:50:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                    | 0/50 [00:00<?, ?it/s]2025-08-23 15:50:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:11 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:11 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:11 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 1 (100.0%):   0%|                                                                                                                 | 0/50 [00:00<?, ?it/s]2025-08-23 15:50:11 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 1.00 / 1 (100.0%):   2%|██                                                                                                       | 1/50 [00:00<00:23,  2.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:11 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:11 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 2 (50.0%):   2%|██                                                                                                        | 1/50 [00:00<00:23,  2.06it/s]2025-08-23 15:50:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:11 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 3 (33.3%):   4%|████▏                                                                                                     | 2/50 [00:00<00:23,  2.06it/s]2025-08-23 15:50:11 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 2.00 / 4 (50.0%):   6%|██████▎                                                                                                   | 3/50 [00:00<00:22,  2.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:11 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:11 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:11 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:11 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 3.00 / 5 (60.0%):   8%|████████▍                                                                                                 | 4/50 [00:00<00:22,  2.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 4.00 / 6 (66.7%):  10%|██████████▌                                                                                               | 5/50 [00:00<00:21,  2.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:11 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:11 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 4.00 / 7 (57.1%):  12%|████████████▋                                                                                             | 6/50 [00:00<00:21,  2.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:11 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:11 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:11 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 8 (62.5%):  14%|██████████████▊                                                                                           | 7/50 [00:00<00:20,  2.06it/s]2025-08-23 15:50:11 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:12 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:12 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 6.00 / 9 (66.7%):  16%|████████████████▉                                                                                         | 8/50 [00:00<00:20,  2.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:12 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:12 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 6.00 / 9 (66.7%):  18%|███████████████████                                                                                       | 9/50 [00:00<00:03, 10.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:12 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:50:12 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:12 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:50:12 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:12 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 10 (70.0%):  18%|██████████████████▉                                                                                      | 9/50 [00:00<00:03, 10.80it/s]2025-08-23 15:50:12 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:12 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:50:12 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:12 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 7.00 / 11 (63.6%):  20%|████████████████████▊                                                                                   | 10/50 [00:00<00:03, 10.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:12 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:12 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:50:12 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 8.00 / 12 (66.7%):  22%|██████████████████████▉                                                                                 | 11/50 [00:00<00:03, 10.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:12 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:12 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 9.00 / 13 (69.2%):  24%|████████████████████████▉                                                                               | 12/50 [00:00<00:03, 10.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:12 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:12 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:12 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:12 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:12 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 14 (64.3%):  26%|███████████████████████████                                                                             | 13/50 [00:00<00:03, 10.80it/s]2025-08-23 15:50:12 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:12 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:12 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:12 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 15 (66.7%):  28%|████████████████████████████▊                                                                          | 14/50 [00:01<00:03, 10.80it/s]2025-08-23 15:50:12 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:12 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:12 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:12 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 16 (62.5%):  30%|██████████████████████████████▉                                                                        | 15/50 [00:01<00:03, 10.80it/s]2025-08-23 15:50:12 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:12 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:12 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:12 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:12 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 11.00 / 17 (64.7%):  32%|████████████████████████████████▉                                                                      | 16/50 [00:01<00:03, 10.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:12 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:12 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 11.00 / 17 (64.7%):  34%|███████████████████████████████████                                                                    | 17/50 [00:01<00:02, 13.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:12 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:12 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 12.00 / 18 (66.7%):  34%|███████████████████████████████████                                                                    | 17/50 [00:01<00:02, 13.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:12 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 19 (63.2%):  36%|█████████████████████████████████████                                                                  | 18/50 [00:01<00:02, 13.80it/s]2025-08-23 15:50:12 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:12 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:12 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 13.00 / 20 (65.0%):  38%|███████████████████████████████████████▏                                                               | 19/50 [00:01<00:02, 13.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:12 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:12 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:12 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:12 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:12 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:12 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 13.00 / 21 (61.9%):  40%|█████████████████████████████████████████▏                                                             | 20/50 [00:01<00:02, 13.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:12 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:12 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 14.00 / 22 (63.6%):  42%|███████████████████████████████████████████▎                                                           | 21/50 [00:01<00:02, 13.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:12 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:12 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:12 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:12 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:12 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 23 (65.2%):  44%|█████████████████████████████████████████████▎                                                         | 22/50 [00:01<00:02, 13.80it/s]2025-08-23 15:50:12 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:12 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:12 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:12 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:12 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:12 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 24 (62.5%):  46%|███████████████████████████████████████████████▍                                                       | 23/50 [00:01<00:01, 13.80it/s]2025-08-23 15:50:12 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:13 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:13 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 25 (64.0%):  48%|█████████████████████████████████████████████████▍                                                     | 24/50 [00:01<00:01, 13.80it/s]2025-08-23 15:50:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 16.00 / 25 (64.0%):  50%|███████████████████████████████████████████████████▌                                                   | 25/50 [00:01<00:01, 15.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:13 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:13 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 26 (65.4%):  50%|███████████████████████████████████████████████████▌                                                   | 25/50 [00:01<00:01, 15.55it/s]2025-08-23 15:50:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:13 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:13 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 27 (63.0%):  52%|█████████████████████████████████████████████████████▌                                                 | 26/50 [00:01<00:01, 15.55it/s]2025-08-23 15:50:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:13 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:13 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 28 (60.7%):  54%|███████████████████████████████████████████████████████▌                                               | 27/50 [00:01<00:01, 15.55it/s]2025-08-23 15:50:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:13 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:13 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 29 (62.1%):  56%|█████████████████████████████████████████████████████████▋                                             | 28/50 [00:01<00:01, 15.55it/s]2025-08-23 15:50:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:13 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:13 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 30 (63.3%):  58%|███████████████████████████████████████████████████████████▋                                           | 29/50 [00:01<00:01, 15.55it/s]2025-08-23 15:50:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:13 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:13 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 31 (61.3%):  60%|█████████████████████████████████████████████████████████████▊                                         | 30/50 [00:01<00:01, 15.55it/s]2025-08-23 15:50:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:13 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:13 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 32 (62.5%):  62%|███████████████████████████████████████████████████████████████▊                                       | 31/50 [00:01<00:01, 15.55it/s]2025-08-23 15:50:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:13 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:13 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 33 (63.6%):  64%|█████████████████████████████████████████████████████████████████▉                                     | 32/50 [00:02<00:01, 15.55it/s]2025-08-23 15:50:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 21.00 / 33 (63.6%):  66%|███████████████████████████████████████████████████████████████████▉                                   | 33/50 [00:02<00:01, 16.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:13 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:13 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:13 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:13 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 22.00 / 34 (64.7%):  66%|███████████████████████████████████████████████████████████████████▉                                   | 33/50 [00:02<00:01, 16.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 22.00 / 35 (62.9%):  68%|██████████████████████████████████████████████████████████████████████                                 | 34/50 [00:02<00:00, 16.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:13 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:13 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 36 (63.9%):  70%|████████████████████████████████████████████████████████████████████████                               | 35/50 [00:02<00:00, 16.49it/s]2025-08-23 15:50:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:13 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:13 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 37 (64.9%):  72%|██████████████████████████████████████████████████████████████████████████▏                            | 36/50 [00:02<00:00, 16.49it/s]2025-08-23 15:50:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:13 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:13 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 38 (63.2%):  74%|████████████████████████████████████████████████████████████████████████████▏                          | 37/50 [00:02<00:00, 16.49it/s]2025-08-23 15:50:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:13 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:13 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.00 / 39 (64.1%):  76%|██████████████████████████████████████████████████████████████████████████████▎                        | 38/50 [00:02<00:00, 16.49it/s]2025-08-23 15:50:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:13 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:13 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:13 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 26.00 / 40 (65.0%):  78%|████████████████████████████████████████████████████████████████████████████████▎                      | 39/50 [00:02<00:00, 16.49it/s]2025-08-23 15:50:13 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:14 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:14 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:14 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27.00 / 41 (65.9%):  80%|██████████████████████████████████████████████████████████████████████████████████▍                    | 40/50 [00:02<00:00, 16.49it/s]2025-08-23 15:50:14 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 27.00 / 41 (65.9%):  82%|████████████████████████████████████████████████████████████████████████████████████▍                  | 41/50 [00:02<00:00, 15.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:14 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:14 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:14 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 28.00 / 42 (66.7%):  82%|████████████████████████████████████████████████████████████████████████████████████▍                  | 41/50 [00:02<00:00, 15.62it/s]2025-08-23 15:50:14 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:14 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:14 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 29.00 / 43 (67.4%):  84%|██████████████████████████████████████████████████████████████████████████████████████▌                | 42/50 [00:02<00:00, 15.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:14 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:14 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 29.00 / 44 (65.9%):  86%|████████████████████████████████████████████████████████████████████████████████████████▌              | 43/50 [00:02<00:00, 15.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:14 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:14 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:14 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 30.00 / 45 (66.7%):  88%|██████████████████████████████████████████████████████████████████████████████████████████▋            | 44/50 [00:02<00:00, 15.62it/s]2025-08-23 15:50:14 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:14 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:14 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 31.00 / 46 (67.4%):  90%|████████████████████████████████████████████████████████████████████████████████████████████▋          | 45/50 [00:02<00:00, 15.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:14 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 32.00 / 47 (68.1%):  92%|██████████████████████████████████████████████████████████████████████████████████████████████▊        | 46/50 [00:02<00:00, 15.62it/s]2025-08-23 15:50:14 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 33.00 / 48 (68.8%):  94%|████████████████████████████████████████████████████████████████████████████████████████████████▊      | 47/50 [00:02<00:00, 15.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:14 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:14 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 34.00 / 49 (69.4%):  98%|████████████████████████████████████████████████████████████████████████████████████████████████████▉  | 49/50 [00:03<00:00, 16.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:14 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:14 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 34.00 / 50 (68.0%): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 14.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/23 15:50:14 INFO dspy.evaluate.evaluate: Average Metric: 34 / 50 (68.0%)\n",
      "2025/08/23 15:50:14 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 68.0 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 0'].\n",
      "2025/08/23 15:50:14 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [66.0, 68.0, 62.0, 62.0, 68.0, 70.0, 70.0, 68.0]\n",
      "2025/08/23 15:50:14 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 70.0\n",
      "2025/08/23 15:50:14 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/08/23 15:50:14 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 9 / 18 =====\n",
      "\u001b[92m15:50:14 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-08-23 15:50:14 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:14 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:14 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:14 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:14 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "  0%|                                                                                                                                                    | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:14 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:14 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:14 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:14 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:14 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:14 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:14 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:14 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:14 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:14 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:15 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:15 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:15 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:15 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 1.00 / 1 (100.0%):   0%|                                                                                                                 | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:15 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:15 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:15 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:50:15 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 1 (100.0%):   2%|██                                                                                                       | 1/50 [00:00<00:27,  1.77it/s]2025-08-23 15:50:15 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 2.00 / 2 (100.0%):   2%|██                                                                                                       | 1/50 [00:00<00:27,  1.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:15 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:15 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 2.00 / 3 (66.7%):   4%|████▏                                                                                                     | 2/50 [00:00<00:27,  1.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:15 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:50:15 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:15 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:15 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:15 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:15 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 4 (75.0%):   6%|██████▎                                                                                                   | 3/50 [00:00<00:26,  1.77it/s]2025-08-23 15:50:15 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:15 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:50:15 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:15 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 3.00 / 5 (60.0%):   8%|████████▍                                                                                                 | 4/50 [00:00<00:26,  1.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:15 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:15 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:15 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 6 (50.0%):  10%|██████████▌                                                                                               | 5/50 [00:00<00:25,  1.77it/s]2025-08-23 15:50:15 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:15 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:15 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 4.00 / 7 (57.1%):  12%|████████████▋                                                                                             | 6/50 [00:00<00:24,  1.77it/s]2025-08-23 15:50:15 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:15 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:15 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 4.00 / 8 (50.0%):  14%|██████████████▊                                                                                           | 7/50 [00:00<00:24,  1.77it/s]2025-08-23 15:50:15 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:50:15 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:15 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:15 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:15 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 9 (55.6%):  16%|████████████████▉                                                                                         | 8/50 [00:01<00:23,  1.77it/s]2025-08-23 15:50:15 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 5.00 / 9 (55.6%):  18%|███████████████████                                                                                       | 9/50 [00:01<00:04,  8.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:15 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:15 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 5.00 / 10 (50.0%):  18%|██████████████████▉                                                                                      | 9/50 [00:01<00:04,  8.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:15 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:15 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:15 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:15 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 5.00 / 11 (45.5%):  20%|████████████████████▊                                                                                   | 10/50 [00:01<00:04,  8.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:15 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:15 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:15 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 12 (41.7%):  22%|██████████████████████▉                                                                                 | 11/50 [00:01<00:04,  8.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:15 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:15 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:15 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:15 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 6.00 / 13 (46.2%):  24%|████████████████████████▉                                                                               | 12/50 [00:01<00:04,  8.59it/s]2025-08-23 15:50:15 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:15 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:15 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 7.00 / 14 (50.0%):  26%|███████████████████████████                                                                             | 13/50 [00:01<00:04,  8.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:15 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:15 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:16 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:16 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 8.00 / 15 (53.3%):  28%|█████████████████████████████                                                                           | 14/50 [00:01<00:04,  8.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 9.00 / 16 (56.2%):  30%|███████████████████████████████▏                                                                        | 15/50 [00:01<00:04,  8.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:16 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:16 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 10.00 / 17 (58.8%):  32%|████████████████████████████████▉                                                                      | 16/50 [00:01<00:03,  8.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:50:16 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 10.00 / 17 (58.8%):  34%|███████████████████████████████████                                                                    | 17/50 [00:01<00:02, 11.48it/s]2025-08-23 15:50:16 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 18 (55.6%):  34%|███████████████████████████████████                                                                    | 17/50 [00:01<00:02, 11.48it/s]2025-08-23 15:50:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:16 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:16 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:16 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:16 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 10.00 / 19 (52.6%):  36%|█████████████████████████████████████                                                                  | 18/50 [00:01<00:02, 11.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 10.00 / 20 (50.0%):  38%|███████████████████████████████████████▏                                                               | 19/50 [00:01<00:02, 11.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:16 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:16 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 11.00 / 21 (52.4%):  40%|█████████████████████████████████████████▏                                                             | 20/50 [00:01<00:02, 11.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:16 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:16 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 22 (54.5%):  42%|███████████████████████████████████████████▎                                                           | 21/50 [00:01<00:02, 11.48it/s]2025-08-23 15:50:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:16 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:16 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 23 (52.2%):  44%|█████████████████████████████████████████████▎                                                         | 22/50 [00:01<00:02, 11.48it/s]2025-08-23 15:50:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:16 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:16 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 24 (54.2%):  46%|███████████████████████████████████████████████▍                                                       | 23/50 [00:01<00:02, 11.48it/s]2025-08-23 15:50:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:16 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:16 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 14.00 / 25 (56.0%):  50%|███████████████████████████████████████████████████▌                                                   | 25/50 [00:02<00:01, 13.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:16 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:16 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 26 (57.7%):  50%|███████████████████████████████████████████████████▌                                                   | 25/50 [00:02<00:01, 13.72it/s]2025-08-23 15:50:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:16 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:16 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 27 (59.3%):  52%|█████████████████████████████████████████████████████▌                                                 | 26/50 [00:02<00:01, 13.72it/s]2025-08-23 15:50:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:16 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:16 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:16 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 28 (60.7%):  54%|███████████████████████████████████████████████████████▌                                               | 27/50 [00:02<00:01, 13.72it/s]2025-08-23 15:50:16 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 29 (58.6%):  56%|█████████████████████████████████████████████████████████▋                                             | 28/50 [00:02<00:01, 13.72it/s]2025-08-23 15:50:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 30 (60.0%):  58%|███████████████████████████████████████████████████████████▋                                           | 29/50 [00:02<00:01, 13.72it/s]2025-08-23 15:50:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 31 (58.1%):  60%|█████████████████████████████████████████████████████████████▊                                         | 30/50 [00:02<00:01, 13.72it/s]2025-08-23 15:50:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 18.00 / 31 (58.1%):  62%|███████████████████████████████████████████████████████████████▊                                       | 31/50 [00:02<00:01, 17.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 19.00 / 32 (59.4%):  62%|███████████████████████████████████████████████████████████████▊                                       | 31/50 [00:02<00:01, 17.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 33 (57.6%):  64%|█████████████████████████████████████████████████████████████████▉                                     | 32/50 [00:02<00:01, 17.68it/s]2025-08-23 15:50:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 34 (55.9%):  66%|███████████████████████████████████████████████████████████████████▉                                   | 33/50 [00:02<00:00, 17.68it/s]2025-08-23 15:50:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 19.00 / 34 (55.9%):  68%|██████████████████████████████████████████████████████████████████████                                 | 34/50 [00:02<00:01, 14.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 35 (57.1%):  68%|██████████████████████████████████████████████████████████████████████                                 | 34/50 [00:02<00:01, 14.96it/s]2025-08-23 15:50:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 20.00 / 36 (55.6%):  70%|████████████████████████████████████████████████████████████████████████                               | 35/50 [00:02<00:01, 14.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:50:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 21.00 / 37 (56.8%):  72%|██████████████████████████████████████████████████████████████████████████▏                            | 36/50 [00:02<00:01, 13.92it/s]2025-08-23 15:50:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 38 (57.9%):  74%|████████████████████████████████████████████████████████████████████████████▏                          | 37/50 [00:02<00:00, 13.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:50:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 39 (59.0%):  76%|██████████████████████████████████████████████████████████████████████████████▎                        | 38/50 [00:02<00:00, 13.92it/s]2025-08-23 15:50:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 40 (57.5%):  78%|████████████████████████████████████████████████████████████████████████████████▎                      | 39/50 [00:02<00:00, 13.92it/s]2025-08-23 15:50:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 23.00 / 40 (57.5%):  80%|██████████████████████████████████████████████████████████████████████████████████▍                    | 40/50 [00:03<00:00, 15.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 24.00 / 41 (58.5%):  80%|██████████████████████████████████████████████████████████████████████████████████▍                    | 40/50 [00:03<00:00, 15.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:17 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.00 / 42 (59.5%):  82%|████████████████████████████████████████████████████████████████████████████████████▍                  | 41/50 [00:03<00:00, 15.53it/s]2025-08-23 15:50:17 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 25.00 / 42 (59.5%):  84%|██████████████████████████████████████████████████████████████████████████████████████▌                | 42/50 [00:03<00:00, 15.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:17 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:17 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 26.00 / 43 (60.5%):  84%|██████████████████████████████████████████████████████████████████████████████████████▌                | 42/50 [00:03<00:00, 15.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27.00 / 44 (61.4%):  86%|████████████████████████████████████████████████████████████████████████████████████████▌              | 43/50 [00:03<00:00, 15.66it/s]2025-08-23 15:50:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 28.00 / 45 (62.2%):  88%|██████████████████████████████████████████████████████████████████████████████████████████▋            | 44/50 [00:03<00:00, 14.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 28.00 / 46 (60.9%):  90%|████████████████████████████████████████████████████████████████████████████████████████████▋          | 45/50 [00:03<00:00, 14.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 28.00 / 47 (59.6%):  92%|██████████████████████████████████████████████████████████████████████████████████████████████▊        | 46/50 [00:03<00:00, 14.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 29.00 / 48 (60.4%):  96%|██████████████████████████████████████████████████████████████████████████████████████████████████▉    | 48/50 [00:03<00:00, 17.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 30.00 / 49 (61.2%):  96%|██████████████████████████████████████████████████████████████████████████████████████████████████▉    | 48/50 [00:03<00:00, 17.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 31.00 / 50 (62.0%): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 13.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/23 15:50:18 INFO dspy.evaluate.evaluate: Average Metric: 31 / 50 (62.0%)\n",
      "2025/08/23 15:50:18 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 62.0 with parameters ['Predictor 0: Instruction 3', 'Predictor 0: Few-Shot Set 1'].\n",
      "2025/08/23 15:50:18 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [66.0, 68.0, 62.0, 62.0, 68.0, 70.0, 70.0, 68.0, 62.0]\n",
      "2025/08/23 15:50:18 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 70.0\n",
      "2025/08/23 15:50:18 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/08/23 15:50:18 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 10 / 18 =====\n",
      "\u001b[92m15:50:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-08-23 15:50:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:50:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:50:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                    | 0/50 [00:00<?, ?it/s]2025-08-23 15:50:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 1 (0.0%):   0%|                                                                                                                   | 0/50 [00:00<?, ?it/s]2025-08-23 15:50:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 0.00 / 1 (0.0%):   2%|██▏                                                                                                        | 1/50 [00:00<00:21,  2.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 1.00 / 2 (50.0%):   2%|██                                                                                                        | 1/50 [00:00<00:21,  2.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 1.00 / 3 (33.3%):   4%|████▏                                                                                                     | 2/50 [00:00<00:20,  2.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 2.00 / 4 (50.0%):   6%|██████▎                                                                                                   | 3/50 [00:00<00:20,  2.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:18 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:18 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 2.00 / 5 (40.0%):   8%|████████▍                                                                                                 | 4/50 [00:00<00:19,  2.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 3.00 / 6 (50.0%):  10%|██████████▌                                                                                               | 5/50 [00:00<00:19,  2.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:18 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:18 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:19 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:19 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:19 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 7 (42.9%):  12%|████████████▋                                                                                             | 6/50 [00:00<00:18,  2.33it/s]2025-08-23 15:50:19 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:19 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:19 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 4.00 / 8 (50.0%):  14%|██████████████▊                                                                                           | 7/50 [00:00<00:18,  2.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:19 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:19 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:19 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:19 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:19 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:19 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 5.00 / 9 (55.6%):  16%|████████████████▉                                                                                         | 8/50 [00:00<00:18,  2.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:19 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:19 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 5.00 / 9 (55.6%):  18%|███████████████████                                                                                       | 9/50 [00:00<00:03, 11.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:19 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:19 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 5.00 / 10 (50.0%):  18%|██████████████████▉                                                                                      | 9/50 [00:00<00:03, 11.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:19 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:19 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:19 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 11 (45.5%):  20%|████████████████████▊                                                                                   | 10/50 [00:00<00:03, 11.62it/s]2025-08-23 15:50:19 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:19 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:19 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:19 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 12 (41.7%):  22%|██████████████████████▉                                                                                 | 11/50 [00:00<00:03, 11.62it/s]2025-08-23 15:50:19 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:19 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:19 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:19 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 13 (46.2%):  24%|████████████████████████▉                                                                               | 12/50 [00:00<00:03, 11.62it/s]2025-08-23 15:50:19 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:19 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:19 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:19 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:19 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 7.00 / 14 (50.0%):  26%|███████████████████████████                                                                             | 13/50 [00:00<00:03, 11.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:19 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:19 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 8.00 / 15 (53.3%):  28%|█████████████████████████████                                                                           | 14/50 [00:00<00:03, 11.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:19 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:19 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:19 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:19 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:19 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 16 (56.2%):  30%|███████████████████████████████▏                                                                        | 15/50 [00:00<00:03, 11.62it/s]2025-08-23 15:50:19 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 9.00 / 16 (56.2%):  32%|█████████████████████████████████▎                                                                      | 16/50 [00:00<00:01, 20.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:19 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:19 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:19 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 17 (58.8%):  32%|████████████████████████████████▉                                                                      | 16/50 [00:01<00:01, 20.70it/s]2025-08-23 15:50:19 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:19 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:50:19 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:19 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 11.00 / 18 (61.1%):  34%|███████████████████████████████████                                                                    | 17/50 [00:01<00:01, 20.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:19 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:19 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 12.00 / 19 (63.2%):  36%|█████████████████████████████████████                                                                  | 18/50 [00:01<00:01, 20.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:19 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:19 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 12.00 / 20 (60.0%):  40%|█████████████████████████████████████████▏                                                             | 20/50 [00:01<00:01, 16.01it/s]2025-08-23 15:50:19 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:19 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:50:19 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:19 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:19 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:19 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 13.00 / 21 (61.9%):  40%|█████████████████████████████████████████▏                                                             | 20/50 [00:01<00:01, 16.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:19 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:19 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:19 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:19 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:50:19 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 14.00 / 22 (63.6%):  42%|███████████████████████████████████████████▎                                                           | 21/50 [00:01<00:01, 16.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:19 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:19 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:19 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:19 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 15.00 / 23 (65.2%):  44%|█████████████████████████████████████████████▎                                                         | 22/50 [00:01<00:01, 16.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:19 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:19 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:19 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:19 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:19 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 24 (62.5%):  46%|███████████████████████████████████████████████▍                                                       | 23/50 [00:01<00:01, 16.01it/s]2025-08-23 15:50:19 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:20 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:20 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:20 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 25 (64.0%):  48%|█████████████████████████████████████████████████▍                                                     | 24/50 [00:01<00:01, 16.01it/s]2025-08-23 15:50:20 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:20 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 25 (64.0%):  50%|███████████████████████████████████████████████████▌                                                   | 25/50 [00:01<00:01, 13.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:20 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 26 (61.5%):  50%|███████████████████████████████████████████████████▌                                                   | 25/50 [00:01<00:01, 13.33it/s]2025-08-23 15:50:20 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:20 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:20 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:20 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 27 (59.3%):  52%|█████████████████████████████████████████████████████▌                                                 | 26/50 [00:01<00:01, 13.33it/s]2025-08-23 15:50:20 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:20 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:20 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 16.00 / 28 (57.1%):  54%|███████████████████████████████████████████████████████▌                                               | 27/50 [00:01<00:01, 13.33it/s]2025-08-23 15:50:20 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:20 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 29 (58.6%):  56%|█████████████████████████████████████████████████████████▋                                             | 28/50 [00:01<00:01, 13.33it/s]2025-08-23 15:50:20 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:20 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:50:20 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:20 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:50:20 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 18.00 / 30 (60.0%):  58%|███████████████████████████████████████████████████████████▋                                           | 29/50 [00:01<00:01, 13.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:20 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:20 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:20 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:20 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 19.00 / 31 (61.3%):  60%|█████████████████████████████████████████████████████████████▊                                         | 30/50 [00:01<00:01, 13.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:20 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:50:20 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:20 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:50:20 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:20 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:20 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:20 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 32 (62.5%):  62%|███████████████████████████████████████████████████████████████▊                                       | 31/50 [00:01<00:01, 13.33it/s]2025-08-23 15:50:20 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:20 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:20 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 21.00 / 33 (63.6%):  64%|█████████████████████████████████████████████████████████████████▉                                     | 32/50 [00:02<00:01, 13.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:20 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 33 (63.6%):  66%|███████████████████████████████████████████████████████████████████▉                                   | 33/50 [00:02<00:01, 15.03it/s]2025-08-23 15:50:20 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:20 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:20 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:20 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 34 (64.7%):  66%|███████████████████████████████████████████████████████████████████▉                                   | 33/50 [00:02<00:01, 15.03it/s]2025-08-23 15:50:20 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:20 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:20 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 23.00 / 35 (65.7%):  68%|██████████████████████████████████████████████████████████████████████                                 | 34/50 [00:02<00:01, 15.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:20 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:20 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:20 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:20 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:20 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 36 (66.7%):  70%|████████████████████████████████████████████████████████████████████████                               | 35/50 [00:02<00:00, 15.03it/s]2025-08-23 15:50:20 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:20 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:20 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:20 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.00 / 37 (67.6%):  72%|██████████████████████████████████████████████████████████████████████████▏                            | 36/50 [00:02<00:00, 15.03it/s]2025-08-23 15:50:20 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:20 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:20 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:20 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.00 / 38 (65.8%):  74%|████████████████████████████████████████████████████████████████████████████▏                          | 37/50 [00:02<00:00, 15.03it/s]2025-08-23 15:50:20 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:20 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 26.00 / 39 (66.7%):  76%|██████████████████████████████████████████████████████████████████████████████▎                        | 38/50 [00:02<00:00, 15.03it/s]2025-08-23 15:50:20 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:20 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:20 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:20 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:20 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:20 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 26.00 / 40 (65.0%):  78%|████████████████████████████████████████████████████████████████████████████████▎                      | 39/50 [00:02<00:00, 15.03it/s]2025-08-23 15:50:20 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:21 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:21 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:21 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27.00 / 41 (65.9%):  80%|██████████████████████████████████████████████████████████████████████████████████▍                    | 40/50 [00:02<00:00, 15.03it/s]2025-08-23 15:50:21 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:21 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27.00 / 41 (65.9%):  82%|████████████████████████████████████████████████████████████████████████████████████▍                  | 41/50 [00:02<00:00, 15.92it/s]2025-08-23 15:50:21 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:21 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 28.00 / 42 (66.7%):  82%|████████████████████████████████████████████████████████████████████████████████████▍                  | 41/50 [00:02<00:00, 15.92it/s]2025-08-23 15:50:21 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:21 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:21 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:21 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:21 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 30.00 / 44 (68.2%):  86%|████████████████████████████████████████████████████████████████████████████████████████▌              | 43/50 [00:02<00:00, 15.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:21 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:21 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:21 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 31.00 / 45 (68.9%):  88%|██████████████████████████████████████████████████████████████████████████████████████████▋            | 44/50 [00:02<00:00, 15.92it/s]2025-08-23 15:50:21 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 32.00 / 46 (69.6%):  90%|████████████████████████████████████████████████████████████████████████████████████████████▋          | 45/50 [00:02<00:00, 15.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:21 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:21 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:21 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:21 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 33.00 / 48 (68.8%):  94%|████████████████████████████████████████████████████████████████████████████████████████████████▊      | 47/50 [00:02<00:00, 20.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:21 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:21 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 33.00 / 49 (67.3%):  96%|██████████████████████████████████████████████████████████████████████████████████████████████████▉    | 48/50 [00:03<00:00, 20.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:21 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:21 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 34.00 / 50 (68.0%): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 15.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/23 15:50:21 INFO dspy.evaluate.evaluate: Average Metric: 34 / 50 (68.0%)\n",
      "2025/08/23 15:50:21 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 68.0 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 7'].\n",
      "2025/08/23 15:50:21 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [66.0, 68.0, 62.0, 62.0, 68.0, 70.0, 70.0, 68.0, 62.0, 68.0]\n",
      "2025/08/23 15:50:21 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 70.0\n",
      "2025/08/23 15:50:21 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/08/23 15:50:21 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 11 / 18 =====\n",
      "\u001b[92m15:50:21 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-08-23 15:50:21 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:21 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:50:21 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:21 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:50:21 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "  0%|                                                                                                                                                    | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:21 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:21 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:21 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:21 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:21 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:21 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:21 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:21 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:21 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:21 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:22 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 1 (0.0%):   0%|                                                                                                                   | 0/50 [00:00<?, ?it/s]2025-08-23 15:50:22 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 0.00 / 1 (0.0%):   2%|██▏                                                                                                        | 1/50 [00:00<00:22,  2.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:22 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 2 (50.0%):   2%|██                                                                                                        | 1/50 [00:00<00:22,  2.16it/s]2025-08-23 15:50:22 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:22 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 3 (66.7%):   4%|████▏                                                                                                     | 2/50 [00:00<00:22,  2.16it/s]2025-08-23 15:50:22 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:22 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 4 (75.0%):   6%|██████▎                                                                                                   | 3/50 [00:00<00:21,  2.16it/s]2025-08-23 15:50:22 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:22 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 5 (80.0%):   8%|████████▍                                                                                                 | 4/50 [00:00<00:21,  2.16it/s]2025-08-23 15:50:22 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:22 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 6 (83.3%):  10%|██████████▌                                                                                               | 5/50 [00:00<00:20,  2.16it/s]2025-08-23 15:50:22 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:22 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 7 (71.4%):  12%|████████████▋                                                                                             | 6/50 [00:00<00:20,  2.16it/s]2025-08-23 15:50:22 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:22 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 8 (62.5%):  14%|██████████████▊                                                                                           | 7/50 [00:00<00:19,  2.16it/s]2025-08-23 15:50:22 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 5.00 / 8 (62.5%):  16%|████████████████▉                                                                                         | 8/50 [00:00<00:02, 16.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 9 (55.6%):  16%|████████████████▉                                                                                         | 8/50 [00:01<00:02, 16.22it/s]2025-08-23 15:50:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:22 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 10 (60.0%):  18%|██████████████████▉                                                                                      | 9/50 [00:01<00:02, 16.22it/s]2025-08-23 15:50:22 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:22 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:22 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 7.00 / 11 (63.6%):  20%|████████████████████▊                                                                                   | 10/50 [00:01<00:02, 16.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 7.00 / 11 (63.6%):  22%|██████████████████████▉                                                                                 | 11/50 [00:01<00:03, 10.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 7.00 / 12 (58.3%):  22%|██████████████████████▉                                                                                 | 11/50 [00:01<00:03, 10.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:22 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:22 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 8.00 / 13 (61.5%):  24%|████████████████████████▉                                                                               | 12/50 [00:01<00:03, 10.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:22 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:50:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:22 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 8.00 / 14 (57.1%):  26%|███████████████████████████                                                                             | 13/50 [00:01<00:03, 10.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:22 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:22 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:22 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 9.00 / 15 (60.0%):  28%|█████████████████████████████                                                                           | 14/50 [00:01<00:03, 10.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:22 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:22 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:22 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:50:22 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:22 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 9.00 / 16 (56.2%):  30%|███████████████████████████████▏                                                                        | 15/50 [00:01<00:03, 10.76it/s]2025-08-23 15:50:22 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:50:22 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:23 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:23 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 17 (58.8%):  32%|████████████████████████████████▉                                                                      | 16/50 [00:01<00:03, 10.76it/s]2025-08-23 15:50:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 10.00 / 17 (58.8%):  34%|███████████████████████████████████                                                                    | 17/50 [00:01<00:02, 11.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:23 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:23 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 11.00 / 18 (61.1%):  34%|███████████████████████████████████                                                                    | 17/50 [00:01<00:02, 11.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:23 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:23 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 19 (57.9%):  36%|█████████████████████████████████████                                                                  | 18/50 [00:01<00:02, 11.94it/s]2025-08-23 15:50:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:23 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:23 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 20 (60.0%):  38%|███████████████████████████████████████▏                                                               | 19/50 [00:01<00:02, 11.94it/s]2025-08-23 15:50:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:23 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:23 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 21 (61.9%):  40%|█████████████████████████████████████████▏                                                             | 20/50 [00:01<00:02, 11.94it/s]2025-08-23 15:50:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:23 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:23 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 22 (59.1%):  42%|███████████████████████████████████████████▎                                                           | 21/50 [00:01<00:02, 11.94it/s]2025-08-23 15:50:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:23 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:23 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 23 (56.5%):  44%|█████████████████████████████████████████████▎                                                         | 22/50 [00:01<00:02, 11.94it/s]2025-08-23 15:50:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:23 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:23 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 24 (58.3%):  46%|███████████████████████████████████████████████▍                                                       | 23/50 [00:01<00:02, 11.94it/s]2025-08-23 15:50:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 14.00 / 24 (58.3%):  48%|█████████████████████████████████████████████████▍                                                     | 24/50 [00:01<00:01, 17.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:23 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:23 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 15.00 / 25 (60.0%):  48%|█████████████████████████████████████████████████▍                                                     | 24/50 [00:02<00:01, 17.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:23 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:23 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 26 (61.5%):  50%|███████████████████████████████████████████████████▌                                                   | 25/50 [00:02<00:01, 17.92it/s]2025-08-23 15:50:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:23 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:23 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 27 (63.0%):  52%|█████████████████████████████████████████████████████▌                                                 | 26/50 [00:02<00:01, 17.92it/s]2025-08-23 15:50:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 17.00 / 27 (63.0%):  54%|███████████████████████████████████████████████████████▌                                               | 27/50 [00:02<00:01, 14.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:23 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:23 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 28 (60.7%):  54%|███████████████████████████████████████████████████████▌                                               | 27/50 [00:02<00:01, 14.02it/s]2025-08-23 15:50:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:23 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:23 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 29 (58.6%):  56%|█████████████████████████████████████████████████████████▋                                             | 28/50 [00:02<00:01, 14.02it/s]2025-08-23 15:50:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:23 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:23 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 30 (60.0%):  58%|███████████████████████████████████████████████████████████▋                                           | 29/50 [00:02<00:01, 14.02it/s]2025-08-23 15:50:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:23 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:23 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 31 (61.3%):  60%|█████████████████████████████████████████████████████████████▊                                         | 30/50 [00:02<00:01, 14.02it/s]2025-08-23 15:50:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:23 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:23 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:23 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:23 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 20.00 / 32 (62.5%):  64%|█████████████████████████████████████████████████████████████████▉                                     | 32/50 [00:02<00:00, 18.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:24 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 33 (60.6%):  64%|█████████████████████████████████████████████████████████████████▉                                     | 32/50 [00:02<00:00, 18.53it/s]2025-08-23 15:50:24 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:24 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 34 (61.8%):  66%|███████████████████████████████████████████████████████████████████▉                                   | 33/50 [00:02<00:00, 18.53it/s]2025-08-23 15:50:24 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 22.00 / 35 (62.9%):  68%|██████████████████████████████████████████████████████████████████████                                 | 34/50 [00:02<00:00, 18.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 22.00 / 35 (62.9%):  70%|████████████████████████████████████████████████████████████████████████                               | 35/50 [00:02<00:01, 13.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:24 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 36 (63.9%):  70%|████████████████████████████████████████████████████████████████████████                               | 35/50 [00:02<00:01, 13.82it/s]2025-08-23 15:50:24 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:24 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 37 (62.2%):  72%|██████████████████████████████████████████████████████████████████████████▏                            | 36/50 [00:02<00:01, 13.82it/s]2025-08-23 15:50:24 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:24 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:24 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:24 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 38 (63.2%):  74%|████████████████████████████████████████████████████████████████████████████▏                          | 37/50 [00:02<00:00, 13.82it/s]2025-08-23 15:50:24 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:24 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.00 / 39 (64.1%):  76%|██████████████████████████████████████████████████████████████████████████████▎                        | 38/50 [00:02<00:00, 13.82it/s]2025-08-23 15:50:24 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:24 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 26.00 / 40 (65.0%):  78%|████████████████████████████████████████████████████████████████████████████████▎                      | 39/50 [00:02<00:00, 13.82it/s]2025-08-23 15:50:24 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 27.00 / 41 (65.9%):  80%|██████████████████████████████████████████████████████████████████████████████████▍                    | 40/50 [00:02<00:00, 13.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:24 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27.00 / 41 (65.9%):  82%|████████████████████████████████████████████████████████████████████████████████████▍                  | 41/50 [00:02<00:00, 14.12it/s]2025-08-23 15:50:24 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:24 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27.00 / 42 (64.3%):  82%|████████████████████████████████████████████████████████████████████████████████████▍                  | 41/50 [00:03<00:00, 14.12it/s]2025-08-23 15:50:24 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 28.00 / 43 (65.1%):  86%|████████████████████████████████████████████████████████████████████████████████████████▌              | 43/50 [00:03<00:00, 14.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 29.00 / 44 (65.9%):  86%|████████████████████████████████████████████████████████████████████████████████████████▌              | 43/50 [00:03<00:00, 14.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 30.00 / 45 (66.7%):  88%|██████████████████████████████████████████████████████████████████████████████████████████▋            | 44/50 [00:03<00:00, 14.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 31.00 / 46 (67.4%):  90%|████████████████████████████████████████████████████████████████████████████████████████████▋          | 45/50 [00:03<00:00, 14.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 32.00 / 47 (68.1%):  92%|██████████████████████████████████████████████████████████████████████████████████████████████▊        | 46/50 [00:03<00:00, 14.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:24 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:24 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 33.00 / 48 (68.8%):  94%|████████████████████████████████████████████████████████████████████████████████████████████████▊      | 47/50 [00:03<00:00, 14.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:25 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:25 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 34.00 / 49 (69.4%):  98%|████████████████████████████████████████████████████████████████████████████████████████████████████▉  | 49/50 [00:03<00:00, 15.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:25 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:25 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 35.00 / 50 (70.0%): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 14.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/23 15:50:25 INFO dspy.evaluate.evaluate: Average Metric: 35 / 50 (70.0%)\n",
      "2025/08/23 15:50:25 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 70.0 with parameters ['Predictor 0: Instruction 4', 'Predictor 0: Few-Shot Set 6'].\n",
      "2025/08/23 15:50:25 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [66.0, 68.0, 62.0, 62.0, 68.0, 70.0, 70.0, 68.0, 62.0, 68.0, 70.0]\n",
      "2025/08/23 15:50:25 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 70.0\n",
      "2025/08/23 15:50:25 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/08/23 15:50:25 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 12 / 18 =====\n",
      "\u001b[92m15:50:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-08-23 15:50:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:50:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:50:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "  0%|                                                                                                                                                    | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:25 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:25 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 1 (100.0%):   0%|                                                                                                                 | 0/50 [00:00<?, ?it/s]2025-08-23 15:50:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:25 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 1 (100.0%):   2%|██                                                                                                       | 1/50 [00:00<00:22,  2.16it/s]2025-08-23 15:50:25 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:25 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:25 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 2.00 / 2 (100.0%):   2%|██                                                                                                       | 1/50 [00:00<00:22,  2.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 3 (66.7%):   4%|████▏                                                                                                     | 2/50 [00:00<00:22,  2.16it/s]2025-08-23 15:50:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:25 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:25 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 4 (50.0%):   6%|██████▎                                                                                                   | 3/50 [00:00<00:21,  2.16it/s]2025-08-23 15:50:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:25 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:25 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 5 (40.0%):   8%|████████▍                                                                                                 | 4/50 [00:00<00:21,  2.16it/s]2025-08-23 15:50:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:25 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:25 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 6 (50.0%):  10%|██████████▌                                                                                               | 5/50 [00:00<00:20,  2.16it/s]2025-08-23 15:50:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:25 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:25 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:25 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 7 (42.9%):  12%|████████████▋                                                                                             | 6/50 [00:00<00:20,  2.16it/s]2025-08-23 15:50:25 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 4.00 / 8 (50.0%):  14%|██████████████▊                                                                                           | 7/50 [00:00<00:19,  2.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:25 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:25 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:26 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:26 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:26 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 9 (44.4%):  16%|████████████████▉                                                                                         | 8/50 [00:01<00:19,  2.16it/s]2025-08-23 15:50:26 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:26 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 9 (44.4%):  18%|███████████████████                                                                                       | 9/50 [00:01<00:04,  9.47it/s]2025-08-23 15:50:26 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 5.00 / 10 (50.0%):  18%|██████████████████▉                                                                                      | 9/50 [00:01<00:04,  9.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:26 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:26 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:26 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 11 (45.5%):  20%|████████████████████▊                                                                                   | 10/50 [00:01<00:04,  9.47it/s]2025-08-23 15:50:26 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:26 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:26 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:26 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:26 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 6.00 / 12 (50.0%):  22%|██████████████████████▉                                                                                 | 11/50 [00:01<00:04,  9.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:26 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:26 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 7.00 / 13 (53.8%):  24%|████████████████████████▉                                                                               | 12/50 [00:01<00:04,  9.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:26 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:26 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:26 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:26 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 7.00 / 14 (50.0%):  26%|███████████████████████████                                                                             | 13/50 [00:01<00:03,  9.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:26 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:26 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:26 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 15 (53.3%):  28%|█████████████████████████████                                                                           | 14/50 [00:01<00:03,  9.47it/s]2025-08-23 15:50:26 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:26 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:26 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:26 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:26 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 9.00 / 16 (56.2%):  30%|███████████████████████████████▏                                                                        | 15/50 [00:01<00:03,  9.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:26 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:26 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:26 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:26 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:26 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:26 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:26 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 17 (58.8%):  32%|████████████████████████████████▉                                                                      | 16/50 [00:01<00:03,  9.47it/s]2025-08-23 15:50:26 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:26 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 17 (58.8%):  34%|███████████████████████████████████                                                                    | 17/50 [00:01<00:02, 12.23it/s]2025-08-23 15:50:26 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 10.00 / 18 (55.6%):  34%|███████████████████████████████████                                                                    | 17/50 [00:01<00:02, 12.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:26 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:26 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:26 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 19 (52.6%):  36%|█████████████████████████████████████                                                                  | 18/50 [00:01<00:02, 12.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:26 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:50:26 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:26 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:26 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:26 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 11.00 / 20 (55.0%):  38%|███████████████████████████████████████▏                                                               | 19/50 [00:01<00:02, 12.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:26 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:26 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 12.00 / 21 (57.1%):  40%|█████████████████████████████████████████▏                                                             | 20/50 [00:01<00:02, 12.23it/s]2025-08-23 15:50:26 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:26 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:50:26 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:26 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:26 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 22 (59.1%):  42%|███████████████████████████████████████████▎                                                           | 21/50 [00:01<00:02, 12.23it/s]2025-08-23 15:50:26 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:26 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:26 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:50:26 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:50:26 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 14.00 / 23 (60.9%):  44%|█████████████████████████████████████████████▎                                                         | 22/50 [00:01<00:02, 12.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:26 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:26 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:26 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:26 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:26 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 24 (62.5%):  46%|███████████████████████████████████████████████▍                                                       | 23/50 [00:01<00:02, 12.23it/s]2025-08-23 15:50:26 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:27 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:27 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:27 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 25 (60.0%):  48%|█████████████████████████████████████████████████▍                                                     | 24/50 [00:02<00:02, 12.23it/s]2025-08-23 15:50:27 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 15.00 / 25 (60.0%):  50%|███████████████████████████████████████████████████▌                                                   | 25/50 [00:02<00:01, 13.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:27 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:27 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:27 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:27 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 16.00 / 26 (61.5%):  50%|███████████████████████████████████████████████████▌                                                   | 25/50 [00:02<00:01, 13.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:27 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:50:27 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:27 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 17.00 / 27 (63.0%):  52%|█████████████████████████████████████████████████████▌                                                 | 26/50 [00:02<00:01, 13.89it/s]2025-08-23 15:50:27 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:27 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:50:27 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:50:27 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:27 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 17.00 / 28 (60.7%):  54%|███████████████████████████████████████████████████████▌                                               | 27/50 [00:02<00:01, 13.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:27 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:27 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 18.00 / 29 (62.1%):  56%|█████████████████████████████████████████████████████████▋                                             | 28/50 [00:02<00:01, 13.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:27 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:27 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:50:27 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 19.00 / 30 (63.3%):  58%|███████████████████████████████████████████████████████████▋                                           | 29/50 [00:02<00:01, 13.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:27 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:50:27 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:27 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:50:27 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:27 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 31 (61.3%):  60%|█████████████████████████████████████████████████████████████▊                                         | 30/50 [00:02<00:01, 13.89it/s]2025-08-23 15:50:27 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:50:27 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:27 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:27 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:27 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 32 (59.4%):  62%|███████████████████████████████████████████████████████████████▊                                       | 31/50 [00:02<00:01, 13.89it/s]2025-08-23 15:50:27 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:27 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:27 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:27 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 33 (57.6%):  64%|█████████████████████████████████████████████████████████████████▉                                     | 32/50 [00:02<00:01, 13.89it/s]2025-08-23 15:50:27 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 19.00 / 33 (57.6%):  66%|███████████████████████████████████████████████████████████████████▉                                   | 33/50 [00:02<00:01, 15.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:27 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:27 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:27 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 34 (58.8%):  66%|███████████████████████████████████████████████████████████████████▉                                   | 33/50 [00:02<00:01, 15.33it/s]2025-08-23 15:50:27 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:27 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:27 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:27 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 35 (60.0%):  68%|██████████████████████████████████████████████████████████████████████                                 | 34/50 [00:02<00:01, 15.33it/s]2025-08-23 15:50:27 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 21.00 / 35 (60.0%):  70%|████████████████████████████████████████████████████████████████████████                               | 35/50 [00:02<00:00, 15.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:27 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:27 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 22.00 / 36 (61.1%):  70%|████████████████████████████████████████████████████████████████████████                               | 35/50 [00:02<00:00, 15.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:27 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:27 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:28 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:28 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:28 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 37 (62.2%):  72%|██████████████████████████████████████████████████████████████████████████▏                            | 36/50 [00:02<00:00, 15.58it/s]2025-08-23 15:50:28 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:28 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:28 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:28 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 38 (63.2%):  74%|████████████████████████████████████████████████████████████████████████████▏                          | 37/50 [00:02<00:00, 15.58it/s]2025-08-23 15:50:28 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:28 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:28 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:28 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.00 / 39 (64.1%):  76%|██████████████████████████████████████████████████████████████████████████████▎                        | 38/50 [00:02<00:00, 15.58it/s]2025-08-23 15:50:28 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:28 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:28 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:28 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 26.00 / 40 (65.0%):  78%|████████████████████████████████████████████████████████████████████████████████▎                      | 39/50 [00:02<00:00, 15.58it/s]2025-08-23 15:50:28 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 26.00 / 40 (65.0%):  80%|██████████████████████████████████████████████████████████████████████████████████▍                    | 40/50 [00:02<00:00, 19.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:28 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:28 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 27.00 / 41 (65.9%):  80%|██████████████████████████████████████████████████████████████████████████████████▍                    | 40/50 [00:02<00:00, 19.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:28 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:28 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:28 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:28 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 28.00 / 42 (66.7%):  82%|████████████████████████████████████████████████████████████████████████████████████▍                  | 41/50 [00:03<00:00, 19.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:28 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:28 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:28 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:28 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 29.00 / 43 (67.4%):  86%|████████████████████████████████████████████████████████████████████████████████████████▌              | 43/50 [00:03<00:00, 14.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:28 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:28 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 30.00 / 44 (68.2%):  86%|████████████████████████████████████████████████████████████████████████████████████████▌              | 43/50 [00:03<00:00, 14.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:28 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:28 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 31.00 / 45 (68.9%):  88%|██████████████████████████████████████████████████████████████████████████████████████████▋            | 44/50 [00:03<00:00, 14.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:28 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:28 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:28 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:28 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 32.00 / 47 (68.1%):  92%|██████████████████████████████████████████████████████████████████████████████████████████████▊        | 46/50 [00:03<00:00, 14.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:28 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:28 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 33.00 / 48 (68.8%):  94%|████████████████████████████████████████████████████████████████████████████████████████████████▊      | 47/50 [00:03<00:00, 14.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:28 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:28 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 33.00 / 49 (67.3%):  98%|████████████████████████████████████████████████████████████████████████████████████████████████████▉  | 49/50 [00:03<00:00, 15.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:28 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:28 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 34.00 / 50 (68.0%): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 13.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/23 15:50:29 INFO dspy.evaluate.evaluate: Average Metric: 34 / 50 (68.0%)\n",
      "2025/08/23 15:50:29 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 68.0 with parameters ['Predictor 0: Instruction 4', 'Predictor 0: Few-Shot Set 8'].\n",
      "2025/08/23 15:50:29 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [66.0, 68.0, 62.0, 62.0, 68.0, 70.0, 70.0, 68.0, 62.0, 68.0, 70.0, 68.0]\n",
      "2025/08/23 15:50:29 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 70.0\n",
      "2025/08/23 15:50:29 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/08/23 15:50:29 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 13 / 18 =====\n",
      "\u001b[92m15:50:29 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-08-23 15:50:29 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:29 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:29 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "  0%|                                                                                                                                                    | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:29 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:50:29 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:29 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:29 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:29 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:29 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:29 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:50:29 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:29 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:29 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:29 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:29 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:29 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:29 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:29 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 1 (100.0%):   0%|                                                                                                                 | 0/50 [00:00<?, ?it/s]2025-08-23 15:50:29 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 1.00 / 1 (100.0%):   2%|██                                                                                                       | 1/50 [00:00<00:21,  2.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:29 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:29 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:29 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 2 (100.0%):   2%|██                                                                                                       | 1/50 [00:00<00:21,  2.31it/s]2025-08-23 15:50:29 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:29 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:29 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:29 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 3 (100.0%):   4%|████▏                                                                                                    | 2/50 [00:00<00:20,  2.31it/s]2025-08-23 15:50:29 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:29 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:29 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:29 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 4 (75.0%):   6%|██████▎                                                                                                   | 3/50 [00:00<00:20,  2.31it/s]2025-08-23 15:50:29 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:29 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:29 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 3.00 / 5 (60.0%):   8%|████████▍                                                                                                 | 4/50 [00:00<00:19,  2.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:29 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:29 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:29 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:29 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:29 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:29 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 4.00 / 6 (66.7%):  10%|██████████▌                                                                                               | 5/50 [00:00<00:19,  2.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:29 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:29 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 4.00 / 7 (57.1%):  12%|████████████▋                                                                                             | 6/50 [00:00<00:19,  2.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:29 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:29 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:29 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:29 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:29 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 8 (62.5%):  14%|██████████████▊                                                                                           | 7/50 [00:00<00:18,  2.31it/s]2025-08-23 15:50:29 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 5.00 / 8 (62.5%):  16%|████████████████▉                                                                                         | 8/50 [00:00<00:02, 16.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:29 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:29 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:29 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 9 (66.7%):  16%|████████████████▉                                                                                         | 8/50 [00:00<00:02, 16.07it/s]2025-08-23 15:50:29 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:29 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 10 (70.0%):  18%|██████████████████▉                                                                                      | 9/50 [00:00<00:02, 16.07it/s]2025-08-23 15:50:29 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:29 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:50:29 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:29 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 7.00 / 11 (63.6%):  20%|████████████████████▊                                                                                   | 10/50 [00:00<00:02, 16.07it/s]2025-08-23 15:50:29 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 7.00 / 11 (63.6%):  22%|██████████████████████▉                                                                                 | 11/50 [00:00<00:03, 12.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:29 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:29 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:30 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:30 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 12 (58.3%):  22%|██████████████████████▉                                                                                 | 11/50 [00:00<00:03, 12.53it/s]2025-08-23 15:50:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:30 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:30 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 13 (53.8%):  24%|████████████████████████▉                                                                               | 12/50 [00:01<00:03, 12.53it/s]2025-08-23 15:50:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:30 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 13 (53.8%):  26%|███████████████████████████                                                                             | 13/50 [00:01<00:03, 10.11it/s]2025-08-23 15:50:30 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:30 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:30 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 8.00 / 14 (57.1%):  26%|███████████████████████████                                                                             | 13/50 [00:01<00:03, 10.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:30 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 15 (60.0%):  28%|█████████████████████████████                                                                           | 14/50 [00:01<00:03, 10.11it/s]2025-08-23 15:50:30 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 16 (62.5%):  30%|██████████████████████████████▉                                                                        | 15/50 [00:01<00:03, 10.11it/s]2025-08-23 15:50:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:30 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:30 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 17 (64.7%):  32%|████████████████████████████████▉                                                                      | 16/50 [00:01<00:03, 10.11it/s]2025-08-23 15:50:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 11.00 / 17 (64.7%):  34%|███████████████████████████████████                                                                    | 17/50 [00:01<00:02, 13.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:30 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:30 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:30 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 18 (66.7%):  34%|███████████████████████████████████                                                                    | 17/50 [00:01<00:02, 13.49it/s]2025-08-23 15:50:30 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 19 (68.4%):  36%|█████████████████████████████████████                                                                  | 18/50 [00:01<00:02, 13.49it/s]2025-08-23 15:50:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:30 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:30 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:30 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:30 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:30 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 20 (70.0%):  38%|███████████████████████████████████████▏                                                               | 19/50 [00:01<00:02, 13.49it/s]2025-08-23 15:50:30 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 14.00 / 20 (70.0%):  40%|█████████████████████████████████████████▏                                                             | 20/50 [00:01<00:02, 11.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 14.00 / 21 (66.7%):  40%|█████████████████████████████████████████▏                                                             | 20/50 [00:01<00:02, 11.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 22 (63.6%):  42%|███████████████████████████████████████████▎                                                           | 21/50 [00:01<00:02, 11.92it/s]2025-08-23 15:50:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:30 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:30 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 23 (65.2%):  44%|█████████████████████████████████████████████▎                                                         | 22/50 [00:01<00:02, 11.92it/s]2025-08-23 15:50:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:30 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:30 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 24 (62.5%):  46%|███████████████████████████████████████████████▍                                                       | 23/50 [00:01<00:02, 11.92it/s]2025-08-23 15:50:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:30 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:30 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 25 (64.0%):  48%|█████████████████████████████████████████████████▍                                                     | 24/50 [00:01<00:02, 11.92it/s]2025-08-23 15:50:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 16.00 / 25 (64.0%):  50%|███████████████████████████████████████████████████▌                                                   | 25/50 [00:01<00:01, 15.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:30 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:30 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 17.00 / 26 (65.4%):  50%|███████████████████████████████████████████████████▌                                                   | 25/50 [00:01<00:01, 15.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:30 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:30 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 17.00 / 27 (63.0%):  52%|█████████████████████████████████████████████████████▌                                                 | 26/50 [00:02<00:01, 15.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 28 (64.3%):  54%|███████████████████████████████████████████████████████▌                                               | 27/50 [00:02<00:01, 15.56it/s]2025-08-23 15:50:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 18.00 / 28 (64.3%):  56%|█████████████████████████████████████████████████████████▋                                             | 28/50 [00:02<00:01, 14.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 29 (62.1%):  56%|█████████████████████████████████████████████████████████▋                                             | 28/50 [00:02<00:01, 14.28it/s]2025-08-23 15:50:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 30 (63.3%):  58%|███████████████████████████████████████████████████████████▋                                           | 29/50 [00:02<00:01, 14.28it/s]2025-08-23 15:50:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 31 (64.5%):  60%|█████████████████████████████████████████████████████████████▊                                         | 30/50 [00:02<00:01, 14.28it/s]2025-08-23 15:50:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 32 (62.5%):  62%|███████████████████████████████████████████████████████████████▊                                       | 31/50 [00:02<00:01, 14.28it/s]2025-08-23 15:50:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 32 (62.5%):  64%|█████████████████████████████████████████████████████████████████▉                                     | 32/50 [00:02<00:01, 16.02it/s]2025-08-23 15:50:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 21.00 / 33 (63.6%):  64%|█████████████████████████████████████████████████████████████████▉                                     | 32/50 [00:02<00:01, 16.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 34 (64.7%):  66%|███████████████████████████████████████████████████████████████████▉                                   | 33/50 [00:02<00:01, 16.02it/s]2025-08-23 15:50:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 23.00 / 35 (65.7%):  68%|██████████████████████████████████████████████████████████████████████                                 | 34/50 [00:02<00:00, 16.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 23.00 / 35 (65.7%):  70%|████████████████████████████████████████████████████████████████████████                               | 35/50 [00:02<00:00, 15.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 23.00 / 36 (63.9%):  70%|████████████████████████████████████████████████████████████████████████                               | 35/50 [00:02<00:00, 15.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 37 (64.9%):  72%|██████████████████████████████████████████████████████████████████████████▏                            | 36/50 [00:02<00:00, 15.75it/s]2025-08-23 15:50:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 37 (64.9%):  74%|████████████████████████████████████████████████████████████████████████████▏                          | 37/50 [00:02<00:00, 14.49it/s]2025-08-23 15:50:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.00 / 38 (65.8%):  74%|████████████████████████████████████████████████████████████████████████████▏                          | 37/50 [00:02<00:00, 14.49it/s]2025-08-23 15:50:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 26.00 / 39 (66.7%):  76%|██████████████████████████████████████████████████████████████████████████████▎                        | 38/50 [00:02<00:00, 14.49it/s]2025-08-23 15:50:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 27.00 / 40 (67.5%):  78%|████████████████████████████████████████████████████████████████████████████████▎                      | 39/50 [00:02<00:00, 14.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 28.00 / 41 (68.3%):  80%|██████████████████████████████████████████████████████████████████████████████████▍                    | 40/50 [00:02<00:00, 14.49it/s]2025-08-23 15:50:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 28.00 / 41 (68.3%):  82%|████████████████████████████████████████████████████████████████████████████████████▍                  | 41/50 [00:02<00:00, 17.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:31 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:31 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:31 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 29.00 / 42 (69.0%):  82%|████████████████████████████████████████████████████████████████████████████████████▍                  | 41/50 [00:02<00:00, 17.13it/s]2025-08-23 15:50:31 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 30.00 / 43 (69.8%):  84%|██████████████████████████████████████████████████████████████████████████████████████▌                | 42/50 [00:03<00:00, 17.13it/s]2025-08-23 15:50:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 30.00 / 43 (69.8%):  86%|████████████████████████████████████████████████████████████████████████████████████████▌              | 43/50 [00:03<00:00, 11.66it/s]2025-08-23 15:50:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 33.00 / 46 (71.7%):  90%|████████████████████████████████████████████████████████████████████████████████████████████▋          | 45/50 [00:03<00:00, 11.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 34.00 / 47 (72.3%):  92%|██████████████████████████████████████████████████████████████████████████████████████████████▊        | 46/50 [00:03<00:00, 11.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 35.00 / 48 (72.9%):  94%|████████████████████████████████████████████████████████████████████████████████████████████████▊      | 47/50 [00:03<00:00, 11.66it/s]2025-08-23 15:50:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 36.00 / 49 (73.5%):  96%|██████████████████████████████████████████████████████████████████████████████████████████████████▉    | 48/50 [00:03<00:00, 16.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:32 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:32 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 37.00 / 50 (74.0%): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 14.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/23 15:50:32 INFO dspy.evaluate.evaluate: Average Metric: 37 / 50 (74.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/23 15:50:32 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mBest full score so far!\u001b[0m Score: 74.0\n",
      "2025/08/23 15:50:32 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 74.0 with parameters ['Predictor 0: Instruction 5', 'Predictor 0: Few-Shot Set 6'].\n",
      "2025/08/23 15:50:32 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [66.0, 68.0, 62.0, 62.0, 68.0, 70.0, 70.0, 68.0, 62.0, 68.0, 70.0, 68.0, 74.0]\n",
      "2025/08/23 15:50:32 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 74.0\n",
      "2025/08/23 15:50:32 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/08/23 15:50:32 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 14 / 18 =====\n",
      "\u001b[92m15:50:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                    | 0/50 [00:00<?, ?it/s]2025-08-23 15:50:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:32 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:32 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 1 (100.0%):   0%|                                                                                                                 | 0/50 [00:00<?, ?it/s]2025-08-23 15:50:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 1.00 / 1 (100.0%):   2%|██                                                                                                       | 1/50 [00:00<00:22,  2.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 2.00 / 2 (100.0%):   2%|██                                                                                                       | 1/50 [00:00<00:22,  2.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 3 (66.7%):   4%|████▏                                                                                                     | 2/50 [00:00<00:22,  2.14it/s]2025-08-23 15:50:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 4 (50.0%):   6%|██████▎                                                                                                   | 3/50 [00:00<00:22,  2.14it/s]2025-08-23 15:50:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 5 (60.0%):   8%|████████▍                                                                                                 | 4/50 [00:00<00:21,  2.14it/s]2025-08-23 15:50:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 6 (50.0%):  10%|██████████▌                                                                                               | 5/50 [00:00<00:21,  2.14it/s]2025-08-23 15:50:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 7 (57.1%):  12%|████████████▋                                                                                             | 6/50 [00:00<00:20,  2.14it/s]2025-08-23 15:50:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 8 (62.5%):  14%|██████████████▊                                                                                           | 7/50 [00:00<00:20,  2.14it/s]2025-08-23 15:50:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 5.00 / 8 (62.5%):  16%|████████████████▉                                                                                         | 8/50 [00:00<00:02, 16.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 9 (66.7%):  16%|████████████████▉                                                                                         | 8/50 [00:01<00:02, 16.22it/s]2025-08-23 15:50:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 7.00 / 10 (70.0%):  18%|██████████████████▉                                                                                      | 9/50 [00:01<00:02, 16.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 7.00 / 11 (63.6%):  20%|████████████████████▊                                                                                   | 10/50 [00:01<00:02, 16.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 7.00 / 11 (63.6%):  22%|██████████████████████▉                                                                                 | 11/50 [00:01<00:03, 10.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 12 (58.3%):  22%|██████████████████████▉                                                                                 | 11/50 [00:01<00:03, 10.88it/s]2025-08-23 15:50:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 8.00 / 13 (61.5%):  24%|████████████████████████▉                                                                               | 12/50 [00:01<00:03, 10.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 8.00 / 14 (57.1%):  26%|███████████████████████████                                                                             | 13/50 [00:01<00:03, 10.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 15 (60.0%):  28%|█████████████████████████████                                                                           | 14/50 [00:01<00:03, 10.88it/s]2025-08-23 15:50:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:33 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:33 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:33 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 16 (62.5%):  30%|██████████████████████████████▉                                                                        | 15/50 [00:01<00:03, 10.88it/s]2025-08-23 15:50:33 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 10.00 / 17 (58.8%):  32%|████████████████████████████████▉                                                                      | 16/50 [00:01<00:03, 10.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 10.00 / 17 (58.8%):  34%|███████████████████████████████████                                                                    | 17/50 [00:01<00:02, 11.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:34 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 18 (61.1%):  34%|███████████████████████████████████                                                                    | 17/50 [00:01<00:02, 11.47it/s]2025-08-23 15:50:34 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 19 (63.2%):  36%|█████████████████████████████████████                                                                  | 18/50 [00:01<00:02, 11.47it/s]2025-08-23 15:50:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:34 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:50:34 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:34 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 12.00 / 20 (60.0%):  38%|███████████████████████████████████████▏                                                               | 19/50 [00:01<00:02, 11.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:34 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:50:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:34 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:34 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 13.00 / 21 (61.9%):  40%|█████████████████████████████████████████▏                                                             | 20/50 [00:01<00:02, 11.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:34 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:34 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:34 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 22 (59.1%):  42%|███████████████████████████████████████████▎                                                           | 21/50 [00:01<00:02, 11.47it/s]2025-08-23 15:50:34 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:34 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 23 (60.9%):  44%|█████████████████████████████████████████████▎                                                         | 22/50 [00:01<00:02, 11.47it/s]2025-08-23 15:50:34 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:34 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 24 (62.5%):  48%|█████████████████████████████████████████████████▍                                                     | 24/50 [00:01<00:01, 15.53it/s]2025-08-23 15:50:34 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 16.00 / 25 (64.0%):  48%|█████████████████████████████████████████████████▍                                                     | 24/50 [00:02<00:01, 15.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:34 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:34 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:34 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 26 (65.4%):  50%|███████████████████████████████████████████████████▌                                                   | 25/50 [00:02<00:01, 15.53it/s]2025-08-23 15:50:34 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:34 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 27 (66.7%):  52%|█████████████████████████████████████████████████████▌                                                 | 26/50 [00:02<00:01, 15.53it/s]2025-08-23 15:50:34 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 27 (66.7%):  54%|███████████████████████████████████████████████████████▌                                               | 27/50 [00:02<00:01, 13.88it/s]2025-08-23 15:50:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:34 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 28 (67.9%):  54%|███████████████████████████████████████████████████████▌                                               | 27/50 [00:02<00:01, 13.88it/s]2025-08-23 15:50:34 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 19.00 / 29 (65.5%):  56%|█████████████████████████████████████████████████████████▋                                             | 28/50 [00:02<00:01, 13.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:34 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:34 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 19.00 / 30 (63.3%):  58%|███████████████████████████████████████████████████████████▋                                           | 29/50 [00:02<00:01, 13.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:34 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:34 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:34 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:34 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:34 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 31 (64.5%):  60%|█████████████████████████████████████████████████████████████▊                                         | 30/50 [00:02<00:01, 13.88it/s]2025-08-23 15:50:34 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:35 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 32 (62.5%):  62%|███████████████████████████████████████████████████████████████▊                                       | 31/50 [00:02<00:01, 13.88it/s]2025-08-23 15:50:35 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 20.00 / 32 (62.5%):  64%|█████████████████████████████████████████████████████████████████▉                                     | 32/50 [00:02<00:01, 12.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:35 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:35 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 21.00 / 33 (63.6%):  64%|█████████████████████████████████████████████████████████████████▉                                     | 32/50 [00:02<00:01, 12.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:35 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 34 (64.7%):  66%|███████████████████████████████████████████████████████████████████▉                                   | 33/50 [00:02<00:01, 12.65it/s]2025-08-23 15:50:35 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:35 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 35 (62.9%):  68%|██████████████████████████████████████████████████████████████████████                                 | 34/50 [00:02<00:01, 12.65it/s]2025-08-23 15:50:35 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:35 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 36 (63.9%):  70%|████████████████████████████████████████████████████████████████████████                               | 35/50 [00:02<00:01, 12.65it/s]2025-08-23 15:50:35 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:35 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 37 (64.9%):  72%|██████████████████████████████████████████████████████████████████████████▏                            | 36/50 [00:02<00:01, 12.65it/s]2025-08-23 15:50:35 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:35 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.00 / 38 (65.8%):  74%|████████████████████████████████████████████████████████████████████████████▏                          | 37/50 [00:02<00:01, 12.65it/s]2025-08-23 15:50:35 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:35 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 26.00 / 39 (66.7%):  76%|██████████████████████████████████████████████████████████████████████████████▎                        | 38/50 [00:02<00:00, 12.65it/s]2025-08-23 15:50:35 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:35 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27.00 / 40 (67.5%):  78%|████████████████████████████████████████████████████████████████████████████████▎                      | 39/50 [00:03<00:00, 12.65it/s]2025-08-23 15:50:35 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 27.00 / 40 (67.5%):  80%|██████████████████████████████████████████████████████████████████████████████████▍                    | 40/50 [00:03<00:00, 13.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 28.00 / 41 (68.3%):  80%|██████████████████████████████████████████████████████████████████████████████████▍                    | 40/50 [00:03<00:00, 13.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 29.00 / 42 (69.0%):  82%|████████████████████████████████████████████████████████████████████████████████████▍                  | 41/50 [00:03<00:00, 13.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:35 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 30.00 / 43 (69.8%):  84%|██████████████████████████████████████████████████████████████████████████████████████▌                | 42/50 [00:03<00:00, 13.86it/s]2025-08-23 15:50:35 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:35 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:35 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 31.00 / 44 (70.5%):  86%|████████████████████████████████████████████████████████████████████████████████████████▌              | 43/50 [00:03<00:00, 13.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 32.00 / 45 (71.1%):  88%|██████████████████████████████████████████████████████████████████████████████████████████▋            | 44/50 [00:03<00:00, 13.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 33.00 / 46 (71.7%):  90%|████████████████████████████████████████████████████████████████████████████████████████████▋          | 45/50 [00:03<00:00, 13.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:35 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:35 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 34.00 / 47 (72.3%):  94%|████████████████████████████████████████████████████████████████████████████████████████████████▊      | 47/50 [00:03<00:00, 16.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:36 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:36 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 35.00 / 48 (72.9%):  94%|████████████████████████████████████████████████████████████████████████████████████████████████▊      | 47/50 [00:03<00:00, 16.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:36 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:36 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:36 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 36.00 / 49 (73.5%):  96%|██████████████████████████████████████████████████████████████████████████████████████████████████▉    | 48/50 [00:03<00:00, 16.84it/s]2025-08-23 15:50:36 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 37.00 / 50 (74.0%): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 13.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/23 15:50:36 INFO dspy.evaluate.evaluate: Average Metric: 37 / 50 (74.0%)\n",
      "2025/08/23 15:50:36 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 74.0 with parameters ['Predictor 0: Instruction 5', 'Predictor 0: Few-Shot Set 6'].\n",
      "2025/08/23 15:50:36 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [66.0, 68.0, 62.0, 62.0, 68.0, 70.0, 70.0, 68.0, 62.0, 68.0, 70.0, 68.0, 74.0, 74.0]\n",
      "2025/08/23 15:50:36 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 74.0\n",
      "2025/08/23 15:50:36 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/08/23 15:50:36 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 15 / 18 =====\n",
      "\u001b[92m15:50:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-08-23 15:50:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                    | 0/50 [00:00<?, ?it/s]2025-08-23 15:50:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:36 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:36 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 1 (0.0%):   0%|                                                                                                                   | 0/50 [00:00<?, ?it/s]2025-08-23 15:50:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 0.00 / 1 (0.0%):   2%|██▏                                                                                                        | 1/50 [00:00<00:26,  1.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:36 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:36 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:36 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:36 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 0.00 / 2 (0.0%):   2%|██▏                                                                                                        | 1/50 [00:00<00:26,  1.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:36 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:36 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 1.00 / 3 (33.3%):   4%|████▏                                                                                                     | 2/50 [00:00<00:25,  1.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:36 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:36 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 2.00 / 4 (50.0%):   6%|██████▎                                                                                                   | 3/50 [00:00<00:25,  1.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 3.00 / 5 (60.0%):   8%|████████▍                                                                                                 | 4/50 [00:00<00:24,  1.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:36 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:36 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 3.00 / 6 (50.0%):  10%|██████████▌                                                                                               | 5/50 [00:00<00:23,  1.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:36 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:36 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 7 (57.1%):  12%|████████████▋                                                                                             | 6/50 [00:00<00:23,  1.88it/s]2025-08-23 15:50:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:36 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:36 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 5.00 / 8 (62.5%):  14%|██████████████▊                                                                                           | 7/50 [00:00<00:22,  1.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 9 (66.7%):  16%|████████████████▉                                                                                         | 8/50 [00:00<00:22,  1.88it/s]2025-08-23 15:50:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 6.00 / 9 (66.7%):  18%|███████████████████                                                                                       | 9/50 [00:00<00:03, 10.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 10 (70.0%):  18%|██████████████████▉                                                                                      | 9/50 [00:01<00:03, 10.37it/s]2025-08-23 15:50:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 8.00 / 11 (72.7%):  20%|████████████████████▊                                                                                   | 10/50 [00:01<00:03, 10.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:50:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:50:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 8.00 / 12 (66.7%):  22%|██████████████████████▉                                                                                 | 11/50 [00:01<00:03, 10.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 13 (61.5%):  24%|████████████████████████▉                                                                               | 12/50 [00:01<00:03, 10.37it/s]2025-08-23 15:50:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 14 (64.3%):  26%|███████████████████████████                                                                             | 13/50 [00:01<00:03, 10.37it/s]2025-08-23 15:50:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 15 (60.0%):  28%|█████████████████████████████                                                                           | 14/50 [00:01<00:03, 10.37it/s]2025-08-23 15:50:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 16 (62.5%):  30%|██████████████████████████████▉                                                                        | 15/50 [00:01<00:03, 10.37it/s]2025-08-23 15:50:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 10.00 / 16 (62.5%):  32%|████████████████████████████████▉                                                                      | 16/50 [00:01<00:01, 18.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 17 (64.7%):  32%|████████████████████████████████▉                                                                      | 16/50 [00:01<00:01, 18.81it/s]2025-08-23 15:50:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 18 (66.7%):  34%|███████████████████████████████████                                                                    | 17/50 [00:01<00:01, 18.81it/s]2025-08-23 15:50:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 12.00 / 19 (63.2%):  36%|█████████████████████████████████████                                                                  | 18/50 [00:01<00:01, 18.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 20 (65.0%):  38%|███████████████████████████████████████▏                                                               | 19/50 [00:01<00:01, 18.81it/s]2025-08-23 15:50:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 13.00 / 20 (65.0%):  40%|█████████████████████████████████████████▏                                                             | 20/50 [00:01<00:02, 13.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 21 (61.9%):  40%|█████████████████████████████████████████▏                                                             | 20/50 [00:01<00:02, 13.99it/s]2025-08-23 15:50:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 22 (59.1%):  42%|███████████████████████████████████████████▎                                                           | 21/50 [00:01<00:02, 13.99it/s]2025-08-23 15:50:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 23 (60.9%):  44%|█████████████████████████████████████████████▎                                                         | 22/50 [00:01<00:02, 13.99it/s]2025-08-23 15:50:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 24 (58.3%):  46%|███████████████████████████████████████████████▍                                                       | 23/50 [00:01<00:01, 13.99it/s]2025-08-23 15:50:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 25 (60.0%):  48%|█████████████████████████████████████████████████▍                                                     | 24/50 [00:01<00:01, 13.99it/s]2025-08-23 15:50:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 15.00 / 25 (60.0%):  50%|███████████████████████████████████████████████████▌                                                   | 25/50 [00:01<00:01, 13.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 26 (61.5%):  50%|███████████████████████████████████████████████████▌                                                   | 25/50 [00:02<00:01, 13.23it/s]2025-08-23 15:50:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 17.00 / 27 (63.0%):  52%|█████████████████████████████████████████████████████▌                                                 | 26/50 [00:02<00:01, 13.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 28 (60.7%):  54%|███████████████████████████████████████████████████████▌                                               | 27/50 [00:02<00:01, 13.23it/s]2025-08-23 15:50:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 17.00 / 28 (60.7%):  56%|█████████████████████████████████████████████████████████▋                                             | 28/50 [00:02<00:01, 15.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 29 (62.1%):  56%|█████████████████████████████████████████████████████████▋                                             | 28/50 [00:02<00:01, 15.02it/s]2025-08-23 15:50:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 30 (60.0%):  58%|███████████████████████████████████████████████████████████▋                                           | 29/50 [00:02<00:01, 15.02it/s]2025-08-23 15:50:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 19.00 / 31 (61.3%):  60%|█████████████████████████████████████████████████████████████▊                                         | 30/50 [00:02<00:01, 15.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 32 (62.5%):  62%|███████████████████████████████████████████████████████████████▊                                       | 31/50 [00:02<00:01, 15.02it/s]2025-08-23 15:50:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 21.00 / 33 (63.6%):  64%|█████████████████████████████████████████████████████████████████▉                                     | 32/50 [00:02<00:01, 15.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 33 (63.6%):  66%|███████████████████████████████████████████████████████████████████▉                                   | 33/50 [00:02<00:01, 13.85it/s]2025-08-23 15:50:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 34 (61.8%):  66%|███████████████████████████████████████████████████████████████████▉                                   | 33/50 [00:02<00:01, 13.85it/s]2025-08-23 15:50:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 35 (60.0%):  68%|██████████████████████████████████████████████████████████████████████                                 | 34/50 [00:02<00:01, 13.85it/s]2025-08-23 15:50:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 22.00 / 36 (61.1%):  70%|████████████████████████████████████████████████████████████████████████                               | 35/50 [00:02<00:01, 13.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 22.00 / 36 (61.1%):  72%|██████████████████████████████████████████████████████████████████████████▏                            | 36/50 [00:02<00:00, 15.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 37 (62.2%):  72%|██████████████████████████████████████████████████████████████████████████▏                            | 36/50 [00:02<00:00, 15.72it/s]2025-08-23 15:50:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 38 (63.2%):  74%|████████████████████████████████████████████████████████████████████████████▏                          | 37/50 [00:02<00:00, 15.72it/s]2025-08-23 15:50:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.00 / 39 (64.1%):  76%|██████████████████████████████████████████████████████████████████████████████▎                        | 38/50 [00:02<00:00, 15.72it/s]2025-08-23 15:50:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:38 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 26.00 / 40 (65.0%):  78%|████████████████████████████████████████████████████████████████████████████████▎                      | 39/50 [00:02<00:00, 15.72it/s]2025-08-23 15:50:38 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:39 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:39 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 27.00 / 41 (65.9%):  80%|██████████████████████████████████████████████████████████████████████████████████▍                    | 40/50 [00:02<00:00, 15.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:39 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:39 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 27.00 / 41 (65.9%):  82%|████████████████████████████████████████████████████████████████████████████████████▍                  | 41/50 [00:02<00:00, 14.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:39 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:39 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:39 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 28.00 / 42 (66.7%):  82%|████████████████████████████████████████████████████████████████████████████████████▍                  | 41/50 [00:03<00:00, 14.80it/s]2025-08-23 15:50:39 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:39 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:39 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 29.00 / 43 (67.4%):  84%|██████████████████████████████████████████████████████████████████████████████████████▌                | 42/50 [00:03<00:00, 14.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:39 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:39 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 30.00 / 44 (68.2%):  88%|██████████████████████████████████████████████████████████████████████████████████████████▋            | 44/50 [00:03<00:00, 16.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:39 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:39 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 31.00 / 45 (68.9%):  88%|██████████████████████████████████████████████████████████████████████████████████████████▋            | 44/50 [00:03<00:00, 16.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:39 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:39 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 32.00 / 46 (69.6%):  90%|████████████████████████████████████████████████████████████████████████████████████████████▋          | 45/50 [00:03<00:00, 16.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:39 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:39 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 33.00 / 47 (70.2%):  92%|██████████████████████████████████████████████████████████████████████████████████████████████▊        | 46/50 [00:03<00:00, 16.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:39 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:39 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 34.00 / 48 (70.8%):  96%|██████████████████████████████████████████████████████████████████████████████████████████████████▉    | 48/50 [00:03<00:00, 15.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:39 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:39 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 35.00 / 49 (71.4%):  96%|██████████████████████████████████████████████████████████████████████████████████████████████████▉    | 48/50 [00:03<00:00, 15.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:39 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:39 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 36.00 / 50 (72.0%): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 13.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/23 15:50:39 INFO dspy.evaluate.evaluate: Average Metric: 36 / 50 (72.0%)\n",
      "2025/08/23 15:50:39 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 72.0 with parameters ['Predictor 0: Instruction 5', 'Predictor 0: Few-Shot Set 6'].\n",
      "2025/08/23 15:50:39 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [66.0, 68.0, 62.0, 62.0, 68.0, 70.0, 70.0, 68.0, 62.0, 68.0, 70.0, 68.0, 74.0, 74.0, 72.0]\n",
      "2025/08/23 15:50:39 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 74.0\n",
      "2025/08/23 15:50:39 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/08/23 15:50:39 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 16 / 18 =====\n",
      "\u001b[92m15:50:39 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-08-23 15:50:39 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:39 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:39 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:39 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:39 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:39 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                    | 0/50 [00:00<?, ?it/s]2025-08-23 15:50:39 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:39 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:50:39 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:39 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:39 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:39 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:39 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:39 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:50:39 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:40 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:40 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:40 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:40 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 1.00 / 1 (100.0%):   0%|                                                                                                                 | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:40 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 1 (100.0%):   2%|██                                                                                                       | 1/50 [00:00<00:28,  1.72it/s]2025-08-23 15:50:40 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:40 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:40 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 1.00 / 2 (50.0%):   2%|██                                                                                                        | 1/50 [00:00<00:28,  1.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:40 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:40 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:40 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:40 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 2.00 / 3 (66.7%):   4%|████▏                                                                                                     | 2/50 [00:00<00:27,  1.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:40 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 4 (75.0%):   6%|██████▎                                                                                                   | 3/50 [00:00<00:27,  1.72it/s]2025-08-23 15:50:40 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:40 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:40 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:40 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:40 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:40 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 5 (80.0%):   8%|████████▍                                                                                                 | 4/50 [00:00<00:26,  1.72it/s]2025-08-23 15:50:40 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:40 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:40 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:40 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 6 (66.7%):  10%|██████████▌                                                                                               | 5/50 [00:00<00:26,  1.72it/s]2025-08-23 15:50:40 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:40 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:40 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:40 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 7 (57.1%):  12%|████████████▋                                                                                             | 6/50 [00:00<00:25,  1.72it/s]2025-08-23 15:50:40 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:40 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:40 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:40 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 8 (50.0%):  14%|██████████████▊                                                                                           | 7/50 [00:00<00:25,  1.72it/s]2025-08-23 15:50:40 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:41 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:41 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:41 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:41 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 5.00 / 9 (55.6%):  16%|████████████████▉                                                                                         | 8/50 [00:01<00:24,  1.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:41 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 9 (55.6%):  18%|███████████████████                                                                                       | 9/50 [00:01<00:04,  8.73it/s]2025-08-23 15:50:41 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 5.00 / 10 (50.0%):  18%|██████████████████▉                                                                                      | 9/50 [00:01<00:04,  8.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:41 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:41 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:41 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:41 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:41 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 11 (54.5%):  20%|████████████████████▊                                                                                   | 10/50 [00:01<00:04,  8.73it/s]2025-08-23 15:50:41 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:41 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:41 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:41 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 12 (58.3%):  22%|██████████████████████▉                                                                                 | 11/50 [00:01<00:04,  8.73it/s]2025-08-23 15:50:41 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:41 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:41 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:41 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:41 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 7.00 / 13 (53.8%):  24%|████████████████████████▉                                                                               | 12/50 [00:01<00:04,  8.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:41 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:41 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 8.00 / 14 (57.1%):  26%|███████████████████████████                                                                             | 13/50 [00:01<00:04,  8.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:41 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:41 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:41 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:41 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 9.00 / 15 (60.0%):  28%|█████████████████████████████                                                                           | 14/50 [00:01<00:04,  8.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:41 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 15 (60.0%):  30%|███████████████████████████████▏                                                                        | 15/50 [00:01<00:02, 15.14it/s]2025-08-23 15:50:41 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:41 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:41 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 9.00 / 16 (56.2%):  30%|███████████████████████████████▏                                                                        | 15/50 [00:01<00:02, 15.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:41 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:41 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:41 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:41 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 10.00 / 17 (58.8%):  32%|████████████████████████████████▉                                                                      | 16/50 [00:01<00:02, 15.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:41 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:41 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:41 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:41 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:41 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:41 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 11.00 / 18 (61.1%):  34%|███████████████████████████████████                                                                    | 17/50 [00:01<00:02, 15.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:41 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 19 (63.2%):  36%|█████████████████████████████████████                                                                  | 18/50 [00:01<00:02, 15.14it/s]2025-08-23 15:50:41 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:41 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 19 (63.2%):  38%|███████████████████████████████████████▏                                                               | 19/50 [00:01<00:02, 12.23it/s]2025-08-23 15:50:41 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:41 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 20 (65.0%):  38%|███████████████████████████████████████▏                                                               | 19/50 [00:01<00:02, 12.23it/s]2025-08-23 15:50:41 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:41 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:41 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:41 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:41 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:41 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 21 (61.9%):  40%|█████████████████████████████████████████▏                                                             | 20/50 [00:01<00:02, 12.23it/s]2025-08-23 15:50:41 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:41 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:41 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:41 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 22 (63.6%):  42%|███████████████████████████████████████████▎                                                           | 21/50 [00:01<00:02, 12.23it/s]2025-08-23 15:50:41 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:41 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:41 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:41 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 23 (65.2%):  44%|█████████████████████████████████████████████▎                                                         | 22/50 [00:01<00:02, 12.23it/s]2025-08-23 15:50:41 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:41 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:41 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 15.00 / 24 (62.5%):  46%|███████████████████████████████████████████████▍                                                       | 23/50 [00:01<00:02, 12.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:41 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 24 (62.5%):  48%|█████████████████████████████████████████████████▍                                                     | 24/50 [00:01<00:01, 14.61it/s]2025-08-23 15:50:41 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:42 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:42 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 16.00 / 25 (64.0%):  48%|█████████████████████████████████████████████████▍                                                     | 24/50 [00:02<00:01, 14.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:42 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:42 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:42 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:42 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:42 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 26 (65.4%):  50%|███████████████████████████████████████████████████▌                                                   | 25/50 [00:02<00:01, 14.61it/s]2025-08-23 15:50:42 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:42 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:42 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:42 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:42 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 18.00 / 27 (66.7%):  52%|█████████████████████████████████████████████████████▌                                                 | 26/50 [00:02<00:01, 14.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:42 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 27 (66.7%):  54%|███████████████████████████████████████████████████████▌                                               | 27/50 [00:02<00:01, 13.08it/s]2025-08-23 15:50:42 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 19.00 / 28 (67.9%):  54%|███████████████████████████████████████████████████████▌                                               | 27/50 [00:02<00:01, 13.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:42 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:42 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:42 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:42 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:42 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 29 (65.5%):  56%|█████████████████████████████████████████████████████████▋                                             | 28/50 [00:02<00:01, 13.08it/s]2025-08-23 15:50:42 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:42 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:42 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 19.00 / 30 (63.3%):  58%|███████████████████████████████████████████████████████████▋                                           | 29/50 [00:02<00:01, 13.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:42 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 30 (63.3%):  60%|█████████████████████████████████████████████████████████████▊                                         | 30/50 [00:02<00:01, 14.80it/s]2025-08-23 15:50:42 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:42 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:42 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:42 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 31 (61.3%):  60%|█████████████████████████████████████████████████████████████▊                                         | 30/50 [00:02<00:01, 14.80it/s]2025-08-23 15:50:42 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:42 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:42 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 20.00 / 32 (62.5%):  62%|███████████████████████████████████████████████████████████████▊                                       | 31/50 [00:02<00:01, 14.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:42 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:42 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:42 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:42 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:42 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 33 (63.6%):  64%|█████████████████████████████████████████████████████████████████▉                                     | 32/50 [00:02<00:01, 14.80it/s]2025-08-23 15:50:42 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 21.00 / 33 (63.6%):  66%|███████████████████████████████████████████████████████████████████▉                                   | 33/50 [00:02<00:01, 12.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:42 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:42 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:42 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 34 (64.7%):  66%|███████████████████████████████████████████████████████████████████▉                                   | 33/50 [00:02<00:01, 12.14it/s]2025-08-23 15:50:42 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:42 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:42 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:42 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 35 (62.9%):  68%|██████████████████████████████████████████████████████████████████████                                 | 34/50 [00:02<00:01, 12.14it/s]2025-08-23 15:50:42 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:42 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:42 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:42 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 36 (63.9%):  70%|████████████████████████████████████████████████████████████████████████                               | 35/50 [00:02<00:01, 12.14it/s]2025-08-23 15:50:42 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:42 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:42 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 23.00 / 37 (62.2%):  72%|██████████████████████████████████████████████████████████████████████████▏                            | 36/50 [00:02<00:01, 12.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:42 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:42 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 23.00 / 37 (62.2%):  74%|████████████████████████████████████████████████████████████████████████████▏                          | 37/50 [00:02<00:00, 14.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:42 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:42 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 24.00 / 38 (63.2%):  74%|████████████████████████████████████████████████████████████████████████████▏                          | 37/50 [00:03<00:00, 14.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:42 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:42 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:42 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:42 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:42 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.00 / 39 (64.1%):  76%|██████████████████████████████████████████████████████████████████████████████▎                        | 38/50 [00:03<00:00, 14.95it/s]2025-08-23 15:50:42 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 25.00 / 39 (64.1%):  78%|████████████████████████████████████████████████████████████████████████████████▎                      | 39/50 [00:03<00:00, 14.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:42 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:42 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 26.00 / 40 (65.0%):  78%|████████████████████████████████████████████████████████████████████████████████▎                      | 39/50 [00:03<00:00, 14.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:43 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:43 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:43 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:43 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:43 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27.00 / 41 (65.9%):  80%|██████████████████████████████████████████████████████████████████████████████████▍                    | 40/50 [00:03<00:00, 14.26it/s]2025-08-23 15:50:43 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:43 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27.00 / 41 (65.9%):  82%|████████████████████████████████████████████████████████████████████████████████████▍                  | 41/50 [00:03<00:00, 11.69it/s]2025-08-23 15:50:43 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:43 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27.00 / 42 (64.3%):  82%|████████████████████████████████████████████████████████████████████████████████████▍                  | 41/50 [00:03<00:00, 11.69it/s]2025-08-23 15:50:43 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:43 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:43 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 28.00 / 43 (65.1%):  84%|██████████████████████████████████████████████████████████████████████████████████████▌                | 42/50 [00:03<00:00, 11.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:43 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:43 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 29.00 / 44 (65.9%):  86%|████████████████████████████████████████████████████████████████████████████████████████▌              | 43/50 [00:03<00:00, 11.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:43 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:43 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 30.00 / 45 (66.7%):  88%|██████████████████████████████████████████████████████████████████████████████████████████▋            | 44/50 [00:03<00:00, 11.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:43 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:43 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 31.00 / 46 (67.4%):  92%|██████████████████████████████████████████████████████████████████████████████████████████████▊        | 46/50 [00:03<00:00, 14.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:43 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:43 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 32.00 / 47 (68.1%):  92%|██████████████████████████████████████████████████████████████████████████████████████████████▊        | 46/50 [00:03<00:00, 14.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:43 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:43 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 33.00 / 48 (68.8%):  96%|██████████████████████████████████████████████████████████████████████████████████████████████████▉    | 48/50 [00:03<00:00, 14.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:43 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:43 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 34.00 / 49 (69.4%):  96%|██████████████████████████████████████████████████████████████████████████████████████████████████▉    | 48/50 [00:03<00:00, 14.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:43 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:43 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 35.00 / 50 (70.0%): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:04<00:00, 12.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/23 15:50:43 INFO dspy.evaluate.evaluate: Average Metric: 35 / 50 (70.0%)\n",
      "2025/08/23 15:50:43 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 70.0 with parameters ['Predictor 0: Instruction 5', 'Predictor 0: Few-Shot Set 4'].\n",
      "2025/08/23 15:50:43 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [66.0, 68.0, 62.0, 62.0, 68.0, 70.0, 70.0, 68.0, 62.0, 68.0, 70.0, 68.0, 74.0, 74.0, 72.0, 70.0]\n",
      "2025/08/23 15:50:43 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 74.0\n",
      "2025/08/23 15:50:43 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/08/23 15:50:43 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 17 / 18 =====\n",
      "\u001b[92m15:50:43 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-08-23 15:50:43 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:43 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:43 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:43 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:43 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:43 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:43 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "  0%|                                                                                                                                                    | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:43 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:43 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:43 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:43 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:43 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:43 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:43 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:43 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:44 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:44 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:44 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:44 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 1.00 / 1 (100.0%):   0%|                                                                                                                 | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:44 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:50:44 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 1 (100.0%):   2%|██                                                                                                       | 1/50 [00:00<00:22,  2.16it/s]2025-08-23 15:50:44 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 2.00 / 2 (100.0%):   2%|██                                                                                                       | 1/50 [00:00<00:22,  2.16it/s]2025-08-23 15:50:44 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:44 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 3 (66.7%):   4%|████▏                                                                                                     | 2/50 [00:00<00:22,  2.16it/s]2025-08-23 15:50:44 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:44 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 4 (75.0%):   6%|██████▎                                                                                                   | 3/50 [00:00<00:21,  2.16it/s]2025-08-23 15:50:44 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:44 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:44 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:44 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:44 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:44 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:44 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:44 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 5 (80.0%):   8%|████████▍                                                                                                 | 4/50 [00:00<00:21,  2.16it/s]2025-08-23 15:50:44 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:44 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:44 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:44 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:44 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 4.00 / 6 (66.7%):  10%|██████████▌                                                                                               | 5/50 [00:00<00:20,  2.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:44 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:44 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 4.00 / 7 (57.1%):  12%|████████████▋                                                                                             | 6/50 [00:00<00:20,  2.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:44 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:44 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:44 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:44 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:44 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 8 (62.5%):  14%|██████████████▊                                                                                           | 7/50 [00:00<00:19,  2.16it/s]2025-08-23 15:50:44 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:44 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:44 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:44 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 9 (55.6%):  16%|████████████████▉                                                                                         | 8/50 [00:00<00:19,  2.16it/s]2025-08-23 15:50:44 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 5.00 / 9 (55.6%):  18%|███████████████████                                                                                       | 9/50 [00:00<00:03, 11.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:44 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:44 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:44 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 10 (50.0%):  18%|██████████████████▉                                                                                      | 9/50 [00:00<00:03, 11.31it/s]2025-08-23 15:50:44 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:44 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:44 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 6.00 / 11 (54.5%):  20%|████████████████████▊                                                                                   | 10/50 [00:00<00:03, 11.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:44 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:44 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:44 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:44 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:44 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 12 (58.3%):  22%|██████████████████████▉                                                                                 | 11/50 [00:00<00:03, 11.31it/s]2025-08-23 15:50:44 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:44 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:44 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:44 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 13 (61.5%):  24%|████████████████████████▉                                                                               | 12/50 [00:00<00:03, 11.31it/s]2025-08-23 15:50:44 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:44 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:44 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:44 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 14 (64.3%):  26%|███████████████████████████                                                                             | 13/50 [00:00<00:03, 11.31it/s]2025-08-23 15:50:44 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:44 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:44 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:44 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 15 (66.7%):  28%|████████████████████████████▊                                                                          | 14/50 [00:00<00:03, 11.31it/s]2025-08-23 15:50:44 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:44 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:44 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:44 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 16 (62.5%):  30%|██████████████████████████████▉                                                                        | 15/50 [00:00<00:03, 11.31it/s]2025-08-23 15:50:44 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:45 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:45 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:45 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 17 (64.7%):  32%|████████████████████████████████▉                                                                      | 16/50 [00:01<00:03, 11.31it/s]2025-08-23 15:50:45 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:45 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:45 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 11.00 / 17 (64.7%):  34%|███████████████████████████████████                                                                    | 17/50 [00:01<00:02, 13.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:45 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 18 (66.7%):  34%|███████████████████████████████████                                                                    | 17/50 [00:01<00:02, 13.24it/s]2025-08-23 15:50:45 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 13.00 / 19 (68.4%):  36%|█████████████████████████████████████                                                                  | 18/50 [00:01<00:02, 13.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:45 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:45 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:45 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:45 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:45 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 20 (70.0%):  38%|███████████████████████████████████████▏                                                               | 19/50 [00:01<00:02, 13.24it/s]2025-08-23 15:50:45 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:45 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 21 (66.7%):  40%|█████████████████████████████████████████▏                                                             | 20/50 [00:01<00:02, 13.24it/s]2025-08-23 15:50:45 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:45 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:45 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:45 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:45 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:45 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:45 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:45 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 22 (68.2%):  42%|███████████████████████████████████████████▎                                                           | 21/50 [00:01<00:02, 13.24it/s]2025-08-23 15:50:45 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:45 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:45 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:45 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 23 (69.6%):  44%|█████████████████████████████████████████████▎                                                         | 22/50 [00:01<00:02, 13.24it/s]2025-08-23 15:50:45 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:45 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:45 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:45 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 24 (66.7%):  46%|███████████████████████████████████████████████▍                                                       | 23/50 [00:01<00:02, 13.24it/s]2025-08-23 15:50:45 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:45 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:45 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:45 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 25 (68.0%):  48%|█████████████████████████████████████████████████▍                                                     | 24/50 [00:01<00:01, 13.24it/s]2025-08-23 15:50:45 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 17.00 / 25 (68.0%):  50%|███████████████████████████████████████████████████▌                                                   | 25/50 [00:01<00:01, 14.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:45 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:45 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:45 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:45 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 18.00 / 26 (69.2%):  50%|███████████████████████████████████████████████████▌                                                   | 25/50 [00:01<00:01, 14.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:45 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:45 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 18.00 / 27 (66.7%):  52%|█████████████████████████████████████████████████████▌                                                 | 26/50 [00:01<00:01, 14.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:45 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 28 (67.9%):  54%|███████████████████████████████████████████████████████▌                                               | 27/50 [00:01<00:01, 14.28it/s]2025-08-23 15:50:45 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:45 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:45 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:45 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 29 (69.0%):  56%|█████████████████████████████████████████████████████████▋                                             | 28/50 [00:01<00:01, 14.28it/s]2025-08-23 15:50:45 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:45 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:45 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:45 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:45 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:45 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:45 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:45 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 30 (70.0%):  58%|███████████████████████████████████████████████████████████▋                                           | 29/50 [00:01<00:01, 14.28it/s]2025-08-23 15:50:45 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:45 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:45 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:45 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 31 (71.0%):  60%|█████████████████████████████████████████████████████████████▊                                         | 30/50 [00:01<00:01, 14.28it/s]2025-08-23 15:50:45 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:45 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:45 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:45 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 32 (68.8%):  62%|███████████████████████████████████████████████████████████████▊                                       | 31/50 [00:02<00:01, 14.28it/s]2025-08-23 15:50:45 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 22.00 / 32 (68.8%):  64%|█████████████████████████████████████████████████████████████████▉                                     | 32/50 [00:02<00:00, 19.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:46 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:46 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:46 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:46 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:46 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 33 (66.7%):  64%|█████████████████████████████████████████████████████████████████▉                                     | 32/50 [00:02<00:00, 19.81it/s]2025-08-23 15:50:46 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 23.00 / 34 (67.6%):  66%|███████████████████████████████████████████████████████████████████▉                                   | 33/50 [00:02<00:00, 19.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:46 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:46 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:46 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:46 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:46 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 35 (68.6%):  68%|██████████████████████████████████████████████████████████████████████                                 | 34/50 [00:02<00:00, 19.81it/s]2025-08-23 15:50:46 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:46 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:46 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:46 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.00 / 36 (69.4%):  70%|████████████████████████████████████████████████████████████████████████                               | 35/50 [00:02<00:00, 19.81it/s]2025-08-23 15:50:46 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 25.00 / 36 (69.4%):  72%|██████████████████████████████████████████████████████████████████████████▏                            | 36/50 [00:02<00:00, 16.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:46 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:46 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:46 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 26.00 / 37 (70.3%):  72%|██████████████████████████████████████████████████████████████████████████▏                            | 36/50 [00:02<00:00, 16.37it/s]2025-08-23 15:50:46 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:46 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:46 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:46 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27.00 / 38 (71.1%):  74%|████████████████████████████████████████████████████████████████████████████▏                          | 37/50 [00:02<00:00, 16.37it/s]2025-08-23 15:50:46 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:46 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:46 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:46 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 28.00 / 39 (71.8%):  76%|██████████████████████████████████████████████████████████████████████████████▎                        | 38/50 [00:02<00:00, 16.37it/s]2025-08-23 15:50:46 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:46 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:46 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:46 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 29.00 / 40 (72.5%):  78%|████████████████████████████████████████████████████████████████████████████████▎                      | 39/50 [00:02<00:00, 16.37it/s]2025-08-23 15:50:46 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:46 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:46 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:46 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 29.00 / 41 (70.7%):  80%|██████████████████████████████████████████████████████████████████████████████████▍                    | 40/50 [00:02<00:00, 16.37it/s]2025-08-23 15:50:46 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 29.00 / 41 (70.7%):  82%|████████████████████████████████████████████████████████████████████████████████████▍                  | 41/50 [00:02<00:00, 14.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:46 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:46 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:46 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 30.00 / 42 (71.4%):  82%|████████████████████████████████████████████████████████████████████████████████████▍                  | 41/50 [00:02<00:00, 14.78it/s]2025-08-23 15:50:46 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:46 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:46 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:46 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:46 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 32.00 / 44 (72.7%):  86%|████████████████████████████████████████████████████████████████████████████████████████▌              | 43/50 [00:02<00:00, 14.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:46 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:46 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 33.00 / 45 (73.3%):  88%|██████████████████████████████████████████████████████████████████████████████████████████▋            | 44/50 [00:02<00:00, 14.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:46 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:46 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 34.00 / 46 (73.9%):  90%|████████████████████████████████████████████████████████████████████████████████████████████▋          | 45/50 [00:02<00:00, 14.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:46 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:46 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 35.00 / 47 (74.5%):  92%|██████████████████████████████████████████████████████████████████████████████████████████████▊        | 46/50 [00:02<00:00, 14.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:46 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:46 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 35.00 / 48 (72.9%):  96%|██████████████████████████████████████████████████████████████████████████████████████████████████▉    | 48/50 [00:02<00:00, 19.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:47 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:47 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 35.00 / 49 (71.4%):  96%|██████████████████████████████████████████████████████████████████████████████████████████████████▉    | 48/50 [00:03<00:00, 19.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:47 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:47 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 36.00 / 50 (72.0%): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 14.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/23 15:50:47 INFO dspy.evaluate.evaluate: Average Metric: 36 / 50 (72.0%)\n",
      "2025/08/23 15:50:47 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 72.0 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 11'].\n",
      "2025/08/23 15:50:47 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [66.0, 68.0, 62.0, 62.0, 68.0, 70.0, 70.0, 68.0, 62.0, 68.0, 70.0, 68.0, 74.0, 74.0, 72.0, 70.0, 72.0]\n",
      "2025/08/23 15:50:47 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 74.0\n",
      "2025/08/23 15:50:47 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/08/23 15:50:47 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 18 / 18 =====\n",
      "\u001b[92m15:50:47 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-08-23 15:50:47 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:47 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:50:47 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:47 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:50:47 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:47 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:47 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "  0%|                                                                                                                                                    | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:47 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:47 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:47 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:47 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:47 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:47 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:47 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:47 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:47 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:47 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:47 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 1 (100.0%):   2%|██                                                                                                       | 1/50 [00:00<00:22,  2.18it/s]2025-08-23 15:50:47 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:47 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:50:47 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:47 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:50:47 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:47 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 2 (50.0%):   2%|██                                                                                                        | 1/50 [00:00<00:22,  2.18it/s]2025-08-23 15:50:47 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 1.00 / 3 (33.3%):   4%|████▏                                                                                                     | 2/50 [00:00<00:22,  2.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:47 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:47 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:47 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:47 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:47 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 4 (50.0%):   6%|██████▎                                                                                                   | 3/50 [00:00<00:21,  2.18it/s]2025-08-23 15:50:47 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:47 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:47 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:47 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 5 (60.0%):   8%|████████▍                                                                                                 | 4/50 [00:00<00:21,  2.18it/s]2025-08-23 15:50:47 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:47 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:47 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 3.00 / 6 (50.0%):  10%|██████████▌                                                                                               | 5/50 [00:00<00:20,  2.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:47 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 6 (50.0%):  12%|████████████▋                                                                                             | 6/50 [00:00<00:03, 12.73it/s]2025-08-23 15:50:47 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:47 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:47 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:47 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 7 (57.1%):  12%|████████████▋                                                                                             | 6/50 [00:00<00:03, 12.73it/s]2025-08-23 15:50:47 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 4.00 / 8 (50.0%):  14%|██████████████▊                                                                                           | 7/50 [00:00<00:03, 12.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 5.00 / 9 (55.6%):  16%|████████████████▉                                                                                         | 8/50 [00:01<00:03, 12.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 5.00 / 9 (55.6%):  18%|███████████████████                                                                                       | 9/50 [00:01<00:04,  8.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 10 (60.0%):  18%|██████████████████▉                                                                                      | 9/50 [00:01<00:04,  8.81it/s]2025-08-23 15:50:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 11 (54.5%):  20%|████████████████████▊                                                                                   | 10/50 [00:01<00:04,  8.81it/s]2025-08-23 15:50:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 12 (58.3%):  22%|██████████████████████▉                                                                                 | 11/50 [00:01<00:04,  8.81it/s]2025-08-23 15:50:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 13 (53.8%):  24%|████████████████████████▉                                                                               | 12/50 [00:01<00:04,  8.81it/s]2025-08-23 15:50:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 14 (57.1%):  26%|███████████████████████████                                                                             | 13/50 [00:01<00:04,  8.81it/s]2025-08-23 15:50:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 15 (53.3%):  28%|█████████████████████████████                                                                           | 14/50 [00:01<00:04,  8.81it/s]2025-08-23 15:50:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:48 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:48 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:48 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 16 (56.2%):  30%|███████████████████████████████▏                                                                        | 15/50 [00:01<00:03,  8.81it/s]2025-08-23 15:50:48 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 9.00 / 16 (56.2%):  32%|█████████████████████████████████▎                                                                      | 16/50 [00:01<00:01, 18.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 17 (52.9%):  32%|█████████████████████████████████▎                                                                      | 16/50 [00:01<00:01, 18.00it/s]2025-08-23 15:50:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:50:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 10.00 / 18 (55.6%):  34%|███████████████████████████████████                                                                    | 17/50 [00:01<00:01, 18.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 19 (57.9%):  36%|█████████████████████████████████████                                                                  | 18/50 [00:01<00:01, 18.00it/s]2025-08-23 15:50:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 20 (55.0%):  38%|███████████████████████████████████████▏                                                               | 19/50 [00:01<00:01, 18.00it/s]2025-08-23 15:50:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 11.00 / 20 (55.0%):  40%|█████████████████████████████████████████▏                                                             | 20/50 [00:01<00:02, 12.48it/s]2025-08-23 15:50:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:50:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 12.00 / 21 (57.1%):  40%|█████████████████████████████████████████▏                                                             | 20/50 [00:01<00:02, 12.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 12.00 / 22 (54.5%):  42%|███████████████████████████████████████████▎                                                           | 21/50 [00:01<00:02, 12.48it/s]2025-08-23 15:50:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 23 (52.2%):  44%|█████████████████████████████████████████████▎                                                         | 22/50 [00:01<00:02, 12.48it/s]2025-08-23 15:50:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:50:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 13.00 / 24 (54.2%):  46%|███████████████████████████████████████████████▍                                                       | 23/50 [00:01<00:02, 12.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:50:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 25 (52.0%):  48%|█████████████████████████████████████████████████▍                                                     | 24/50 [00:02<00:02, 12.48it/s]2025-08-23 15:50:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 13.00 / 25 (52.0%):  50%|███████████████████████████████████████████████████▌                                                   | 25/50 [00:02<00:02, 10.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 26 (50.0%):  50%|███████████████████████████████████████████████████▌                                                   | 25/50 [00:02<00:02, 10.58it/s]2025-08-23 15:50:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 14.00 / 27 (51.9%):  52%|█████████████████████████████████████████████████████▌                                                 | 26/50 [00:02<00:02, 10.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 14.00 / 28 (50.0%):  54%|███████████████████████████████████████████████████████▌                                               | 27/50 [00:02<00:02, 10.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:50:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 14.00 / 29 (48.3%):  56%|█████████████████████████████████████████████████████████▋                                             | 28/50 [00:02<00:02, 10.58it/s]2025-08-23 15:50:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 15.00 / 30 (50.0%):  58%|███████████████████████████████████████████████████████████▋                                           | 29/50 [00:02<00:01, 10.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 16.00 / 31 (51.6%):  60%|█████████████████████████████████████████████████████████████▊                                         | 30/50 [00:02<00:01, 10.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:49 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:49 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 32 (53.1%):  62%|███████████████████████████████████████████████████████████████▊                                       | 31/50 [00:02<00:01, 10.58it/s]2025-08-23 15:50:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:49 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:49 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:50 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:50 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:50 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 33 (54.5%):  64%|█████████████████████████████████████████████████████████████████▉                                     | 32/50 [00:02<00:01, 10.58it/s]2025-08-23 15:50:50 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 18.00 / 33 (54.5%):  66%|███████████████████████████████████████████████████████████████████▉                                   | 33/50 [00:02<00:01, 12.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:50 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:50 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 19.00 / 34 (55.9%):  66%|███████████████████████████████████████████████████████████████████▉                                   | 33/50 [00:02<00:01, 12.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:50 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:50 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:50 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:50 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:50 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 35 (54.3%):  68%|██████████████████████████████████████████████████████████████████████                                 | 34/50 [00:02<00:01, 12.85it/s]2025-08-23 15:50:50 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:50 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:50 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 20.00 / 36 (55.6%):  70%|████████████████████████████████████████████████████████████████████████                               | 35/50 [00:02<00:01, 12.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:50 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:50 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:50 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:50 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 20.00 / 37 (54.1%):  72%|██████████████████████████████████████████████████████████████████████████▏                            | 36/50 [00:02<00:01, 12.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:50 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 37 (54.1%):  74%|████████████████████████████████████████████████████████████████████████████▏                          | 37/50 [00:02<00:00, 15.24it/s]2025-08-23 15:50:50 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:50 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:50 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:50 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 38 (55.3%):  74%|████████████████████████████████████████████████████████████████████████████▏                          | 37/50 [00:02<00:00, 15.24it/s]2025-08-23 15:50:50 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:50 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:50 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:50 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 39 (53.8%):  76%|██████████████████████████████████████████████████████████████████████████████▎                        | 38/50 [00:02<00:00, 15.24it/s]2025-08-23 15:50:50 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:50 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:50 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:50 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 40 (55.0%):  78%|████████████████████████████████████████████████████████████████████████████████▎                      | 39/50 [00:02<00:00, 15.24it/s]2025-08-23 15:50:50 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:50 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:50 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:50 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:50 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 23.00 / 41 (56.1%):  80%|██████████████████████████████████████████████████████████████████████████████████▍                    | 40/50 [00:03<00:00, 15.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:50 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 41 (56.1%):  82%|████████████████████████████████████████████████████████████████████████████████████▍                  | 41/50 [00:03<00:00, 13.37it/s]2025-08-23 15:50:50 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:50 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:50:50 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 42 (57.1%):  82%|████████████████████████████████████████████████████████████████████████████████████▍                  | 41/50 [00:03<00:00, 13.37it/s]2025-08-23 15:50:50 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:50:50 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 25.00 / 43 (58.1%):  84%|██████████████████████████████████████████████████████████████████████████████████████▌                | 42/50 [00:03<00:00, 13.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:50 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:50 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 26.00 / 44 (59.1%):  86%|████████████████████████████████████████████████████████████████████████████████████████▌              | 43/50 [00:03<00:00, 13.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:50 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:50 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:50 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:50 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 27.00 / 46 (58.7%):  90%|████████████████████████████████████████████████████████████████████████████████████████████▋          | 45/50 [00:03<00:00, 16.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:50 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:50 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 28.00 / 47 (59.6%):  92%|██████████████████████████████████████████████████████████████████████████████████████████████▊        | 46/50 [00:03<00:00, 16.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:50 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:50 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 29.00 / 48 (60.4%):  96%|██████████████████████████████████████████████████████████████████████████████████████████████████▉    | 48/50 [00:03<00:00, 17.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:51 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:51 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 30.00 / 49 (61.2%):  96%|██████████████████████████████████████████████████████████████████████████████████████████████████▉    | 48/50 [00:03<00:00, 17.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:51 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:51 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 31.00 / 50 (62.0%): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 13.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/23 15:50:51 INFO dspy.evaluate.evaluate: Average Metric: 31 / 50 (62.0%)\n",
      "2025/08/23 15:50:51 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 62.0 with parameters ['Predictor 0: Instruction 5', 'Predictor 0: Few-Shot Set 3'].\n",
      "2025/08/23 15:50:51 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [66.0, 68.0, 62.0, 62.0, 68.0, 70.0, 70.0, 68.0, 62.0, 68.0, 70.0, 68.0, 74.0, 74.0, 72.0, 70.0, 72.0, 62.0]\n",
      "2025/08/23 15:50:51 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 74.0\n",
      "2025/08/23 15:50:51 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/08/23 15:50:51 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 19 / 18 =====\n",
      "\u001b[92m15:50:51 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-08-23 15:50:51 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:51 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:50:51 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:51 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:50:51 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:51 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                    | 0/50 [00:00<?, ?it/s]2025-08-23 15:50:51 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:51 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:51 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:51 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:51 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:51 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:51 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:51 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:51 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:51 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:51 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:51 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 1 (100.0%):   0%|                                                                                                                 | 0/50 [00:00<?, ?it/s]2025-08-23 15:50:51 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:51 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:51 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 1.00 / 1 (100.0%):   2%|██                                                                                                       | 1/50 [00:00<00:23,  2.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:51 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 2 (100.0%):   2%|██                                                                                                       | 1/50 [00:00<00:23,  2.07it/s]2025-08-23 15:50:51 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:51 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 3 (66.7%):   4%|████▏                                                                                                     | 2/50 [00:00<00:23,  2.07it/s]2025-08-23 15:50:51 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:51 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 4 (50.0%):   6%|██████▎                                                                                                   | 3/50 [00:00<00:22,  2.07it/s]2025-08-23 15:50:51 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:51 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:51 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:51 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:51 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:51 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:51 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:51 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 5 (60.0%):   8%|████████▍                                                                                                 | 4/50 [00:00<00:22,  2.07it/s]2025-08-23 15:50:51 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:51 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:51 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:51 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 6 (50.0%):  10%|██████████▌                                                                                               | 5/50 [00:00<00:21,  2.07it/s]2025-08-23 15:50:51 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:51 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:51 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:51 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 7 (42.9%):  12%|████████████▋                                                                                             | 6/50 [00:00<00:21,  2.07it/s]2025-08-23 15:50:51 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:51 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:51 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:51 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 8 (37.5%):  14%|██████████████▊                                                                                           | 7/50 [00:00<00:20,  2.07it/s]2025-08-23 15:50:51 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 4.00 / 9 (44.4%):  16%|████████████████▉                                                                                         | 8/50 [00:00<00:20,  2.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 9 (44.4%):  18%|███████████████████                                                                                       | 9/50 [00:00<00:03, 10.38it/s]2025-08-23 15:50:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 10 (40.0%):  18%|██████████████████▉                                                                                      | 9/50 [00:00<00:03, 10.38it/s]2025-08-23 15:50:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 5.00 / 11 (45.5%):  20%|████████████████████▊                                                                                   | 10/50 [00:00<00:03, 10.38it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 12 (50.0%):  22%|██████████████████████▉                                                                                 | 11/50 [00:00<00:03, 10.38it/s]2025-08-23 15:50:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 13 (53.8%):  24%|████████████████████████▉                                                                               | 12/50 [00:00<00:03, 10.38it/s]2025-08-23 15:50:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 14 (50.0%):  26%|███████████████████████████                                                                             | 13/50 [00:01<00:03, 10.38it/s]2025-08-23 15:50:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 15 (46.7%):  28%|█████████████████████████████                                                                           | 14/50 [00:01<00:03, 10.38it/s]2025-08-23 15:50:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 16 (50.0%):  30%|███████████████████████████████▏                                                                        | 15/50 [00:01<00:03, 10.38it/s]2025-08-23 15:50:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 17 (47.1%):  32%|█████████████████████████████████▎                                                                      | 16/50 [00:01<00:03, 10.38it/s]2025-08-23 15:50:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 8.00 / 17 (47.1%):  34%|███████████████████████████████████▎                                                                    | 17/50 [00:01<00:02, 13.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 9.00 / 18 (50.0%):  34%|███████████████████████████████████▎                                                                    | 17/50 [00:01<00:02, 13.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 19 (52.6%):  36%|█████████████████████████████████████                                                                  | 18/50 [00:01<00:02, 13.69it/s]2025-08-23 15:50:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 10.00 / 20 (50.0%):  38%|███████████████████████████████████████▏                                                               | 19/50 [00:01<00:02, 13.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 21 (47.6%):  40%|█████████████████████████████████████████▏                                                             | 20/50 [00:01<00:02, 13.69it/s]2025-08-23 15:50:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 22 (50.0%):  42%|███████████████████████████████████████████▎                                                           | 21/50 [00:01<00:02, 13.69it/s]2025-08-23 15:50:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 23 (47.8%):  44%|█████████████████████████████████████████████▎                                                         | 22/50 [00:01<00:02, 13.69it/s]2025-08-23 15:50:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:52 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:52 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:52 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 24 (50.0%):  46%|███████████████████████████████████████████████▍                                                       | 23/50 [00:01<00:01, 13.69it/s]2025-08-23 15:50:52 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 12.00 / 24 (50.0%):  48%|█████████████████████████████████████████████████▍                                                     | 24/50 [00:01<00:01, 20.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:50:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 13.00 / 25 (52.0%):  48%|█████████████████████████████████████████████████▍                                                     | 24/50 [00:01<00:01, 20.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 13.00 / 26 (50.0%):  50%|███████████████████████████████████████████████████▌                                                   | 25/50 [00:01<00:01, 20.51it/s]2025-08-23 15:50:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 13.00 / 27 (48.1%):  52%|█████████████████████████████████████████████████████▌                                                 | 26/50 [00:02<00:01, 20.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 28 (50.0%):  54%|███████████████████████████████████████████████████████▌                                               | 27/50 [00:02<00:01, 20.51it/s]2025-08-23 15:50:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 28 (50.0%):  56%|█████████████████████████████████████████████████████████▋                                             | 28/50 [00:02<00:01, 14.92it/s]2025-08-23 15:50:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 15.00 / 29 (51.7%):  56%|█████████████████████████████████████████████████████████▋                                             | 28/50 [00:02<00:01, 14.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 15.00 / 30 (50.0%):  58%|███████████████████████████████████████████████████████████▋                                           | 29/50 [00:02<00:01, 14.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 31 (51.6%):  60%|█████████████████████████████████████████████████████████████▊                                         | 30/50 [00:02<00:01, 14.92it/s]2025-08-23 15:50:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 32 (50.0%):  62%|███████████████████████████████████████████████████████████████▊                                       | 31/50 [00:02<00:01, 14.92it/s]2025-08-23 15:50:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 33 (51.5%):  64%|█████████████████████████████████████████████████████████████████▉                                     | 32/50 [00:02<00:01, 14.92it/s]2025-08-23 15:50:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 33 (51.5%):  66%|███████████████████████████████████████████████████████████████████▉                                   | 33/50 [00:02<00:01, 13.33it/s]2025-08-23 15:50:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 17.00 / 34 (50.0%):  66%|███████████████████████████████████████████████████████████████████▉                                   | 33/50 [00:02<00:01, 13.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 17.00 / 35 (48.6%):  68%|██████████████████████████████████████████████████████████████████████                                 | 34/50 [00:02<00:01, 13.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 18.00 / 36 (50.0%):  70%|████████████████████████████████████████████████████████████████████████                               | 35/50 [00:02<00:01, 13.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 19.00 / 37 (51.4%):  72%|██████████████████████████████████████████████████████████████████████████▏                            | 36/50 [00:02<00:01, 13.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 38 (52.6%):  74%|████████████████████████████████████████████████████████████████████████████▏                          | 37/50 [00:02<00:00, 13.33it/s]2025-08-23 15:50:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 39 (53.8%):  76%|██████████████████████████████████████████████████████████████████████████████▎                        | 38/50 [00:02<00:00, 13.33it/s]2025-08-23 15:50:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:53 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:53 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:53 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 40 (55.0%):  78%|████████████████████████████████████████████████████████████████████████████████▎                      | 39/50 [00:02<00:00, 13.33it/s]2025-08-23 15:50:53 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 41 (56.1%):  80%|██████████████████████████████████████████████████████████████████████████████████▍                    | 40/50 [00:02<00:00, 13.33it/s]2025-08-23 15:50:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 41 (56.1%):  82%|████████████████████████████████████████████████████████████████████████████████████▍                  | 41/50 [00:02<00:00, 14.53it/s]2025-08-23 15:50:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 24.00 / 42 (57.1%):  82%|████████████████████████████████████████████████████████████████████████████████████▍                  | 41/50 [00:02<00:00, 14.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:54 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:54 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 24.00 / 43 (55.8%):  84%|██████████████████████████████████████████████████████████████████████████████████████▌                | 42/50 [00:02<00:00, 14.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 25.00 / 44 (56.8%):  86%|████████████████████████████████████████████████████████████████████████████████████████▌              | 43/50 [00:02<00:00, 14.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 25.00 / 45 (55.6%):  88%|██████████████████████████████████████████████████████████████████████████████████████████▋            | 44/50 [00:02<00:00, 14.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 26.00 / 46 (56.5%):  90%|████████████████████████████████████████████████████████████████████████████████████████████▋          | 45/50 [00:03<00:00, 14.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 27.00 / 47 (57.4%):  92%|██████████████████████████████████████████████████████████████████████████████████████████████▊        | 46/50 [00:03<00:00, 14.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 28.00 / 48 (58.3%):  94%|████████████████████████████████████████████████████████████████████████████████████████████████▊      | 47/50 [00:03<00:00, 14.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 29.00 / 49 (59.2%):  96%|██████████████████████████████████████████████████████████████████████████████████████████████████▉    | 48/50 [00:03<00:00, 14.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:54 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 29.00 / 49 (59.2%):  98%|████████████████████████████████████████████████████████████████████████████████████████████████████▉  | 49/50 [00:03<00:00, 15.27it/s]2025-08-23 15:50:54 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 29.00 / 50 (58.0%): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 14.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/23 15:50:54 INFO dspy.evaluate.evaluate: Average Metric: 29 / 50 (58.0%)\n",
      "2025/08/23 15:50:54 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 58.0 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 5'].\n",
      "2025/08/23 15:50:54 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [66.0, 68.0, 62.0, 62.0, 68.0, 70.0, 70.0, 68.0, 62.0, 68.0, 70.0, 68.0, 74.0, 74.0, 72.0, 70.0, 72.0, 62.0, 58.0]\n",
      "2025/08/23 15:50:54 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 74.0\n",
      "2025/08/23 15:50:54 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/08/23 15:50:54 INFO dspy.teleprompt.mipro_optimizer_v2: Returning best identified program with score 74.0!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "judge_model = dspy.LM(\n",
    "    \"gemini/gemini-1.5-flash\",\n",
    "    api_key=secrets[\"GEMINI_API_KEY\"],\n",
    "    cache=False,\n",
    "    temperature=0\n",
    ")\n",
    "dspy.configure(lm=judge_model,track_usage=True,adapter=dspy.JSONAdapter())\n",
    "generate_judge_reasoning = dspy.ChainOfThought(SupportTranscriptJudge)\n",
    "\n",
    "optimizer = dspy.MIPROv2(\n",
    "    metric=match_judge_metric,\n",
    "    auto=\"medium\",\n",
    "    init_temperature=1.0,\n",
    "    seed=101\n",
    ")\n",
    "\n",
    "generate_judge_reasoning_optimized = optimizer.compile(\n",
    "    generate_judge_reasoning,\n",
    "    trainset=training_set,\n",
    "    valset=validation_set,\n",
    "    requires_permission_to_run=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d768118-19eb-4fb0-9d78-09cba468ecae",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "  0%|                                                                                                                                                   | 0/160 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:50:59 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:50:59 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 1.00 / 1 (100.0%):   0%|                                                                                                                | 0/160 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 1.00 / 1 (100.0%):   1%|▋                                                                                                       | 1/160 [00:00<01:18,  2.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 2 (100.0%):   1%|▋                                                                                                       | 1/160 [00:00<01:18,  2.04it/s]2025-08-23 15:51:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 3 (100.0%):   1%|█▎                                                                                                      | 2/160 [00:00<01:17,  2.04it/s]2025-08-23 15:51:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 4.00 / 4 (100.0%):   2%|█▉                                                                                                      | 3/160 [00:00<01:17,  2.04it/s]2025-08-23 15:51:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 5.00 / 5 (100.0%):   2%|██▌                                                                                                     | 4/160 [00:00<01:16,  2.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 6.00 / 6 (100.0%):   3%|███▎                                                                                                    | 5/160 [00:00<01:16,  2.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 7 (85.7%):   4%|███▉                                                                                                     | 6/160 [00:00<01:15,  2.04it/s]2025-08-23 15:51:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:51:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 8 (87.5%):   4%|████▌                                                                                                    | 7/160 [00:00<01:15,  2.04it/s]2025-08-23 15:51:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 9 (88.9%):   5%|█████▎                                                                                                   | 8/160 [00:00<01:14,  2.04it/s]2025-08-23 15:51:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 10 (80.0%):   6%|█████▊                                                                                                  | 9/160 [00:00<01:14,  2.04it/s]2025-08-23 15:51:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 11 (72.7%):   6%|██████▍                                                                                                | 10/160 [00:00<01:13,  2.04it/s]2025-08-23 15:51:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 12 (66.7%):   7%|███████                                                                                                | 11/160 [00:00<01:13,  2.04it/s]2025-08-23 15:51:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 13 (61.5%):   8%|███████▋                                                                                               | 12/160 [00:00<01:12,  2.04it/s]2025-08-23 15:51:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 9.00 / 14 (64.3%):   8%|████████▎                                                                                              | 13/160 [00:00<01:12,  2.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 10.00 / 15 (66.7%):   9%|████████▉                                                                                             | 14/160 [00:00<01:11,  2.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 16 (62.5%):   9%|█████████▌                                                                                            | 15/160 [00:00<01:11,  2.04it/s]2025-08-23 15:51:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 17 (64.7%):  10%|██████████▏                                                                                           | 16/160 [00:00<01:10,  2.04it/s]2025-08-23 15:51:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 11.00 / 18 (61.1%):  11%|██████████▊                                                                                           | 17/160 [00:00<01:10,  2.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 11.00 / 19 (57.9%):  11%|███████████▍                                                                                          | 18/160 [00:00<01:09,  2.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 20 (60.0%):  12%|████████████                                                                                          | 19/160 [00:00<01:09,  2.04it/s]2025-08-23 15:51:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 12.00 / 21 (57.1%):  12%|████████████▊                                                                                         | 20/160 [00:00<01:08,  2.04it/s]2025-08-23 15:51:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 22 (54.5%):  13%|█████████████▍                                                                                        | 21/160 [00:00<01:08,  2.04it/s]2025-08-23 15:51:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 12.00 / 23 (52.2%):  14%|██████████████▋                                                                                       | 23/160 [00:00<00:02, 48.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 24 (54.2%):  14%|██████████████▋                                                                                       | 23/160 [00:00<00:02, 48.33it/s]2025-08-23 15:51:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 25 (56.0%):  15%|███████████████▎                                                                                      | 24/160 [00:00<00:02, 48.33it/s]2025-08-23 15:51:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 26 (57.7%):  16%|███████████████▉                                                                                      | 25/160 [00:00<00:02, 48.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:51:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 27 (55.6%):  16%|████████████████▌                                                                                     | 26/160 [00:00<00:02, 48.33it/s]2025-08-23 15:51:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 28 (53.6%):  17%|█████████████████▏                                                                                    | 27/160 [00:01<00:02, 48.33it/s]2025-08-23 15:51:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 29 (55.2%):  18%|█████████████████▊                                                                                    | 28/160 [00:01<00:02, 48.33it/s]2025-08-23 15:51:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 30 (56.7%):  18%|██████████████████▍                                                                                   | 29/160 [00:01<00:02, 48.33it/s]2025-08-23 15:51:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 31 (58.1%):  19%|███████████████████▏                                                                                  | 30/160 [00:01<00:02, 48.33it/s]2025-08-23 15:51:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 32 (59.4%):  19%|███████████████████▊                                                                                  | 31/160 [00:01<00:02, 48.33it/s]2025-08-23 15:51:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:00 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 19.00 / 33 (57.6%):  20%|████████████████████▍                                                                                 | 32/160 [00:01<00:02, 48.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:00 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 34 (58.8%):  21%|█████████████████████                                                                                 | 33/160 [00:01<00:02, 48.33it/s]2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 34 (58.8%):  21%|█████████████████████▋                                                                                | 34/160 [00:01<00:03, 34.99it/s]2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 21.00 / 35 (60.0%):  21%|█████████████████████▋                                                                                | 34/160 [00:01<00:03, 34.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 36 (61.1%):  22%|██████████████████████▎                                                                               | 35/160 [00:01<00:03, 34.99it/s]2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 37 (62.2%):  22%|██████████████████████▉                                                                               | 36/160 [00:01<00:03, 34.99it/s]2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 38 (63.2%):  23%|███████████████████████▌                                                                              | 37/160 [00:01<00:03, 34.99it/s]2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.00 / 39 (64.1%):  24%|████████████████████████▏                                                                             | 38/160 [00:01<00:03, 34.99it/s]2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.00 / 40 (62.5%):  24%|████████████████████████▊                                                                             | 39/160 [00:01<00:03, 34.99it/s]2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 26.00 / 41 (63.4%):  25%|█████████████████████████▌                                                                            | 40/160 [00:01<00:03, 34.99it/s]2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27.00 / 42 (64.3%):  26%|██████████████████████████▏                                                                           | 41/160 [00:01<00:03, 34.99it/s]2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 28.00 / 43 (65.1%):  26%|██████████████████████████▊                                                                           | 42/160 [00:01<00:03, 34.99it/s]2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 29.00 / 44 (65.9%):  27%|███████████████████████████▍                                                                          | 43/160 [00:01<00:03, 34.99it/s]2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 29.00 / 45 (64.4%):  28%|████████████████████████████                                                                          | 44/160 [00:01<00:03, 34.99it/s]2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 30.00 / 46 (65.2%):  28%|████████████████████████████▋                                                                         | 45/160 [00:01<00:03, 34.99it/s]2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 30.00 / 47 (63.8%):  29%|█████████████████████████████▎                                                                        | 46/160 [00:01<00:03, 34.99it/s]2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 31.00 / 48 (64.6%):  29%|█████████████████████████████▉                                                                        | 47/160 [00:01<00:02, 40.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 32.00 / 49 (65.3%):  30%|██████████████████████████████▌                                                                       | 48/160 [00:01<00:02, 40.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 33.00 / 50 (66.0%):  31%|███████████████████████████████▏                                                                      | 49/160 [00:01<00:02, 40.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 34.00 / 51 (66.7%):  31%|███████████████████████████████▉                                                                      | 50/160 [00:01<00:02, 40.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 35.00 / 52 (67.3%):  32%|████████████████████████████████▌                                                                     | 51/160 [00:01<00:02, 40.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 36.00 / 53 (67.9%):  32%|█████████████████████████████████▏                                                                    | 52/160 [00:01<00:02, 40.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 36.00 / 54 (66.7%):  33%|█████████████████████████████████▊                                                                    | 53/160 [00:01<00:02, 40.91it/s]2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 36.00 / 54 (66.7%):  34%|██████████████████████████████████▍                                                                   | 54/160 [00:01<00:02, 38.53it/s]2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 37.00 / 55 (67.3%):  34%|██████████████████████████████████▍                                                                   | 54/160 [00:01<00:02, 38.53it/s]2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 38.00 / 56 (67.9%):  34%|███████████████████████████████████                                                                   | 55/160 [00:01<00:02, 38.53it/s]2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 39.00 / 57 (68.4%):  35%|███████████████████████████████████▋                                                                  | 56/160 [00:01<00:02, 38.53it/s]2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 40.00 / 58 (69.0%):  36%|████████████████████████████████████▎                                                                 | 57/160 [00:01<00:02, 38.53it/s]2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 41.00 / 59 (69.5%):  36%|████████████████████████████████████▉                                                                 | 58/160 [00:01<00:02, 38.53it/s]2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 42.00 / 60 (70.0%):  37%|█████████████████████████████████████▌                                                                | 59/160 [00:01<00:02, 38.53it/s]2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 43.00 / 61 (70.5%):  38%|██████████████████████████████████████▎                                                               | 60/160 [00:01<00:02, 38.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 44.00 / 62 (71.0%):  38%|██████████████████████████████████████▉                                                               | 61/160 [00:01<00:02, 38.53it/s]2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 45.00 / 63 (71.4%):  39%|███████████████████████████████████████▌                                                              | 62/160 [00:01<00:02, 38.53it/s]2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 46.00 / 64 (71.9%):  39%|████████████████████████████████████████▏                                                             | 63/160 [00:01<00:02, 38.53it/s]2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 47.00 / 65 (72.3%):  40%|████████████████████████████████████████▊                                                             | 64/160 [00:01<00:02, 38.53it/s]2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 48.00 / 66 (72.7%):  41%|█████████████████████████████████████████▍                                                            | 65/160 [00:01<00:02, 38.53it/s]2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 48.00 / 66 (72.7%):  41%|██████████████████████████████████████████                                                            | 66/160 [00:01<00:01, 48.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 49.00 / 67 (73.1%):  41%|██████████████████████████████████████████                                                            | 66/160 [00:01<00:01, 48.65it/s]2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 49.00 / 68 (72.1%):  42%|██████████████████████████████████████████▋                                                           | 67/160 [00:01<00:01, 48.65it/s]2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 50.00 / 69 (72.5%):  42%|███████████████████████████████████████████▎                                                          | 68/160 [00:01<00:01, 48.65it/s]2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 50.00 / 70 (71.4%):  43%|███████████████████████████████████████████▉                                                          | 69/160 [00:01<00:01, 48.65it/s]2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 50.00 / 71 (70.4%):  44%|████████████████████████████████████████████▋                                                         | 70/160 [00:01<00:01, 48.65it/s]2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 50.00 / 72 (69.4%):  44%|█████████████████████████████████████████████▎                                                        | 71/160 [00:01<00:01, 48.65it/s]2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 51.00 / 73 (69.9%):  45%|█████████████████████████████████████████████▉                                                        | 72/160 [00:01<00:01, 48.65it/s]2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 51.00 / 73 (69.9%):  46%|██████████████████████████████████████████████▌                                                       | 73/160 [00:01<00:02, 38.09it/s]2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 51.00 / 74 (68.9%):  46%|██████████████████████████████████████████████▌                                                       | 73/160 [00:01<00:02, 38.09it/s]2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 51.00 / 75 (68.0%):  46%|███████████████████████████████████████████████▏                                                      | 74/160 [00:01<00:02, 38.09it/s]2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 51.00 / 76 (67.1%):  47%|███████████████████████████████████████████████▊                                                      | 75/160 [00:01<00:02, 38.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 52.00 / 77 (67.5%):  48%|████████████████████████████████████████████████▍                                                     | 76/160 [00:01<00:02, 38.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 53.00 / 78 (67.9%):  48%|█████████████████████████████████████████████████                                                     | 77/160 [00:01<00:02, 38.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 54.00 / 79 (68.4%):  49%|█████████████████████████████████████████████████▋                                                    | 78/160 [00:01<00:02, 38.09it/s]2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 55.00 / 80 (68.8%):  49%|██████████████████████████████████████████████████▎                                                   | 79/160 [00:02<00:02, 38.09it/s]2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 56.00 / 81 (69.1%):  50%|███████████████████████████████████████████████████                                                   | 80/160 [00:02<00:02, 38.09it/s]2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:01 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 57.00 / 82 (69.5%):  51%|███████████████████████████████████████████████████▋                                                  | 81/160 [00:02<00:02, 38.09it/s]2025-08-23 15:51:01 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 58.00 / 83 (69.9%):  51%|████████████████████████████████████████████████████▎                                                 | 82/160 [00:02<00:02, 38.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 58.00 / 83 (69.9%):  52%|████████████████████████████████████████████████████▉                                                 | 83/160 [00:02<00:01, 47.31it/s]2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 58.00 / 84 (69.0%):  52%|████████████████████████████████████████████████████▉                                                 | 83/160 [00:02<00:01, 47.31it/s]2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 59.00 / 85 (69.4%):  52%|█████████████████████████████████████████████████████▌                                                | 84/160 [00:02<00:01, 47.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 60.00 / 86 (69.8%):  53%|██████████████████████████████████████████████████████▏                                               | 85/160 [00:02<00:01, 47.31it/s]2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 60.00 / 87 (69.0%):  54%|██████████████████████████████████████████████████████▊                                               | 86/160 [00:02<00:01, 47.31it/s]2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 61.00 / 88 (69.3%):  54%|███████████████████████████████████████████████████████▍                                              | 87/160 [00:02<00:01, 47.31it/s]2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 62.00 / 89 (69.7%):  55%|████████████████████████████████████████████████████████                                              | 88/160 [00:02<00:01, 47.31it/s]2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 63.00 / 90 (70.0%):  56%|████████████████████████████████████████████████████████▋                                             | 89/160 [00:02<00:01, 47.31it/s]2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 63.00 / 90 (70.0%):  56%|█████████████████████████████████████████████████████████▍                                            | 90/160 [00:02<00:01, 50.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 63.00 / 91 (69.2%):  56%|█████████████████████████████████████████████████████████▍                                            | 90/160 [00:02<00:01, 50.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 63.00 / 92 (68.5%):  57%|██████████████████████████████████████████████████████████                                            | 91/160 [00:02<00:01, 50.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 64.00 / 93 (68.8%):  57%|██████████████████████████████████████████████████████████▋                                           | 92/160 [00:02<00:01, 50.56it/s]2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 65.00 / 94 (69.1%):  58%|███████████████████████████████████████████████████████████▎                                          | 93/160 [00:02<00:01, 50.56it/s]2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 65.00 / 95 (68.4%):  59%|███████████████████████████████████████████████████████████▉                                          | 94/160 [00:02<00:01, 50.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 66.00 / 96 (68.8%):  59%|████████████████████████████████████████████████████████████▌                                         | 95/160 [00:02<00:01, 50.56it/s]2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 66.00 / 97 (68.0%):  60%|█████████████████████████████████████████████████████████████▏                                        | 96/160 [00:02<00:01, 50.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 66.00 / 97 (68.0%):  61%|█████████████████████████████████████████████████████████████▊                                        | 97/160 [00:02<00:01, 41.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 66.00 / 98 (67.3%):  61%|█████████████████████████████████████████████████████████████▊                                        | 97/160 [00:02<00:01, 41.37it/s]2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 66.00 / 99 (66.7%):  61%|██████████████████████████████████████████████████████████████▍                                       | 98/160 [00:02<00:01, 41.37it/s]2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 67.00 / 100 (67.0%):  62%|██████████████████████████████████████████████████████████████▍                                      | 99/160 [00:02<00:01, 41.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 68.00 / 101 (67.3%):  62%|██████████████████████████████████████████████████████████████▌                                     | 100/160 [00:02<00:01, 41.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 69.00 / 102 (67.6%):  63%|███████████████████████████████████████████████████████████████▏                                    | 101/160 [00:02<00:01, 41.37it/s]2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 70.00 / 103 (68.0%):  64%|███████████████████████████████████████████████████████████████▋                                    | 102/160 [00:02<00:01, 41.37it/s]2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 70.00 / 104 (67.3%):  65%|█████████████████████████████████████████████████████████████████                                   | 104/160 [00:02<00:01, 46.02it/s]2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 70.00 / 105 (66.7%):  65%|█████████████████████████████████████████████████████████████████                                   | 104/160 [00:02<00:01, 46.02it/s]2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 70.00 / 106 (66.0%):  66%|█████████████████████████████████████████████████████████████████▋                                  | 105/160 [00:02<00:01, 46.02it/s]2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 71.00 / 107 (66.4%):  66%|██████████████████████████████████████████████████████████████████▎                                 | 106/160 [00:02<00:01, 46.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 72.00 / 108 (66.7%):  67%|██████████████████████████████████████████████████████████████████▉                                 | 107/160 [00:02<00:01, 46.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 72.00 / 109 (66.1%):  68%|███████████████████████████████████████████████████████████████████▌                                | 108/160 [00:02<00:01, 46.02it/s]2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 73.00 / 110 (66.4%):  68%|████████████████████████████████████████████████████████████████████▏                               | 109/160 [00:02<00:01, 46.02it/s]2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 74.00 / 111 (66.7%):  69%|████████████████████████████████████████████████████████████████████▊                               | 110/160 [00:02<00:01, 46.02it/s]2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 75.00 / 112 (67.0%):  69%|█████████████████████████████████████████████████████████████████████▍                              | 111/160 [00:02<00:01, 46.02it/s]2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 76.00 / 113 (67.3%):  70%|██████████████████████████████████████████████████████████████████████                              | 112/160 [00:02<00:01, 46.02it/s]2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 76.00 / 113 (67.3%):  71%|██████████████████████████████████████████████████████████████████████▋                             | 113/160 [00:02<00:00, 52.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 77.00 / 114 (67.5%):  71%|██████████████████████████████████████████████████████████████████████▋                             | 113/160 [00:02<00:00, 52.11it/s]2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 78.00 / 115 (67.8%):  71%|███████████████████████████████████████████████████████████████████████▎                            | 114/160 [00:02<00:00, 52.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 79.00 / 116 (68.1%):  72%|███████████████████████████████████████████████████████████████████████▉                            | 115/160 [00:02<00:00, 52.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 79.00 / 117 (67.5%):  72%|████████████████████████████████████████████████████████████████████████▌                           | 116/160 [00:02<00:00, 52.11it/s]2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 80.00 / 118 (67.8%):  73%|█████████████████████████████████████████████████████████████████████████▏                          | 117/160 [00:02<00:00, 52.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 81.00 / 119 (68.1%):  74%|█████████████████████████████████████████████████████████████████████████▊                          | 118/160 [00:02<00:00, 52.11it/s]2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 81.00 / 120 (67.5%):  74%|██████████████████████████████████████████████████████████████████████████▍                         | 119/160 [00:02<00:00, 52.11it/s]2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 81.00 / 120 (67.5%):  75%|███████████████████████████████████████████████████████████████████████████                         | 120/160 [00:02<00:00, 49.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 82.00 / 121 (67.8%):  75%|███████████████████████████████████████████████████████████████████████████                         | 120/160 [00:02<00:00, 49.30it/s]2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 83.00 / 122 (68.0%):  76%|███████████████████████████████████████████████████████████████████████████▋                        | 121/160 [00:02<00:00, 49.30it/s]2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 84.00 / 123 (68.3%):  76%|████████████████████████████████████████████████████████████████████████████▎                       | 122/160 [00:02<00:00, 49.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 84.00 / 124 (67.7%):  77%|████████████████████████████████████████████████████████████████████████████▉                       | 123/160 [00:02<00:00, 49.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 85.00 / 125 (68.0%):  78%|█████████████████████████████████████████████████████████████████████████████▌                      | 124/160 [00:02<00:00, 49.30it/s]2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 86.00 / 126 (68.3%):  78%|██████████████████████████████████████████████████████████████████████████████▏                     | 125/160 [00:02<00:00, 49.30it/s]2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 86.00 / 126 (68.3%):  79%|██████████████████████████████████████████████████████████████████████████████▊                     | 126/160 [00:02<00:00, 47.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 87.00 / 127 (68.5%):  79%|██████████████████████████████████████████████████████████████████████████████▊                     | 126/160 [00:02<00:00, 47.83it/s]2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 88.00 / 128 (68.8%):  79%|███████████████████████████████████████████████████████████████████████████████▍                    | 127/160 [00:03<00:00, 47.83it/s]2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 88.00 / 129 (68.2%):  80%|████████████████████████████████████████████████████████████████████████████████                    | 128/160 [00:03<00:00, 47.83it/s]2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 89.00 / 130 (68.5%):  81%|████████████████████████████████████████████████████████████████████████████████▋                   | 129/160 [00:03<00:00, 47.83it/s]2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:02 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 90.00 / 131 (68.7%):  81%|█████████████████████████████████████████████████████████████████████████████████▎                  | 130/160 [00:03<00:00, 47.83it/s]2025-08-23 15:51:02 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 91.00 / 132 (68.9%):  82%|█████████████████████████████████████████████████████████████████████████████████▉                  | 131/160 [00:03<00:00, 47.83it/s]2025-08-23 15:51:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 91.00 / 132 (68.9%):  82%|██████████████████████████████████████████████████████████████████████████████████▌                 | 132/160 [00:03<00:00, 49.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 92.00 / 133 (69.2%):  82%|██████████████████████████████████████████████████████████████████████████████████▌                 | 132/160 [00:03<00:00, 49.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:51:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 92.00 / 134 (68.7%):  83%|███████████████████████████████████████████████████████████████████████████████████▏                | 133/160 [00:03<00:00, 49.92it/s]2025-08-23 15:51:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 92.00 / 135 (68.1%):  84%|███████████████████████████████████████████████████████████████████████████████████▊                | 134/160 [00:03<00:00, 49.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 93.00 / 136 (68.4%):  84%|████████████████████████████████████████████████████████████████████████████████████▍               | 135/160 [00:03<00:00, 49.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:03 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:03 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 94.00 / 137 (68.6%):  85%|█████████████████████████████████████████████████████████████████████████████████████               | 136/160 [00:03<00:00, 49.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 95.00 / 138 (68.8%):  86%|██████████████████████████████████████████████████████████████████████████████████████▎             | 138/160 [00:03<00:00, 50.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 96.00 / 139 (69.1%):  86%|██████████████████████████████████████████████████████████████████████████████████████▎             | 138/160 [00:03<00:00, 50.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 97.00 / 140 (69.3%):  87%|██████████████████████████████████████████████████████████████████████████████████████▉             | 139/160 [00:03<00:00, 50.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 99.00 / 142 (69.7%):  88%|████████████████████████████████████████████████████████████████████████████████████████▏           | 141/160 [00:03<00:00, 50.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 100.00 / 143 (69.9%):  89%|███████████████████████████████████████████████████████████████████████████████████████▊           | 142/160 [00:03<00:00, 50.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 100.00 / 144 (69.4%):  90%|█████████████████████████████████████████████████████████████████████████████████████████          | 144/160 [00:03<00:00, 44.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 100.00 / 145 (69.0%):  90%|█████████████████████████████████████████████████████████████████████████████████████████          | 144/160 [00:03<00:00, 44.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 100.00 / 146 (68.5%):  91%|█████████████████████████████████████████████████████████████████████████████████████████▋         | 145/160 [00:03<00:00, 44.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 100.00 / 147 (68.0%):  91%|██████████████████████████████████████████████████████████████████████████████████████████▎        | 146/160 [00:03<00:00, 44.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 101.00 / 148 (68.2%):  92%|██████████████████████████████████████████████████████████████████████████████████████████▉        | 147/160 [00:03<00:00, 44.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 102.00 / 149 (68.5%):  93%|████████████████████████████████████████████████████████████████████████████████████████████▏      | 149/160 [00:03<00:00, 44.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 102.00 / 150 (68.0%):  93%|████████████████████████████████████████████████████████████████████████████████████████████▏      | 149/160 [00:03<00:00, 44.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 103.00 / 151 (68.2%):  94%|████████████████████████████████████████████████████████████████████████████████████████████▊      | 150/160 [00:03<00:00, 44.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 103.00 / 152 (67.8%):  94%|█████████████████████████████████████████████████████████████████████████████████████████████▍     | 151/160 [00:03<00:00, 44.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 104.00 / 153 (68.0%):  95%|██████████████████████████████████████████████████████████████████████████████████████████████     | 152/160 [00:03<00:00, 44.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 105.00 / 154 (68.2%):  96%|██████████████████████████████████████████████████████████████████████████████████████████████▋    | 153/160 [00:03<00:00, 44.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 106.00 / 155 (68.4%):  97%|███████████████████████████████████████████████████████████████████████████████████████████████▉   | 155/160 [00:03<00:00, 43.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 107.00 / 156 (68.6%):  97%|███████████████████████████████████████████████████████████████████████████████████████████████▉   | 155/160 [00:03<00:00, 43.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 108.00 / 157 (68.8%):  98%|████████████████████████████████████████████████████████████████████████████████████████████████▌  | 156/160 [00:03<00:00, 43.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 109.00 / 158 (69.0%):  98%|█████████████████████████████████████████████████████████████████████████████████████████████████▏ | 157/160 [00:03<00:00, 43.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 109.00 / 159 (68.6%):  99%|█████████████████████████████████████████████████████████████████████████████████████████████████▊ | 158/160 [00:03<00:00, 43.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:03 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:03 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 110.00 / 160 (68.8%): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 160/160 [00:03<00:00, 40.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/23 15:51:03 INFO dspy.evaluate.evaluate: Average Metric: 110 / 160 (68.8%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>example_satisfied</th>\n",
       "      <th>_id</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>pred_satisfied</th>\n",
       "      <th>match_judge_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: I need thi...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_0</td>\n",
       "      <td>Agent is trying to help but needs more information.  The agent's r...</td>\n",
       "      <td>false</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: traveling ...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_1</td>\n",
       "      <td>Agent repeatedly deflected the customer's request for assistance w...</td>\n",
       "      <td>false</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: Looks like...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_2</td>\n",
       "      <td>The agent acknowledges the customer's statement but doesn't offer ...</td>\n",
       "      <td>false</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: I am bring...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_3</td>\n",
       "      <td>The agent's response is helpful and provides necessary information...</td>\n",
       "      <td>true</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: I printed ...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_4</td>\n",
       "      <td>Agent initially misunderstood but quickly clarified and provided t...</td>\n",
       "      <td>true</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Company: American Airlines Conversation Transcript so far: Custome...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_155</td>\n",
       "      <td>The agent apologized and offered further assistance with American ...</td>\n",
       "      <td>true</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: In email, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_156</td>\n",
       "      <td>The agent acknowledged the problem and promised to forward it to t...</td>\n",
       "      <td>true</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: I am looki...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_157</td>\n",
       "      <td>The agent acknowledged the request and is actively working on it.</td>\n",
       "      <td>false</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Company: Delta Air Lines Transcript so far: Customer: I fly from B...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_158</td>\n",
       "      <td>The agent's response is not completely satisfactory as it does not...</td>\n",
       "      <td>false</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: What happe...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_159</td>\n",
       "      <td>The agent's response is unhelpful and doesn't provide a clear solu...</td>\n",
       "      <td>false</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                transcript  \\\n",
       "0    Company: American Airlines Transcript so far: Customer: I need thi...   \n",
       "1    Company: American Airlines Transcript so far: Customer: traveling ...   \n",
       "2    Company: American Airlines Transcript so far: Customer: Looks like...   \n",
       "3    Company: American Airlines Transcript so far: Customer: I am bring...   \n",
       "4    Company: American Airlines Transcript so far: Customer: I printed ...   \n",
       "..                                                                     ...   \n",
       "155  Company: American Airlines Conversation Transcript so far: Custome...   \n",
       "156  Company: American Airlines Transcript so far: Customer: In email, ...   \n",
       "157  Company: American Airlines Transcript so far: Customer: I am looki...   \n",
       "158  Company: Delta Air Lines Transcript so far: Customer: I fly from B...   \n",
       "159  Company: American Airlines Transcript so far: Customer: What happe...   \n",
       "\n",
       "    example_satisfied          _id  \\\n",
       "0                True    example_0   \n",
       "1                True    example_1   \n",
       "2               False    example_2   \n",
       "3                True    example_3   \n",
       "4                True    example_4   \n",
       "..                ...          ...   \n",
       "155              True  example_155   \n",
       "156              True  example_156   \n",
       "157             False  example_157   \n",
       "158             False  example_158   \n",
       "159              True  example_159   \n",
       "\n",
       "                                                                 reasoning  \\\n",
       "0    Agent is trying to help but needs more information.  The agent's r...   \n",
       "1    Agent repeatedly deflected the customer's request for assistance w...   \n",
       "2    The agent acknowledges the customer's statement but doesn't offer ...   \n",
       "3    The agent's response is helpful and provides necessary information...   \n",
       "4    Agent initially misunderstood but quickly clarified and provided t...   \n",
       "..                                                                     ...   \n",
       "155  The agent apologized and offered further assistance with American ...   \n",
       "156  The agent acknowledged the problem and promised to forward it to t...   \n",
       "157      The agent acknowledged the request and is actively working on it.   \n",
       "158  The agent's response is not completely satisfactory as it does not...   \n",
       "159  The agent's response is unhelpful and doesn't provide a clear solu...   \n",
       "\n",
       "    pred_satisfied match_judge_metric  \n",
       "0            false                     \n",
       "1            false                     \n",
       "2            false             ✔️ [1]  \n",
       "3             true             ✔️ [1]  \n",
       "4             true             ✔️ [1]  \n",
       "..             ...                ...  \n",
       "155           true             ✔️ [1]  \n",
       "156           true             ✔️ [1]  \n",
       "157          false             ✔️ [1]  \n",
       "158          false             ✔️ [1]  \n",
       "159          false                     \n",
       "\n",
       "[160 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimized_score = evaluator(generate_judge_reasoning_optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "21b813ff-2cff-440a-b3fd-04882123fbd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68.75"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c64ab9c-df28-45bc-bc38-bd9dc87d628b",
   "metadata": {},
   "source": [
    "## Check against validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0c5e0063-0dd7-4d99-bba5-615437dbad8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_valid = dspy.Evaluate(\n",
    "    metric=match_judge_metric,\n",
    "    devset=validation_set,\n",
    "    display_table=True,\n",
    "    display_progress=True,\n",
    "    num_threads=24,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3f656449-3042-4ba5-b666-c1d0f16f0dde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "\u001b[92m15:51:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "2025-08-23 15:51:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "  0%|                                                                                                                                                    | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:36 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:36 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 1 (100.0%):   0%|                                                                                                                 | 0/50 [00:00<?, ?it/s]2025-08-23 15:51:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 1.00 / 1 (100.0%):   2%|██                                                                                                       | 1/50 [00:00<00:24,  2.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 2.00 / 2 (100.0%):   2%|██                                                                                                       | 1/50 [00:00<00:24,  2.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 3.00 / 3 (100.0%):   4%|████▏                                                                                                    | 2/50 [00:00<00:23,  2.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 4.00 / 4 (100.0%):   6%|██████▎                                                                                                  | 3/50 [00:00<00:23,  2.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 6 (100.0%):  10%|██████████▌                                                                                              | 5/50 [00:00<00:22,  2.03it/s]2025-08-23 15:51:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 7 (85.7%):  12%|████████████▋                                                                                             | 6/50 [00:00<00:21,  2.03it/s]2025-08-23 15:51:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 8 (87.5%):  14%|██████████████▊                                                                                           | 7/50 [00:00<00:21,  2.03it/s]2025-08-23 15:51:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 8.00 / 9 (88.9%):  16%|████████████████▉                                                                                         | 8/50 [00:00<00:20,  2.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 10 (90.0%):  18%|██████████████████▉                                                                                      | 9/50 [00:00<00:20,  2.03it/s]2025-08-23 15:51:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 10.00 / 11 (90.9%):  20%|████████████████████▌                                                                                  | 10/50 [00:00<00:19,  2.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 12 (83.3%):  22%|██████████████████████▋                                                                                | 11/50 [00:00<00:19,  2.03it/s]2025-08-23 15:51:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 13 (84.6%):  24%|████████████████████████▋                                                                              | 12/50 [00:00<00:18,  2.03it/s]2025-08-23 15:51:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 14 (85.7%):  26%|██████████████████████████▊                                                                            | 13/50 [00:00<00:18,  2.03it/s]2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 12.00 / 15 (80.0%):  28%|████████████████████████████▊                                                                          | 14/50 [00:00<00:17,  2.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 16 (81.2%):  30%|██████████████████████████████▉                                                                        | 15/50 [00:00<00:17,  2.03it/s]2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 14.00 / 17 (82.4%):  32%|████████████████████████████████▉                                                                      | 16/50 [00:00<00:16,  2.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 15.00 / 18 (83.3%):  34%|███████████████████████████████████                                                                    | 17/50 [00:00<00:16,  2.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 19 (84.2%):  36%|█████████████████████████████████████                                                                  | 18/50 [00:00<00:15,  2.03it/s]2025-08-23 15:51:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 20 (85.0%):  38%|███████████████████████████████████████▏                                                               | 19/50 [00:00<00:15,  2.03it/s]2025-08-23 15:51:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 21 (85.7%):  40%|█████████████████████████████████████████▏                                                             | 20/50 [00:00<00:14,  2.03it/s]2025-08-23 15:51:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 18.00 / 21 (85.7%):  42%|███████████████████████████████████████████▎                                                           | 21/50 [00:00<00:00, 45.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 22 (81.8%):  42%|███████████████████████████████████████████▎                                                           | 21/50 [00:00<00:00, 45.84it/s]2025-08-23 15:51:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 23 (82.6%):  44%|█████████████████████████████████████████████▎                                                         | 22/50 [00:00<00:00, 45.84it/s]2025-08-23 15:51:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 24 (79.2%):  46%|███████████████████████████████████████████████▍                                                       | 23/50 [00:00<00:00, 45.84it/s]2025-08-23 15:51:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 25 (76.0%):  48%|█████████████████████████████████████████████████▍                                                     | 24/50 [00:01<00:00, 45.84it/s]2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 26 (76.9%):  50%|███████████████████████████████████████████████████▌                                                   | 25/50 [00:01<00:00, 45.84it/s]2025-08-23 15:51:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:3230 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = gemini\n",
      "Average Metric: 20.00 / 27 (74.1%):  52%|█████████████████████████████████████████████████████▌                                                 | 26/50 [00:01<00:00, 45.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 22.00 / 29 (75.9%):  56%|█████████████████████████████████████████████████████████▋                                             | 28/50 [00:01<00:00, 45.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 23.00 / 30 (76.7%):  58%|███████████████████████████████████████████████████████████▋                                           | 29/50 [00:01<00:00, 45.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 24.00 / 31 (77.4%):  60%|█████████████████████████████████████████████████████████████▊                                         | 30/50 [00:01<00:00, 45.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 24.00 / 32 (75.0%):  62%|███████████████████████████████████████████████████████████████▊                                       | 31/50 [00:01<00:00, 45.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 24.00 / 33 (72.7%):  66%|███████████████████████████████████████████████████████████████████▉                                   | 33/50 [00:01<00:00, 32.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 25.00 / 34 (73.5%):  66%|███████████████████████████████████████████████████████████████████▉                                   | 33/50 [00:01<00:00, 32.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 25.00 / 35 (71.4%):  68%|██████████████████████████████████████████████████████████████████████                                 | 34/50 [00:01<00:00, 32.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 25.00 / 36 (69.4%):  70%|████████████████████████████████████████████████████████████████████████                               | 35/50 [00:01<00:00, 32.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 25.00 / 37 (67.6%):  72%|██████████████████████████████████████████████████████████████████████████▏                            | 36/50 [00:01<00:00, 32.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 25.00 / 38 (65.8%):  74%|████████████████████████████████████████████████████████████████████████████▏                          | 37/50 [00:01<00:00, 32.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 26.00 / 39 (66.7%):  76%|██████████████████████████████████████████████████████████████████████████████▎                        | 38/50 [00:01<00:00, 32.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 27.00 / 40 (67.5%):  78%|████████████████████████████████████████████████████████████████████████████████▎                      | 39/50 [00:01<00:00, 32.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 28.00 / 41 (68.3%):  80%|██████████████████████████████████████████████████████████████████████████████████▍                    | 40/50 [00:01<00:00, 32.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 29.00 / 42 (69.0%):  82%|████████████████████████████████████████████████████████████████████████████████████▍                  | 41/50 [00:01<00:00, 32.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 30.00 / 43 (69.8%):  84%|██████████████████████████████████████████████████████████████████████████████████████▌                | 42/50 [00:01<00:00, 32.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 31.00 / 44 (70.5%):  86%|████████████████████████████████████████████████████████████████████████████████████████▌              | 43/50 [00:01<00:00, 32.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 32.00 / 45 (71.1%):  88%|██████████████████████████████████████████████████████████████████████████████████████████▋            | 44/50 [00:01<00:00, 32.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 33.00 / 46 (71.7%):  90%|████████████████████████████████████████████████████████████████████████████████████████████▋          | 45/50 [00:01<00:00, 32.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 34.00 / 47 (72.3%):  92%|██████████████████████████████████████████████████████████████████████████████████████████████▊        | 46/50 [00:01<00:00, 32.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:37 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 35.00 / 48 (72.9%):  96%|██████████████████████████████████████████████████████████████████████████████████████████████████▉    | 48/50 [00:01<00:00, 47.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 35.00 / 49 (71.4%):  96%|██████████████████████████████████████████████████████████████████████████████████████████████████▉    | 48/50 [00:01<00:00, 47.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:51:38 - LiteLLM:INFO\u001b[0m: utils.py:1239 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 15:51:38 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "Average Metric: 36.00 / 50 (72.0%): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 29.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/23 15:51:38 INFO dspy.evaluate.evaluate: Average Metric: 36 / 50 (72.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>example_satisfied</th>\n",
       "      <th>_id</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>pred_satisfied</th>\n",
       "      <th>match_judge_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: I started ...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_110</td>\n",
       "      <td>Agent provided helpful information and alternative solutions.</td>\n",
       "      <td>true</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Company: British Airways Transcript so far: Customer: We have a fl...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_111</td>\n",
       "      <td>The agent thoroughly addresses the customer's concerns, providing ...</td>\n",
       "      <td>true</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: I have 2 s...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_112</td>\n",
       "      <td>The agent initially gave a negative response but then offered a he...</td>\n",
       "      <td>true</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: I want to ...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_113</td>\n",
       "      <td>The agent did not answer the customer's questions about the AAdvan...</td>\n",
       "      <td>false</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: We're due ...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_114</td>\n",
       "      <td>Agent correctly identified the problem and gave a clear solution.</td>\n",
       "      <td>true</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: I'm having...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_115</td>\n",
       "      <td>The agent offered a helpful solution but didn't directly address t...</td>\n",
       "      <td>false</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: I'm travel...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_116</td>\n",
       "      <td>The agent provided a helpful and accurate response by directing th...</td>\n",
       "      <td>true</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: Can I chec...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_117</td>\n",
       "      <td>The agent provided a helpful and complete answer to the customer's...</td>\n",
       "      <td>true</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: Could you ...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_118</td>\n",
       "      <td>The agent initially gave a correct, albeit unhelpful response, but...</td>\n",
       "      <td>true</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: I work as ...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_119</td>\n",
       "      <td>The agent repeatedly fails to understand the customer's request, l...</td>\n",
       "      <td>false</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: @cname- Du...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_120</td>\n",
       "      <td>The agent's response is polite and acknowledges the problem, offer...</td>\n",
       "      <td>false</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: I would li...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_121</td>\n",
       "      <td>Agent's initial response was unhelpful, but the follow-up was sati...</td>\n",
       "      <td>true</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: Hi there, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_122</td>\n",
       "      <td>The agent is following the standard procedure to access the custom...</td>\n",
       "      <td>true</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: I have boo...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_123</td>\n",
       "      <td>The agent's response is unclear and potentially inaccurate regardi...</td>\n",
       "      <td>false</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: I was told...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_124</td>\n",
       "      <td>The agent showed empathy and offered a solution to investigate the...</td>\n",
       "      <td>true</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: I cannot f...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_125</td>\n",
       "      <td>Agent provided a helpful and accurate solution.</td>\n",
       "      <td>true</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: Hi, I am t...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_126</td>\n",
       "      <td>The agent correctly identified that the query was outside their pu...</td>\n",
       "      <td>false</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Company: Amtrak Conversation Transcript so far: Customer: Our syst...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_127</td>\n",
       "      <td>The agent provided the requested confirmation number and offered f...</td>\n",
       "      <td>true</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Company: Spirit Airlines Transcript so far: Customer: I'm allowed ...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_128</td>\n",
       "      <td>The agent did not provide a clear answer and offered an apology in...</td>\n",
       "      <td>false</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: Can anyone...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_129</td>\n",
       "      <td>The agent initially gave inaccurate information about standby and ...</td>\n",
       "      <td>true</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Company: Delta Air Lines Transcript so far: Customer: A friend and...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_130</td>\n",
       "      <td>The agent's response is unhelpful; it doesn't offer a solution and...</td>\n",
       "      <td>false</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: There are ...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_131</td>\n",
       "      <td>Agent's initial response is unhelpful; the follow-up is slightly b...</td>\n",
       "      <td>false</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: We travell...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_132</td>\n",
       "      <td>Agent showed empathy and offered to check for exceptions.</td>\n",
       "      <td>true</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: I can't fi...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_133</td>\n",
       "      <td>Agent offered multiple solutions, escalating to a potentially fast...</td>\n",
       "      <td>true</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: We are hav...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_134</td>\n",
       "      <td>Agent is understanding but still requests sensitive information, a...</td>\n",
       "      <td>false</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: i am flyin...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_135</td>\n",
       "      <td>The agent's response is unhelpful; it doesn't directly answer the ...</td>\n",
       "      <td>false</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Company: Delta Air Lines Conversation Transcript so far: Customer:...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_136</td>\n",
       "      <td>The agent's response is helpful and offers a practical solution to...</td>\n",
       "      <td>true</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: I am flyin...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_137</td>\n",
       "      <td>Agent provided helpful information and addressed customer's concer...</td>\n",
       "      <td>true</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: I have see...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_138</td>\n",
       "      <td>The agent answered the customer's questions clearly and concisely,...</td>\n",
       "      <td>true</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: I just tho...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_139</td>\n",
       "      <td>Agent gave good advice, but could have offered more proactive solu...</td>\n",
       "      <td>true</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: I am tryin...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_140</td>\n",
       "      <td>The agent did not solve the problem; they only offered an alternat...</td>\n",
       "      <td>false</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: I'm intere...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_141</td>\n",
       "      <td>The agent's response is helpful and addresses the customer's reque...</td>\n",
       "      <td>true</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: I am trave...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_142</td>\n",
       "      <td>The agent did not directly answer the customer's question about ba...</td>\n",
       "      <td>false</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: I have a f...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_143</td>\n",
       "      <td>Agent provides a realistic assessment of time constraints and offe...</td>\n",
       "      <td>true</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: I have a d...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_144</td>\n",
       "      <td>Agent is efficient and empathetic to the urgency of the situation.</td>\n",
       "      <td>true</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: Hi, I have...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_145</td>\n",
       "      <td>The agent answered the questions accurately but could have provide...</td>\n",
       "      <td>false</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: I just enr...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_146</td>\n",
       "      <td>The agent's response is polite but lacks specific instructions on ...</td>\n",
       "      <td>false</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: I have boo...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_147</td>\n",
       "      <td>Agent correctly identifies the flight as a code-share but fails to...</td>\n",
       "      <td>false</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: Details so...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_148</td>\n",
       "      <td>Agent is appropriately empathetic and offers to help find alternat...</td>\n",
       "      <td>true</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: Does anyon...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_149</td>\n",
       "      <td>The agent correctly explained the airline's policy regarding minor...</td>\n",
       "      <td>false</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Company: JetBlue Transcript so far: Customer: how much is the fair...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_150</td>\n",
       "      <td>The agent's response is polite but unhelpful; it doesn't provide t...</td>\n",
       "      <td>false</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Company: US Airways Transcript so far: Customer: Air Canada flight...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_151</td>\n",
       "      <td>The agent's initial response was unhelpful, but they improved by o...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Company: Delta Air Lines Transcript so far: Customer: i would like...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_152</td>\n",
       "      <td>The agent provided helpful information and alternative solutions t...</td>\n",
       "      <td>true</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Company: Air Madagascar Transcript so far: Customer: Does anyone k...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_153</td>\n",
       "      <td>The agent's response is polite, helpful, and directs the customer ...</td>\n",
       "      <td>true</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: If I purch...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_154</td>\n",
       "      <td>The agent's response is helpful but doesn't fully alleviate the cu...</td>\n",
       "      <td>false</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Company: American Airlines Conversation Transcript so far: Custome...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_155</td>\n",
       "      <td>The agent apologized and offered further assistance with American ...</td>\n",
       "      <td>true</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: In email, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_156</td>\n",
       "      <td>The agent acknowledged the problem and promised to forward it to t...</td>\n",
       "      <td>true</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: I am looki...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_157</td>\n",
       "      <td>The agent acknowledged the request and is actively working on it.</td>\n",
       "      <td>false</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Company: Delta Air Lines Transcript so far: Customer: I fly from B...</td>\n",
       "      <td>False</td>\n",
       "      <td>example_158</td>\n",
       "      <td>The agent's response is not completely satisfactory as it does not...</td>\n",
       "      <td>false</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Company: American Airlines Transcript so far: Customer: What happe...</td>\n",
       "      <td>True</td>\n",
       "      <td>example_159</td>\n",
       "      <td>The agent's response is unhelpful and doesn't provide a clear solu...</td>\n",
       "      <td>false</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               transcript  \\\n",
       "0   Company: American Airlines Transcript so far: Customer: I started ...   \n",
       "1   Company: British Airways Transcript so far: Customer: We have a fl...   \n",
       "2   Company: American Airlines Transcript so far: Customer: I have 2 s...   \n",
       "3   Company: American Airlines Transcript so far: Customer: I want to ...   \n",
       "4   Company: American Airlines Transcript so far: Customer: We're due ...   \n",
       "5   Company: American Airlines Transcript so far: Customer: I'm having...   \n",
       "6   Company: American Airlines Transcript so far: Customer: I'm travel...   \n",
       "7   Company: American Airlines Transcript so far: Customer: Can I chec...   \n",
       "8   Company: American Airlines Transcript so far: Customer: Could you ...   \n",
       "9   Company: American Airlines Transcript so far: Customer: I work as ...   \n",
       "10  Company: American Airlines Transcript so far: Customer: @cname- Du...   \n",
       "11  Company: American Airlines Transcript so far: Customer: I would li...   \n",
       "12  Company: American Airlines Transcript so far: Customer: Hi there, ...   \n",
       "13  Company: American Airlines Transcript so far: Customer: I have boo...   \n",
       "14  Company: American Airlines Transcript so far: Customer: I was told...   \n",
       "15  Company: American Airlines Transcript so far: Customer: I cannot f...   \n",
       "16  Company: American Airlines Transcript so far: Customer: Hi, I am t...   \n",
       "17  Company: Amtrak Conversation Transcript so far: Customer: Our syst...   \n",
       "18  Company: Spirit Airlines Transcript so far: Customer: I'm allowed ...   \n",
       "19  Company: American Airlines Transcript so far: Customer: Can anyone...   \n",
       "20  Company: Delta Air Lines Transcript so far: Customer: A friend and...   \n",
       "21  Company: American Airlines Transcript so far: Customer: There are ...   \n",
       "22  Company: American Airlines Transcript so far: Customer: We travell...   \n",
       "23  Company: American Airlines Transcript so far: Customer: I can't fi...   \n",
       "24  Company: American Airlines Transcript so far: Customer: We are hav...   \n",
       "25  Company: American Airlines Transcript so far: Customer: i am flyin...   \n",
       "26  Company: Delta Air Lines Conversation Transcript so far: Customer:...   \n",
       "27  Company: American Airlines Transcript so far: Customer: I am flyin...   \n",
       "28  Company: American Airlines Transcript so far: Customer: I have see...   \n",
       "29  Company: American Airlines Transcript so far: Customer: I just tho...   \n",
       "30  Company: American Airlines Transcript so far: Customer: I am tryin...   \n",
       "31  Company: American Airlines Transcript so far: Customer: I'm intere...   \n",
       "32  Company: American Airlines Transcript so far: Customer: I am trave...   \n",
       "33  Company: American Airlines Transcript so far: Customer: I have a f...   \n",
       "34  Company: American Airlines Transcript so far: Customer: I have a d...   \n",
       "35  Company: American Airlines Transcript so far: Customer: Hi, I have...   \n",
       "36  Company: American Airlines Transcript so far: Customer: I just enr...   \n",
       "37  Company: American Airlines Transcript so far: Customer: I have boo...   \n",
       "38  Company: American Airlines Transcript so far: Customer: Details so...   \n",
       "39  Company: American Airlines Transcript so far: Customer: Does anyon...   \n",
       "40  Company: JetBlue Transcript so far: Customer: how much is the fair...   \n",
       "41  Company: US Airways Transcript so far: Customer: Air Canada flight...   \n",
       "42  Company: Delta Air Lines Transcript so far: Customer: i would like...   \n",
       "43  Company: Air Madagascar Transcript so far: Customer: Does anyone k...   \n",
       "44  Company: American Airlines Transcript so far: Customer: If I purch...   \n",
       "45  Company: American Airlines Conversation Transcript so far: Custome...   \n",
       "46  Company: American Airlines Transcript so far: Customer: In email, ...   \n",
       "47  Company: American Airlines Transcript so far: Customer: I am looki...   \n",
       "48  Company: Delta Air Lines Transcript so far: Customer: I fly from B...   \n",
       "49  Company: American Airlines Transcript so far: Customer: What happe...   \n",
       "\n",
       "   example_satisfied          _id  \\\n",
       "0               True  example_110   \n",
       "1               True  example_111   \n",
       "2               True  example_112   \n",
       "3              False  example_113   \n",
       "4               True  example_114   \n",
       "5               True  example_115   \n",
       "6              False  example_116   \n",
       "7               True  example_117   \n",
       "8               True  example_118   \n",
       "9              False  example_119   \n",
       "10             False  example_120   \n",
       "11              True  example_121   \n",
       "12             False  example_122   \n",
       "13             False  example_123   \n",
       "14              True  example_124   \n",
       "15              True  example_125   \n",
       "16              True  example_126   \n",
       "17             False  example_127   \n",
       "18             False  example_128   \n",
       "19              True  example_129   \n",
       "20             False  example_130   \n",
       "21             False  example_131   \n",
       "22              True  example_132   \n",
       "23              True  example_133   \n",
       "24              True  example_134   \n",
       "25             False  example_135   \n",
       "26              True  example_136   \n",
       "27             False  example_137   \n",
       "28              True  example_138   \n",
       "29              True  example_139   \n",
       "30             False  example_140   \n",
       "31             False  example_141   \n",
       "32             False  example_142   \n",
       "33              True  example_143   \n",
       "34             False  example_144   \n",
       "35              True  example_145   \n",
       "36             False  example_146   \n",
       "37              True  example_147   \n",
       "38             False  example_148   \n",
       "39             False  example_149   \n",
       "40             False  example_150   \n",
       "41              True  example_151   \n",
       "42              True  example_152   \n",
       "43              True  example_153   \n",
       "44             False  example_154   \n",
       "45              True  example_155   \n",
       "46              True  example_156   \n",
       "47             False  example_157   \n",
       "48             False  example_158   \n",
       "49              True  example_159   \n",
       "\n",
       "                                                                reasoning  \\\n",
       "0           Agent provided helpful information and alternative solutions.   \n",
       "1   The agent thoroughly addresses the customer's concerns, providing ...   \n",
       "2   The agent initially gave a negative response but then offered a he...   \n",
       "3   The agent did not answer the customer's questions about the AAdvan...   \n",
       "4       Agent correctly identified the problem and gave a clear solution.   \n",
       "5   The agent offered a helpful solution but didn't directly address t...   \n",
       "6   The agent provided a helpful and accurate response by directing th...   \n",
       "7   The agent provided a helpful and complete answer to the customer's...   \n",
       "8   The agent initially gave a correct, albeit unhelpful response, but...   \n",
       "9   The agent repeatedly fails to understand the customer's request, l...   \n",
       "10  The agent's response is polite and acknowledges the problem, offer...   \n",
       "11  Agent's initial response was unhelpful, but the follow-up was sati...   \n",
       "12  The agent is following the standard procedure to access the custom...   \n",
       "13  The agent's response is unclear and potentially inaccurate regardi...   \n",
       "14  The agent showed empathy and offered a solution to investigate the...   \n",
       "15                        Agent provided a helpful and accurate solution.   \n",
       "16  The agent correctly identified that the query was outside their pu...   \n",
       "17  The agent provided the requested confirmation number and offered f...   \n",
       "18  The agent did not provide a clear answer and offered an apology in...   \n",
       "19  The agent initially gave inaccurate information about standby and ...   \n",
       "20  The agent's response is unhelpful; it doesn't offer a solution and...   \n",
       "21  Agent's initial response is unhelpful; the follow-up is slightly b...   \n",
       "22              Agent showed empathy and offered to check for exceptions.   \n",
       "23  Agent offered multiple solutions, escalating to a potentially fast...   \n",
       "24  Agent is understanding but still requests sensitive information, a...   \n",
       "25  The agent's response is unhelpful; it doesn't directly answer the ...   \n",
       "26  The agent's response is helpful and offers a practical solution to...   \n",
       "27  Agent provided helpful information and addressed customer's concer...   \n",
       "28  The agent answered the customer's questions clearly and concisely,...   \n",
       "29  Agent gave good advice, but could have offered more proactive solu...   \n",
       "30  The agent did not solve the problem; they only offered an alternat...   \n",
       "31  The agent's response is helpful and addresses the customer's reque...   \n",
       "32  The agent did not directly answer the customer's question about ba...   \n",
       "33  Agent provides a realistic assessment of time constraints and offe...   \n",
       "34     Agent is efficient and empathetic to the urgency of the situation.   \n",
       "35  The agent answered the questions accurately but could have provide...   \n",
       "36  The agent's response is polite but lacks specific instructions on ...   \n",
       "37  Agent correctly identifies the flight as a code-share but fails to...   \n",
       "38  Agent is appropriately empathetic and offers to help find alternat...   \n",
       "39  The agent correctly explained the airline's policy regarding minor...   \n",
       "40  The agent's response is polite but unhelpful; it doesn't provide t...   \n",
       "41  The agent's initial response was unhelpful, but they improved by o...   \n",
       "42  The agent provided helpful information and alternative solutions t...   \n",
       "43  The agent's response is polite, helpful, and directs the customer ...   \n",
       "44  The agent's response is helpful but doesn't fully alleviate the cu...   \n",
       "45  The agent apologized and offered further assistance with American ...   \n",
       "46  The agent acknowledged the problem and promised to forward it to t...   \n",
       "47      The agent acknowledged the request and is actively working on it.   \n",
       "48  The agent's response is not completely satisfactory as it does not...   \n",
       "49  The agent's response is unhelpful and doesn't provide a clear solu...   \n",
       "\n",
       "   pred_satisfied match_judge_metric  \n",
       "0            true             ✔️ [1]  \n",
       "1            true             ✔️ [1]  \n",
       "2            true             ✔️ [1]  \n",
       "3           false             ✔️ [1]  \n",
       "4            true             ✔️ [1]  \n",
       "5           false                     \n",
       "6            true                     \n",
       "7            true             ✔️ [1]  \n",
       "8            true             ✔️ [1]  \n",
       "9           false             ✔️ [1]  \n",
       "10          false             ✔️ [1]  \n",
       "11           true             ✔️ [1]  \n",
       "12           true                     \n",
       "13          false             ✔️ [1]  \n",
       "14           true             ✔️ [1]  \n",
       "15           true             ✔️ [1]  \n",
       "16          false                     \n",
       "17           true                     \n",
       "18          false             ✔️ [1]  \n",
       "19           true             ✔️ [1]  \n",
       "20          false             ✔️ [1]  \n",
       "21          false             ✔️ [1]  \n",
       "22           true             ✔️ [1]  \n",
       "23           true             ✔️ [1]  \n",
       "24          false                     \n",
       "25          false             ✔️ [1]  \n",
       "26           true             ✔️ [1]  \n",
       "27           true                     \n",
       "28           true             ✔️ [1]  \n",
       "29           true             ✔️ [1]  \n",
       "30          false             ✔️ [1]  \n",
       "31           true                     \n",
       "32          false             ✔️ [1]  \n",
       "33           true             ✔️ [1]  \n",
       "34           true                     \n",
       "35          false                     \n",
       "36          false             ✔️ [1]  \n",
       "37          false                     \n",
       "38           true                     \n",
       "39          false             ✔️ [1]  \n",
       "40          false             ✔️ [1]  \n",
       "41          False                     \n",
       "42           true             ✔️ [1]  \n",
       "43           true             ✔️ [1]  \n",
       "44          false             ✔️ [1]  \n",
       "45           true             ✔️ [1]  \n",
       "46           true             ✔️ [1]  \n",
       "47          false             ✔️ [1]  \n",
       "48          false             ✔️ [1]  \n",
       "49          false                     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimized_valid_score = evaluator_valid(generate_judge_reasoning_optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2fac1b31-0856-414e-a738-2f2990cabaa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_valid_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17b3d13-3fa0-4cd9-91bd-d0418eae6211",
   "metadata": {},
   "source": [
    "## Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d6bf633d-9e1b-4ba7-a38f-6ccf0c25b16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_judge_reasoning.save(\"dspy_modules/baseline_llm_judge\",save_program=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d1e4747c-892e-40bf-9383-e952fb674050",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_judge_reasoning_optimized.save(\"dspy_modules/optimized_llm_judge\",save_program=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3a1237-6316-4016-a6e7-1af04c0c562a",
   "metadata": {},
   "source": [
    "## Use this to see the resulting system prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "131e2410-1c1a-467d-8a05-12c3595b5d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-08-23T15:51:38.410278]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `transcript` (str): Input transcript to judge\n",
      "Your output fields are:\n",
      "1. `reasoning` (str): \n",
      "2. `satisfied` (str): Whether the agent satisfied the customer query. This must be either True or False\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "Inputs will have the following structure:\n",
      "\n",
      "[[ ## transcript ## ]]\n",
      "{transcript}\n",
      "\n",
      "Outputs will be a JSON object with the following fields.\n",
      "\n",
      "{\n",
      "  \"reasoning\": \"{reasoning}\",\n",
      "  \"satisfied\": \"{satisfied}\"\n",
      "}\n",
      "In adhering to this structure, your objective is: \n",
      "        You are an expert in customer service, evaluating interactions between customers and agents. Analyze the following conversation transcript, considering the agent's response in context.  Assess whether the agent's response was satisfactory, focusing on whether it was helpful, accurate, polite, concise, and understanding.  Consider the customer's perspective.  Respond with \"Satisfied: True\" or \"Satisfied: False\", followed by a concise explanation (under 20 words) justifying your assessment.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "This is an example of the task, though some input or output fields are not supplied.\n",
      "\n",
      "[[ ## transcript ## ]]\n",
      "Company: American Airlines\n",
      "Transcript so far: Customer: I'm attempting to purchase tickets and clicking \"no\" to the insurance option, but it doesn't seem like the system is processing my selection. I'm getting a message indicating that I must select an option.\n",
      "Support: I apologize for the inconvenience you're experiencing. It seems like there might be a technical issue with deselecting the insurance option. To assist you better, could you please provide me with the specific flight details and the number of tickets you are trying to purchase?\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "{\n",
      "  \"reasoning\": \"Not supplied for this particular example. \",\n",
      "  \"satisfied\": \"False\"\n",
      "}\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## transcript ## ]]\n",
      "Company: American Airlines\n",
      "Transcript so far: Customer: My husband wrote our TSA PreCheck number on the signature page of our US passports. Will this be a problem at security check when we fly to Europe?\n",
      "Support: It is recommended not to write anything on the signature page of the passport as it may cause issues during security checks. I would suggest contacting the TSA or passport authorities for guidance in this situation.\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "{\n",
      "  \"reasoning\": \"The agent gave good advice and suggested a helpful resource.\",\n",
      "  \"satisfied\": \"true\"\n",
      "}\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## transcript ## ]]\n",
      "Company: American Airlines\n",
      "Transcript so far: Customer: www.flightconnections.com is a good tool to find flights, but never booked a flight there. Most time their prices are higher than the airline, but now I found a flight that is cheaper on their website :) Any experience?\n",
      "Support: That's great to hear! It's always nice to find a deal. If you have any questions or need assistance with booking your flight, feel free to ask!\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "{\n",
      "  \"reasoning\": \"The agent's response is positive but doesn't address the customer's core concern about the legitimacy of the website.\",\n",
      "  \"satisfied\": \"False\"\n",
      "}\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## transcript ## ]]\n",
      "Company: American Airlines\n",
      "Transcript so far: Customer: I'm worried about my flight to Rome next week. I saw a news report about Alitalia losing its operating license. Will my flight be affected? My flight number is AA1234.\n",
      "Agent: Hi there.  American Airlines is a separate entity from Alitalia. Your flight to Rome should be unaffected.  Can I help with anything else?\n",
      "Customer: But what if Alitalia goes bankrupt and impacts your code-share agreement?  I don't want to be stuck in Italy.\n",
      "Support: I completely understand your concern. American Airlines has a robust contingency plan in place for situations like these. Even if Alitalia were to go bankrupt, we would ensure that our passengers reach their destinations smoothly. Your flight to Rome is in good hands, and we will take care of any potential issues. Is there anything else I can assist you with?\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "{\n",
      "  \"reasoning\": \"Agent is reassuring and addresses customer concerns effectively.\",\n",
      "  \"satisfied\": \"true\"\n",
      "}\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## transcript ## ]]\n",
      "Company: Delta Air Lines\n",
      "Transcript so far: Customer: I fly from Birmingham to Amsterdam on the 20th of February and my name is spelt  \"Mclntosh\" instead of \"McIntosh\" I have been told that a note has been attached to my account. Will this be a problem at the airport?\n",
      "Support: I understand your concern about the misspelling of your name on your account. Rest assured, a note has been attached to your account to address this. However, to avoid any inconvenience at the airport, I recommend contacting the airline directly to ensure they have the correct information. Safe travels!\n",
      "\n",
      "Respond with a JSON object in the following order of fields: `reasoning`, then `satisfied`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m{\n",
      "  \"reasoning\": \"The agent's response is not completely satisfactory as it does not provide a definitive answer and defers to another party.\",\n",
      "  \"satisfied\": \"false\"\n",
      "}\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generate_judge_reasoning_optimized.inspect_history(n=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
